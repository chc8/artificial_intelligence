{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "1.16.2\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and modules\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import shutil\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "np.set_printoptions(threshold = np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.enable_eager_execution()\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "BUCKET = \"qwiklabs-gcp-cbc8684b07fc2dbd-bucket\" # REPLACE WITH A BUCKET NAME (PUT YOUR PROJECT ID AND WE CREATE THE BUCKET ITSELF NEXT)\n",
    "PROJECT = \"qwiklabs-gcp-cbc8684b07fc2dbd\" # REPLACE WITH YOUR PROJECT ID\n",
    "REGION = \"us-east1\" # REPLACE WITH YOUR REGION e.g. us-central1\n",
    "\n",
    "# Import os environment variables\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"BUCKET\"] =  BUCKET\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"TFVERSION\"] = \"1.13\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now write into a python module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lstm_encoder_decoder_autoencoder_anomaly_detection_module/trainer/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lstm_encoder_decoder_autoencoder_anomaly_detection_module/trainer/model.py\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set logging to be level of INFO\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Determine CSV and label columns\n",
    "number_of_tags = 5\n",
    "tag_columns = [\"tag_{0}\".format(tag) for tag in range(0, number_of_tags)]\n",
    "UNLABELED_CSV_COLUMNS = tag_columns\n",
    "\n",
    "LABEL_COLUMN = \"anomalous_sequence_flag\"\n",
    "LABELED_CSV_COLUMNS = UNLABELED_CSV_COLUMNS + [LABEL_COLUMN]\n",
    "\n",
    "# Set default values for each CSV column\n",
    "UNLABELED_DEFAULTS = [[\"\"] for _ in UNLABELED_CSV_COLUMNS]\n",
    "\n",
    "LABELED_DEFAULTS = UNLABELED_DEFAULTS + [[0.0]]\n",
    "\n",
    "# Create an input function reading a file using the Dataset API\n",
    "# Then provide the results to the Estimator API\n",
    "def read_dataset(filename, mode, batch_size, params):\n",
    "    def _input_fn():\n",
    "        def decode_csv(value_column, sequence_length):\n",
    "            def convert_sequences_from_strings_to_floats(features, column_list):\n",
    "                def split_and_convert_string(string_tensor):\n",
    "                    # Split string tensor into a sparse tensor based on delimiter\n",
    "                    split_string = tf.string_split(source = tf.expand_dims(input = string_tensor, axis = 0), delimiter = \",\")\n",
    "\n",
    "                    # Converts the values of the sparse tensor to floats\n",
    "                    converted_tensor = tf.string_to_number(split_string.values, out_type = tf.float64)\n",
    "\n",
    "                    # Create a new sparse tensor with the new converted values, because the original sparse tensor values are immutable\n",
    "                    new_sparse_tensor = tf.SparseTensor(indices = split_string.indices, values = converted_tensor, dense_shape = split_string.dense_shape)\n",
    "\n",
    "                    # Create a dense tensor of the float values that were converted from text csv\n",
    "                    dense_floats = tf.sparse_tensor_to_dense(sp_input = new_sparse_tensor, default_value = 0.0)\n",
    "\n",
    "                    dense_floats_vector = tf.squeeze(input = dense_floats, axis = 0)\n",
    "\n",
    "                    return dense_floats_vector\n",
    "                    \n",
    "                for column in column_list:\n",
    "                    features[column] = split_and_convert_string(features[column])\n",
    "                    features[column].set_shape([sequence_length])\n",
    "\n",
    "\n",
    "                return features\n",
    "                \n",
    "            if mode == tf.estimator.ModeKeys.TRAIN or (mode == tf.estimator.ModeKeys.EVAL and params[\"evaluation_mode\"] != \"tune_anomaly_thresholds\"):\n",
    "                columns = tf.decode_csv(records = value_column, record_defaults = UNLABELED_DEFAULTS, field_delim = \";\")\n",
    "                features = dict(zip(UNLABELED_CSV_COLUMNS, columns))\n",
    "                features = convert_sequences_from_strings_to_floats(features, UNLABELED_CSV_COLUMNS)\n",
    "                return features\n",
    "            else:\n",
    "                columns = tf.decode_csv(records = value_column, record_defaults = LABELED_DEFAULTS, field_delim = \";\")\n",
    "                features = dict(zip(LABELED_CSV_COLUMNS, columns))\n",
    "                labels = tf.cast(x = features.pop(LABEL_COLUMN), dtype = tf.float64)\n",
    "                features = convert_sequences_from_strings_to_floats(features, LABELED_CSV_COLUMNS[0:-1])\n",
    "                return features, labels\n",
    "        \n",
    "        # Create list of files that match pattern\n",
    "        file_list = tf.gfile.Glob(filename = filename)\n",
    "\n",
    "        # Create dataset from file list\n",
    "        dataset = tf.data.TextLineDataset(filenames = file_list)    # Read text file\n",
    "\n",
    "        # Decode the CSV file into a features dictionary of tensors\n",
    "        dataset = dataset.map(map_func = lambda x: decode_csv(x, params[\"sequence_length\"]))\n",
    "        \n",
    "        # Determine amount of times to repeat file based on if we are training or evaluating\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            num_epochs = None # indefinitely\n",
    "        else:\n",
    "            num_epochs = 1 # end-of-input after this\n",
    "\n",
    "        # Repeat files num_epoch times\n",
    "        dataset = dataset.repeat(count = num_epochs)\n",
    "\n",
    "        # Group the data into batches\n",
    "        dataset = dataset.batch(batch_size = batch_size)\n",
    "        \n",
    "        # Determine if we should shuffle based on if we are training or evaluating\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            dataset = dataset.shuffle(buffer_size = 10 * batch_size)\n",
    "\n",
    "        # Create a iterator and then pull the next batch of features from the example queue\n",
    "        batched_dataset = dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "        return batched_dataset\n",
    "    return _input_fn\n",
    "\n",
    "# Create our model function to be used in our custom estimator\n",
    "def lstm_encoder_decoder_autoencoder_anomaly_detection(features, labels, mode, params):\n",
    "    print(\"\\nlstm_encoder_decoder_autoencoder_anomaly_detection: features = \\n{}\".format(features))\n",
    "    print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: labels = \\n{}\".format(labels))\n",
    "    print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: mode = \\n{}\".format(mode))\n",
    "    print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: params = \\n{}\".format(params))\n",
    "\n",
    "    # 0. Get input sequence tensor into correct shape\n",
    "    # Get dynamic batch size in case there was a partially filled batch\n",
    "    current_batch_size = tf.shape(input = features[UNLABELED_CSV_COLUMNS[0]], out_type = tf.int64)[0]\n",
    "\n",
    "    # Get the number of features \n",
    "    number_of_features = len(UNLABELED_CSV_COLUMNS)\n",
    "\n",
    "    # Stack all of the features into a 3-D tensor\n",
    "    X = tf.stack(values = list(features.values()), axis = 2) # shape = (current_batch_size, sequence_length, number_of_features)\n",
    "\n",
    "    # Unstack all of 3-D features tensor into a sequence(list) of 2-D tensors of shape = (current_batch_size, number_of_features)\n",
    "    X_sequence = tf.unstack(value = X, num = params[\"sequence_length\"], axis = 1)\n",
    "\n",
    "    # Since this is an autoencoder, the features are the labels. It works better though to have the labels in reverse order\n",
    "    if params[\"reverse_labels_sequence\"] == True:\n",
    "        Y = tf.reverse_sequence(input = X,  # shape = (current_batch_size, sequence_length, number_of_features)\n",
    "                                seq_lengths = tf.tile(input = tf.constant(value = [params[\"sequence_length\"]], dtype = tf.int64), \n",
    "                                                      multiples = tf.expand_dims(input = current_batch_size, axis = 0)), \n",
    "                                seq_axis = 1, \n",
    "                                batch_axis = 0)\n",
    "    else:\n",
    "        Y = X  # shape = (current_batch_size, sequence_length, number_of_features)\n",
    "  \n",
    "  ################################################################################\n",
    "  \n",
    "    # 1. Create encoder of encoder-decoder LSTM stacks\n",
    "    def create_LSTM_stack(lstm_hidden_units, lstm_dropout_output_keep_probs):\n",
    "        # First create a list of LSTM cells using our list of lstm hidden unit sizes\n",
    "        lstm_cells = [tf.contrib.rnn.BasicLSTMCell(num_units = units, forget_bias = 1.0, state_is_tuple = True) for units in lstm_hidden_units] # list of LSTM cells\n",
    "\n",
    "        # Next apply a dropout wrapper to our stack of LSTM cells, in this case just on the outputs\n",
    "        dropout_lstm_cells = [tf.nn.rnn_cell.DropoutWrapper(cell = lstm_cells[cell_index], \n",
    "                                                            input_keep_prob = 1.0, \n",
    "                                                            output_keep_prob = lstm_dropout_output_keep_probs[cell_index], \n",
    "                                                            state_keep_prob = 1.0) for cell_index in range(len(lstm_cells))]\n",
    "\n",
    "        # Create a stack of layers of LSTM cells\n",
    "        stacked_lstm_cells = tf.contrib.rnn.MultiRNNCell(cells = dropout_lstm_cells, state_is_tuple = True) # combines list into MultiRNNCell object\n",
    "\n",
    "        return stacked_lstm_cells\n",
    "  \n",
    "    # Create our decoder now\n",
    "    decoder_stacked_lstm_cells = create_LSTM_stack(params[\"decoder_lstm_hidden_units\"], params[\"lstm_dropout_output_keep_probs\"])\n",
    "  \n",
    "    # Create the encoder variable scope\n",
    "    with tf.variable_scope(\"encoder\"):\n",
    "        # Create separate encoder cells with their own weights separate from decoder\n",
    "        encoder_stacked_lstm_cells = create_LSTM_stack(params[\"encoder_lstm_hidden_units\"], params[\"lstm_dropout_output_keep_probs\"])\n",
    "\n",
    "        # Encode the input sequence using our encoder stack of LSTMs\n",
    "        # encoder_outputs = list sequence_length long of shape = (current_batch_size, encoder_lstm_hidden_units[-1]), # encoder_states = tuple of final encoder c_state and h_state for each layer\n",
    "        encoder_outputs, encoder_states = tf.nn.static_rnn(cell = encoder_stacked_lstm_cells, \n",
    "                                                           inputs = X_sequence, \n",
    "                                                           initial_state = encoder_stacked_lstm_cells.zero_state(batch_size = tf.cast(x = current_batch_size, dtype = tf.int32), dtype = tf.float64), \n",
    "                                                           dtype = tf.float64)\n",
    "\n",
    "        # We just pass on the final c and h states of the encoder\"s last layer, so extract that and drop the others\n",
    "        encoder_final_states = encoder_states[-1] # LSTMStateTuple shape = (current_batch_size, lstm_hidden_units[-1])\n",
    "\n",
    "        # Extract the c and h states from the tuple\n",
    "        encoder_final_c, encoder_final_h = encoder_final_states # both have shape = (current_batch_size, lstm_hidden_units[-1])\n",
    "\n",
    "        # In case the decoder\"s first layer\"s number of units is different than encoder's last layer's number of units, use a dense layer to map to the correct shape\n",
    "        encoder_final_c_dense = tf.layers.dense(inputs = encoder_final_c, units = params[\"decoder_lstm_hidden_units\"][0], activation = None) # shape = (current_batch_size, decoder_lstm_hidden_units[0])\n",
    "        encoder_final_h_dense = tf.layers.dense(inputs = encoder_final_h, units = params[\"decoder_lstm_hidden_units\"][0], activation = None) # shape = (current_batch_size, decoder_lstm_hidden_units[0])\n",
    "\n",
    "        # The decoder\"s first layer\"s state comes from the encoder, the rest of the layers\" initial states are zero\n",
    "        decoder_intial_states = tuple([tf.contrib.rnn.LSTMStateTuple(c = encoder_final_c_dense, h = encoder_final_h_dense)] + \\\n",
    "                                      [tf.contrib.rnn.LSTMStateTuple(c = tf.zeros(shape = [current_batch_size, units], dtype = tf.float64), \n",
    "                                                                     h = tf.zeros(shape = [current_batch_size, units], dtype = tf.float64)) for units in params[\"decoder_lstm_hidden_units\"][1:]])\n",
    "    \n",
    "    ################################################################################\n",
    "\n",
    "    # 2. Create decoder of encoder-decoder LSTM stacks\n",
    "    # The rnn_decoder function takes labels during TRAIN/EVAL and a start token followed by its previous predictions during PREDICT\n",
    "    # Starts with an intial state of the final encoder states\n",
    "    def rnn_decoder(decoder_inputs, initial_state, cell, inference):\n",
    "        # Create the decoder variable scope\n",
    "        with tf.variable_scope(\"decoder\"):\n",
    "            # Load in our initial state from our encoder\n",
    "            state = initial_state # tuple of final encoder c_state and h_state of final encoder layer\n",
    "            \n",
    "            # Create an empty list to store our hidden state output for every timestep\n",
    "            outputs = []\n",
    "            \n",
    "            # Begin with no previous output\n",
    "            previous_output = None\n",
    "            \n",
    "            # Loop over all of our decoder_inputs which will be sequence_length long\n",
    "            for index, decoder_input in enumerate(decoder_inputs):\n",
    "                # If there has been a previous output then we will determine the next input\n",
    "                if previous_output is not None:\n",
    "                    # Create the input layer to our DNN\n",
    "                    network = previous_output # shape = (current_batch_size, lstm_hidden_units[-1])\n",
    "                    \n",
    "                    # Create our dnn variable scope\n",
    "                    with tf.variable_scope(name_or_scope = \"dnn\", reuse = tf.AUTO_REUSE):\n",
    "                        # Add hidden layers with the given number of units/neurons per layer\n",
    "                        for units in params[\"dnn_hidden_units\"]:\n",
    "                            network = tf.layers.dense(inputs = network, units = units, activation = tf.nn.relu) # shape = (current_batch_size, dnn_hidden_units[i])\n",
    "                            \n",
    "                        # Connect the final hidden layer to a dense layer with no activation to get the logits\n",
    "                        logits = tf.layers.dense(inputs = network, units = number_of_features, activation = None) # shape = (current_batch_size, number_of_features)\n",
    "                    \n",
    "                    # If we are in inference then we will overwrite our next decoder_input with the logits we just calculated.\n",
    "                    # Otherwise, we leave the decoder_input input as it was from the enumerated list\n",
    "                    # We have to calculate the logits even when not using them so that the correct dnn subgraph will be generated here and after the encoder-decoder for both training and inference\n",
    "                    if inference == True:\n",
    "                        decoder_input = logits # shape = (current_batch_size, number_of_features)\n",
    "\n",
    "                # If this isn\"t our first time through the loop, just reuse(share) the same variables for each iteration within the current variable scope\n",
    "                if index > 0:\n",
    "                    tf.get_variable_scope().reuse_variables()\n",
    "                \n",
    "                # Run the decoder input through the decoder stack picking up from the previous state\n",
    "                output, state = cell(decoder_input, state) # output = shape = (current_batch_size, lstm_hidden_units[-1]), state = # tuple of final decoder c_state and h_state\n",
    "                \n",
    "                # Append the current decoder hidden state output to the outputs list\n",
    "                outputs.append(output) # growing list eventually sequence_length long of shape = (current_batch_size, lstm_hidden_units[-1])\n",
    "                \n",
    "                # Set the previous output to the output just calculated\n",
    "                previous_output = output # shape = (current_batch_size, lstm_hidden_units[-1])\n",
    "        return outputs, state\n",
    "  \n",
    "    # Train our decoder now\n",
    "  \n",
    "    # Encoder-decoders work differently during training/evaluation and inference so we will have two separate subgraphs for each\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN and params[\"evaluation_mode\"] != \"calculate_error_distribution_statistics\":\n",
    "        # Break 3-D labels tensor into a list of 2-D tensors\n",
    "        unstacked_labels = tf.unstack(value = Y, num = params[\"sequence_length\"], axis = 1) # list of sequence_length long of shape = (current_batch_size, number_of_features)\n",
    "\n",
    "        # Call our decoder using the labels as our inputs, the encoder final state as our initial state, our other LSTM stack as our cells, and inference set to false\n",
    "        decoder_outputs, decoder_states = rnn_decoder(decoder_inputs = unstacked_labels, initial_state = decoder_intial_states, cell = decoder_stacked_lstm_cells, inference = False)\n",
    "    else:\n",
    "        # Since this is inference create fake labels. The list length needs to be the output sequence length even though only the first element is the only one actually used (as our go signal)\n",
    "        fake_labels = [tf.zeros(shape = [current_batch_size, number_of_features], dtype = tf.float64) for _ in range(params[\"sequence_length\"])]\n",
    "        \n",
    "        # Call our decoder using fake labels as our inputs, the encoder final state as our initial state, our other LSTM stack as our cells, and inference set to true\n",
    "        # decoder_outputs = list sequence_length long of shape = (current_batch_size, decoder_lstm_hidden_units[-1]), # decoder_states = tuple of final decoder c_state and h_state for each layer\n",
    "        decoder_outputs, decoder_states = rnn_decoder(decoder_inputs = fake_labels, initial_state = decoder_intial_states, cell = decoder_stacked_lstm_cells, inference = True)\n",
    "    \n",
    "    # Stack together the list of rank 2 decoder output tensors into one rank 3 tensor\n",
    "    stacked_decoder_outputs = tf.stack(values = decoder_outputs, axis = 1) # shape = (current_batch_size, sequence_length, lstm_hidden_units[-1])\n",
    "    \n",
    "    # Reshape rank 3 decoder outputs into rank 2 by folding sequence length into batch size\n",
    "    reshaped_stacked_decoder_outputs = tf.reshape(tensor = stacked_decoder_outputs, shape = [current_batch_size * params[\"sequence_length\"], params[\"decoder_lstm_hidden_units\"][-1]]) # shape = (current_batch_size * sequence_length, lstm_hidden_units[-1])\n",
    "\n",
    "    ################################################################################\n",
    "    \n",
    "    # 3. Create the DNN structure now after the encoder-decoder LSTM stack\n",
    "    # Create the input layer to our DNN\n",
    "    network = reshaped_stacked_decoder_outputs # shape = (current_batch_size * sequence_length, lstm_hidden_units[-1])\n",
    "    \n",
    "    # Reuse the same variable scope as we used within our decoder (for inference)\n",
    "    with tf.variable_scope(name_or_scope = \"dnn\", reuse = tf.AUTO_REUSE):\n",
    "        # Add hidden layers with the given number of units/neurons per layer\n",
    "        for units in params[\"dnn_hidden_units\"]:\n",
    "            network = tf.layers.dense(inputs = network, units = units, activation = tf.nn.relu) # shape = (current_batch_size * sequence_length, dnn_hidden_units[i])\n",
    "\n",
    "        # Connect the final hidden layer to a dense layer with no activation to get the logits\n",
    "        logits = tf.layers.dense(inputs = network, units = number_of_features, activation = None) # shape = (current_batch_size * sequence_length, number_of_features)\n",
    "    \n",
    "    # Now that we are through the final DNN for each sequence element for each example in the batch, reshape the predictions to match our labels\n",
    "    predictions = tf.reshape(tensor = logits, shape = [current_batch_size, params[\"sequence_length\"], number_of_features]) # shape = (current_batch_size, sequence_length, number_of_features)\n",
    "    \n",
    "    with tf.variable_scope(name_or_scope = \"mahalanobis_distance_variables\", reuse = tf.AUTO_REUSE):\n",
    "        # Time based\n",
    "        absolute_error_count_batch_time_variable = tf.get_variable(name = \"absolute_error_count_batch_time_variable\", # shape = ()\n",
    "                                                                   dtype = tf.int64,\n",
    "                                                                   initializer = tf.zeros(shape = [], \n",
    "                                                                                          dtype = tf.int64),\n",
    "                                                                   trainable = False)\n",
    "        \n",
    "        absolute_error_mean_batch_time_variable = tf.get_variable(name = \"absolute_error_mean_batch_time_variable\", # shape = (number_of_features,)\n",
    "                                                                  dtype = tf.float64,\n",
    "                                                                  initializer = tf.zeros(shape = [number_of_features], \n",
    "                                                                                         dtype = tf.float64),\n",
    "                                                                  trainable = False)\n",
    "        \n",
    "        absolute_error_covariance_matrix_batch_time_variable = tf.get_variable(name = \"absolute_error_covariance_matrix_batch_time_variable\", # shape = (number_of_features, number_of_features)\n",
    "                                                                               dtype = tf.float64,\n",
    "                                                                               initializer = tf.zeros(shape = [number_of_features, number_of_features], \n",
    "                                                                                                      dtype = tf.float64),\n",
    "                                                                               trainable = False)\n",
    "\n",
    "        absolute_error_inverse_covariance_matrix_batch_time_variable = tf.get_variable(name = \"absolute_error_inverse_covariance_matrix_batch_time_variable\", # shape = (number_of_features, number_of_features)\n",
    "                                                                                       dtype = tf.float64,\n",
    "                                                                                       initializer = tf.zeros(shape = [number_of_features, number_of_features], \n",
    "                                                                                                              dtype = tf.float64),\n",
    "                                                                                       trainable = False)\n",
    "\n",
    "        # Features based\n",
    "        absolute_error_count_batch_features_variable = tf.get_variable(name = \"absolute_error_count_batch_features_variable\", # shape = ()\n",
    "                                                                       dtype = tf.int64,\n",
    "                                                                       initializer = tf.zeros(shape = [], \n",
    "                                                                                              dtype = tf.int64),\n",
    "                                                                       trainable = False)\n",
    "        \n",
    "        absolute_error_mean_batch_features_variable = tf.get_variable(name = \"absolute_error_mean_batch_features_variable\", # shape = (sequence_length,)\n",
    "                                                                      dtype = tf.float64,\n",
    "                                                                      initializer = tf.zeros(shape = [params[\"sequence_length\"]], \n",
    "                                                                                             dtype = tf.float64),\n",
    "                                                                      trainable = False)\n",
    "        \n",
    "        absolute_error_covariance_matrix_batch_features_variable = tf.get_variable(name = \"absolute_error_covariance_matrix_batch_features_variable\", # shape = (sequence_length, sequence_length)\n",
    "                                                                                   dtype = tf.float64,\n",
    "                                                                                   initializer = tf.zeros(shape = [params[\"sequence_length\"], params[\"sequence_length\"]], \n",
    "                                                                                                          dtype = tf.float64),\n",
    "                                                                                   trainable = False)\n",
    "\n",
    "        absolute_error_inverse_covariance_matrix_batch_features_variable = tf.get_variable(name = \"absolute_error_inverse_covariance_matrix_batch_features_variable\", # shape = (sequence_length, sequence_length)\n",
    "                                                                                           dtype = tf.float64,\n",
    "                                                                                           initializer = tf.zeros(shape = [params[\"sequence_length\"], params[\"sequence_length\"]], \n",
    "                                                                                                                  dtype = tf.float64),\n",
    "                                                                                           trainable = False)\n",
    "        \n",
    "    dummy_variable = tf.get_variable(name = \"dummy_variable\", # shape = ()\n",
    "                                     dtype = tf.float64,\n",
    "                                     initializer = tf.zeros(shape = [], dtype = tf.float64),\n",
    "                                     trainable = True)\n",
    "    \n",
    "    # Now branch off based on which mode we are in\n",
    "    predictions_dict = None\n",
    "    loss = None\n",
    "    train_op = None\n",
    "    eval_metric_ops = None\n",
    "    export_outputs = None\n",
    "    \n",
    "    # 3. Loss function, training/eval ops\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        if params[\"evaluation_mode\"] == \"reconstruction\":\n",
    "            loss = tf.losses.mean_squared_error(labels = Y, predictions = predictions)\n",
    "\n",
    "            train_op = tf.contrib.layers.optimize_loss(\n",
    "                loss = loss,\n",
    "                global_step = tf.train.get_global_step(),\n",
    "                learning_rate = params[\"learning_rate\"],\n",
    "                optimizer = \"Adam\")\n",
    "        elif params[\"evaluation_mode\"] == \"calculate_error_distribution_statistics\":\n",
    "            error = Y - predictions # shape = (current_batch_size, sequence_length, number_of_features)\n",
    "            \n",
    "            absolute_error = tf.abs(x = error) # shape = (current_batch_size, sequence_length, number_of_features)\n",
    "\n",
    "            ################################################################################\n",
    "\n",
    "            with tf.variable_scope(name_or_scope = \"mahalanobis_distance_variables\", reuse = tf.AUTO_REUSE):\n",
    "                # This function updates the count of records used\n",
    "                def update_count(count_a, count_b):\n",
    "                    return count_a + count_b\n",
    "                \n",
    "                # This function updates the mahalanobis distance variables when the number_of_rows equals 1\n",
    "                def singleton_batch_mahalanobis_distance_variable_updating(inner_size, absolute_error_reshaped, absolute_error_count_variable, absolute_error_mean_variable, absolute_error_covariance_matrix_variable, absolute_error_inverse_covariance_matrix_variable):\n",
    "                    # This function updates the mean vector incrementally\n",
    "                    def update_mean_incremental(count_a, mean_a, value_b):\n",
    "                        return (mean_a * tf.cast(x = count_a, dtype = tf.float64) + tf.squeeze(input = value_b, axis = 0)) / tf.cast(x = count_a + 1, dtype = tf.float64)\n",
    "\n",
    "                    # This function updates the covariance matrix incrementally\n",
    "                    def update_covariance_incremental(count_a, mean_a, cov_a, value_b, mean_ab, sample_covariance):\n",
    "                        if sample_covariance == True:\n",
    "                            cov_ab = (cov_a * tf.cast(x = count_a - 1, dtype = tf.float64) + tf.matmul(a = value_b - mean_a, b = value_b - mean_ab, transpose_a = True)) / tf.cast(x = count_a, dtype = tf.float64)\n",
    "                        else:\n",
    "                            cov_ab = (cov_a * tf.cast(x = count_a, dtype = tf.float64) + tf.matmul(a = value_b - mean_a, b = value_b - mean_ab, transpose_a = True)) / tf.cast(x = count_a + 1, dtype = tf.float64)\n",
    "                        return cov_ab\n",
    "\n",
    "                    # Calculate new combined mean to use for incremental covariance matrix calculation\n",
    "                    mean_ab = update_mean_incremental(count_a = absolute_error_count_variable, \n",
    "                                                      mean_a = absolute_error_mean_variable, \n",
    "                                                      value_b = absolute_error_reshaped) # time_shape = (number_of_features,), features_shape = (sequence_length,)\n",
    "\n",
    "                    # Update running variables from single example\n",
    "                    absolute_error_count_tensor = update_count(count_a = absolute_error_count_variable, \n",
    "                                                               count_b = 1) # time_shape = (), features_shape = ()\n",
    "                    \n",
    "                    absolute_error_mean_tensor = mean_ab # time_shape = (number_of_features,), features_shape = (sequence_length,)\n",
    "\n",
    "                    if inner_size == 1:\n",
    "                        absolute_error_covariance_matrix_tensor = tf.zeros_like(tensor = absolute_error_covariance_matrix_variable, dtype = tf.float64)\n",
    "                        absolute_error_inverse_covariance_matrix_tensor = tf.eye(num_rows = tf.shape(input = absolute_error_covariance_matrix_tensor)[0], \n",
    "                                                                                                     dtype = tf.float64) / params[\"eps\"]\n",
    "                    else:\n",
    "                        absolute_error_covariance_matrix_tensor = update_covariance_incremental(count_a = absolute_error_count_variable, \n",
    "                                                                                                mean_a = absolute_error_mean_variable, \n",
    "                                                                                                cov_a = absolute_error_covariance_matrix_variable, \n",
    "                                                                                                value_b = absolute_error_reshaped, \n",
    "                                                                                                mean_ab = mean_ab, \n",
    "                                                                                                sample_covariance = True) # time_shape = (number_of_features, number_of_features), features_shape = (sequence_length, sequence_length)\n",
    "                    \n",
    "                        absolute_error_inverse_covariance_matrix_tensor = tf.matrix_inverse(input = absolute_error_covariance_matrix_tensor + \\\n",
    "                                                                                            tf.eye(num_rows = tf.shape(input = absolute_error_covariance_matrix_tensor)[0], \n",
    "                                                                                                   dtype = tf.float64) * params[\"eps\"]) # time_shape = (number_of_features, number_of_features), features_shape = (sequence_length, sequence_length)\n",
    "\n",
    "                    # Assign values to variables, use control dependencies around return to enforce the mahalanobis variables to be assigned, the control order matters, hence the separate contexts\n",
    "                    with tf.control_dependencies(control_inputs = [tf.assign(ref = absolute_error_covariance_matrix_variable, value = absolute_error_covariance_matrix_tensor)]):\n",
    "                        with tf.control_dependencies(control_inputs = [tf.assign(ref = absolute_error_mean_variable, value = absolute_error_mean_tensor)]):\n",
    "                            with tf.control_dependencies(control_inputs = [tf.assign(ref = absolute_error_count_variable, value = absolute_error_count_tensor)]):\n",
    "                                with tf.control_dependencies(control_inputs = [tf.assign(ref = absolute_error_inverse_covariance_matrix_variable, value = absolute_error_inverse_covariance_matrix_tensor)]):\n",
    "                                    return tf.identity(input = absolute_error_covariance_matrix_variable), tf.identity(input = absolute_error_mean_variable), tf.identity(input = absolute_error_count_variable), tf.identity(input = absolute_error_inverse_covariance_matrix_variable)\n",
    "                \n",
    "                # This function updates the mahalanobis distance variables when the number_of_rows does NOT equal 1\n",
    "                def non_singleton_batch_mahalanobis_distance_variable_updating(current_batch_size, inner_size, absolute_error_reshaped, absolute_error_count_variable, absolute_error_mean_variable, absolute_error_covariance_matrix_variable, absolute_error_inverse_covariance_matrix_variable):\n",
    "                    # This function updates the mean vector using a batch of data\n",
    "                    def update_mean_batch(count_a, mean_a, count_b, mean_b):\n",
    "                        return (mean_a * tf.cast(x = count_a, dtype = tf.float64) + mean_b * tf.cast(x = count_b, dtype = tf.float64)) / tf.cast(x = count_a + count_b, dtype = tf.float64)\n",
    "\n",
    "                    # This function updates the covariance matrix using a batch of data\n",
    "                    def update_covariance_batch(count_a, mean_a, cov_a, count_b, mean_b, cov_b, sample_covariance):\n",
    "                        mean_diff = tf.expand_dims(input = mean_a - mean_b, axis = 0)\n",
    "\n",
    "                        if sample_covariance == True:\n",
    "                            cov_ab = (cov_a * tf.cast(x = count_a - 1, dtype = tf.float64) + cov_b * tf.cast(x = count_b - 1, dtype = tf.float64) + tf.matmul(a = mean_diff, b = mean_diff, transpose_a = True) * tf.cast(x = count_a * count_b, dtype = tf.float64) / tf.cast(x = count_a + count_b, dtype = tf.float64)) / tf.cast(x = count_a + count_b - 1, dtype = tf.float64)\n",
    "                        else:\n",
    "                            cov_ab = (cov_a * tf.cast(x = count_a, dtype = tf.float64) + cov_b * tf.cast(x = count_b, dtype = tf.float64) + tf.matmul(a = mean_diff, b = mean_diff, transpose_a = True) * tf.cast(x = count_a * count_b, dtype = tf.float64) / tf.cast(x = count_a + count_b, dtype = tf.float64)) / tf.cast(x = count_a + count_b, dtype = tf.float64)\n",
    "                        return cov_ab                    \n",
    "                    \n",
    "                    # Find statistics of batch\n",
    "                    number_of_rows = current_batch_size * inner_size\n",
    "                    \n",
    "                    absolute_error_reshaped_mean = tf.reduce_mean(input_tensor = absolute_error_reshaped, axis = 0) # time_shape = (number_of_features,), features_shape = (sequence_length,)\n",
    "\n",
    "                    absolute_error_reshaped_centered = absolute_error_reshaped - absolute_error_reshaped_mean # time_shape = (current_batch_size * sequence_length, number_of_features), features_shape = (current_batch_size * number_of_features, sequence_length)\n",
    "\n",
    "                    if inner_size > 1:\n",
    "                        absolute_error_reshaped_covariance_matrix = tf.matmul(a = absolute_error_reshaped_centered, # time_shape = (number_of_features, number_of_features), features_shape = (sequence_length, sequence_length)\n",
    "                                                                              b = absolute_error_reshaped_centered, \n",
    "                                                                              transpose_a = True) / tf.cast(x = number_of_rows - 1, dtype = tf.float64)\n",
    "\n",
    "                    # Update running variables from batch statistics\n",
    "                    absolute_error_count_tensor = update_count(count_a = absolute_error_count_variable, \n",
    "                                                               count_b = number_of_rows) # time_shape = (), features_shape = ()\n",
    "                    \n",
    "                    absolute_error_mean_tensor = update_mean_batch(count_a = absolute_error_count_variable, \n",
    "                                                                   mean_a = absolute_error_mean_variable, \n",
    "                                                                   count_b = number_of_rows, \n",
    "                                                                   mean_b = absolute_error_reshaped_mean) # time_shape = (number_of_features,), features_shape = (sequence_length,)\n",
    "\n",
    "                    if inner_size == 1:\n",
    "                        absolute_error_covariance_matrix_tensor = tf.zeros_like(tensor = absolute_error_covariance_matrix_variable, dtype = tf.float64)\n",
    "                        absolute_error_inverse_covariance_matrix_tensor = tf.eye(num_rows = tf.shape(input = absolute_error_covariance_matrix_tensor)[0], \n",
    "                                                                                                     dtype = tf.float64) / params[\"eps\"]\n",
    "                    else:\n",
    "                        absolute_error_covariance_matrix_tensor = update_covariance_batch(count_a = absolute_error_count_variable, \n",
    "                                                                                          mean_a = absolute_error_mean_variable, \n",
    "                                                                                          cov_a = absolute_error_covariance_matrix_variable, \n",
    "                                                                                          count_b = number_of_rows, \n",
    "                                                                                          mean_b = absolute_error_reshaped_mean, \n",
    "                                                                                          cov_b = absolute_error_reshaped_covariance_matrix, \n",
    "                                                                                          sample_covariance = True) # time_shape = (number_of_features, number_of_features), features_shape = (sequence_length, sequence_length)\n",
    "\n",
    "                        absolute_error_inverse_covariance_matrix_tensor = tf.matrix_inverse(input = absolute_error_covariance_matrix_tensor + \\\n",
    "                                                                                            tf.eye(num_rows = tf.shape(input = absolute_error_covariance_matrix_tensor)[0], \n",
    "                                                                                                   dtype = tf.float64) * params[\"eps\"]) # time_shape = (number_of_features, number_of_features), features_shape = (sequence_length, sequence_length)\n",
    "                    \n",
    "                    # Assign values to variables, use control dependencies around return to enforce the mahalanobis variables to be assigned, the control order matters, hence the separate contexts\n",
    "                    with tf.control_dependencies(control_inputs = [tf.assign(ref = absolute_error_covariance_matrix_variable, value = absolute_error_covariance_matrix_tensor)]):\n",
    "                        with tf.control_dependencies(control_inputs = [tf.assign(ref = absolute_error_mean_variable, value = absolute_error_mean_tensor)]):\n",
    "                            with tf.control_dependencies(control_inputs = [tf.assign(ref = absolute_error_count_variable, value = absolute_error_count_tensor)]):\n",
    "                                with tf.control_dependencies(control_inputs = [tf.assign(ref = absolute_error_inverse_covariance_matrix_variable, value = absolute_error_inverse_covariance_matrix_tensor)]):\n",
    "                                    return tf.identity(input = absolute_error_covariance_matrix_variable), tf.identity(input = absolute_error_mean_variable), tf.identity(input = absolute_error_count_variable), tf.identity(input = absolute_error_inverse_covariance_matrix_variable)\n",
    "                \n",
    "                # Check if batch is a singleton or not, very important for covariance math\n",
    "                \n",
    "                # Time based ########################################\n",
    "                absolute_error_reshaped_batch_time = tf.reshape(tensor = absolute_error, \n",
    "                                                                shape = [current_batch_size * params[\"sequence_length\"], number_of_features]) # shape = (current_batch_size * sequence_length, number_of_features)\n",
    "                \n",
    "                singleton_batch_time_condition = tf.equal(x = current_batch_size * params[\"sequence_length\"], y = 1) # shape = ()\n",
    "                \n",
    "                covariance_batch_time_variable, mean_batch_time_variable, count_batch_time_variable, inverse_batch_time_variable = \\\n",
    "                    tf.cond(pred = singleton_batch_time_condition, \n",
    "                            true_fn = lambda: singleton_batch_mahalanobis_distance_variable_updating(params[\"sequence_length\"], absolute_error_reshaped_batch_time, absolute_error_count_batch_time_variable, absolute_error_mean_batch_time_variable, absolute_error_covariance_matrix_batch_time_variable, absolute_error_inverse_covariance_matrix_batch_time_variable), \n",
    "                            false_fn = lambda: non_singleton_batch_mahalanobis_distance_variable_updating(current_batch_size, params[\"sequence_length\"], absolute_error_reshaped_batch_time, absolute_error_count_batch_time_variable, absolute_error_mean_batch_time_variable, absolute_error_covariance_matrix_batch_time_variable, absolute_error_inverse_covariance_matrix_batch_time_variable))\n",
    "\n",
    "                # Features based ########################################\n",
    "                absolute_error_transposed_batch_features = tf.transpose(a = absolute_error, perm = [0, 2, 1]) # shape = (current_batch_size, number_of_features, sequence_length)\n",
    "\n",
    "                absolute_error_reshaped_batch_features = tf.reshape(tensor = absolute_error_transposed_batch_features, \n",
    "                                                                    shape = [current_batch_size * number_of_features, params[\"sequence_length\"]]) # shape = (current_batch_size * number_of_features, sequence_length)\n",
    "\n",
    "                singleton_batch_features_condition = tf.equal(x = current_batch_size * number_of_features, y = 1) # shape = ()\n",
    "                \n",
    "                covariance_batch_features_variable, mean_batch_features_variable, count_batch_features_variable, inverse_batch_features_variable = \\\n",
    "                    tf.cond(pred = singleton_batch_features_condition, \n",
    "                            true_fn = lambda: singleton_batch_mahalanobis_distance_variable_updating(number_of_features, absolute_error_reshaped_batch_features, absolute_error_count_batch_features_variable, absolute_error_mean_batch_features_variable, absolute_error_covariance_matrix_batch_features_variable, absolute_error_inverse_covariance_matrix_batch_features_variable), \n",
    "                            false_fn = lambda: non_singleton_batch_mahalanobis_distance_variable_updating(current_batch_size, number_of_features, absolute_error_reshaped_batch_features, absolute_error_count_batch_features_variable, absolute_error_mean_batch_features_variable, absolute_error_covariance_matrix_batch_features_variable, absolute_error_inverse_covariance_matrix_batch_features_variable))\n",
    "\n",
    "            # Lastly use control dependencies around loss to enforce the mahalanobis variables to be assigned, the control order matters, hence the separate contexts\n",
    "            with tf.control_dependencies(control_inputs = [covariance_batch_time_variable, covariance_batch_features_variable]):\n",
    "                with tf.control_dependencies(control_inputs = [mean_batch_time_variable, mean_batch_features_variable]):\n",
    "                    with tf.control_dependencies(control_inputs = [count_batch_time_variable, count_batch_features_variable]):\n",
    "                        with tf.control_dependencies(control_inputs = [inverse_batch_time_variable, inverse_batch_features_variable]):\n",
    "                            loss = tf.reduce_sum(input_tensor = tf.zeros(shape = (), dtype = tf.float64) * dummy_variable)\n",
    "\n",
    "                            train_op = tf.contrib.layers.optimize_loss(\n",
    "                                loss = loss,\n",
    "                                global_step = tf.train.get_global_step(),\n",
    "                                learning_rate = params[\"learning_rate\"],\n",
    "                                optimizer = \"SGD\")\n",
    "                                                                                                       \n",
    "    elif mode == tf.estimator.ModeKeys.EVAL and params[\"evaluation_mode\"] != \"tune_anomaly_thresholds\":\n",
    "        # Reconstruction loss on evaluation set\n",
    "        loss = tf.losses.mean_squared_error(labels = Y, predictions = predictions)\n",
    "        \n",
    "        if params[\"evaluation_mode\"] == \"reconstruction\": # if reconstruction during train_and_evaluate\n",
    "            # Reconstruction eval metrics\n",
    "            eval_metric_ops = {\n",
    "                \"rmse\": tf.metrics.root_mean_squared_error(labels = Y, predictions = predictions),\n",
    "                \"mae\": tf.metrics.mean_absolute_error(labels = Y, predictions = predictions)\n",
    "            }\n",
    "    else: # mode == tf.estimator.ModeKeys.PREDICT or (mode == tf.estimator.ModeKeys.EVAL and params[\"evaluation_mode\"] == \"tune_anomaly_thresholds\")\n",
    "        def mahalanobis_distance(error_vectors_reshaped, mean_vector, inverse_covariance_matrix, final_shape):\n",
    "            error_vectors_reshaped_centered = error_vectors_reshaped - mean_vector # time_shape = (current_batch_size * sequence_length, number_of_features), features_shape = (current_batch_size * number_of_features, sequence_length)\n",
    "\n",
    "            mahalanobis_right_matrix_product = tf.matmul(a = inverse_covariance_matrix, # time_shape = (number_of_features, current_batch_size * sequence_length), features_shape = (sequence_length, current_batch_size * number_of_features)\n",
    "                                                         b = error_vectors_reshaped_centered,\n",
    "                                                         transpose_b = True)\n",
    "\n",
    "\n",
    "            mahalanobis_distance_vectorized = tf.matmul(a = error_vectors_reshaped_centered, # time_shape = (current_batch_size * sequence_length, current_batch_size * sequence_length), features_shape = (current_batch_size * number_of_features, current_batch_size * number_of_features)\n",
    "                                                        b = mahalanobis_right_matrix_product)\n",
    "\n",
    "            mahalanobis_distance_flat = tf.diag_part(input = mahalanobis_distance_vectorized) # time_shape = (current_batch_size * sequence_length,), features_shape = (current_batch_size * number_of_features,)\n",
    "\n",
    "            mahalanobis_distance_final_shaped = tf.reshape(tensor = mahalanobis_distance_flat, shape = [-1, final_shape]) # time_shape = (current_batch_size, sequence_length), features_shape = (current_batch_size, number_of_features)\n",
    "\n",
    "            mahalanobis_distance_final_shaped_abs = tf.abs(x = mahalanobis_distance_final_shaped) # time_shape = (current_batch_size, sequence_length), features_shape = (current_batch_size, number_of_features)\n",
    "            \n",
    "            return mahalanobis_distance_final_shaped_abs\n",
    "    \n",
    "        error = Y - predictions # shape = (current_batch_size, sequence_length, number_of_features)\n",
    "        absolute_error = tf.abs(x = error) # shape = (current_batch_size, sequence_length, number_of_features)\n",
    "        \n",
    "        with tf.variable_scope(name_or_scope = \"mahalanobis_distance_variables\", reuse = tf.AUTO_REUSE):\n",
    "            # Time based\n",
    "            absolute_error_reshaped_batch_time = tf.reshape(tensor = absolute_error,  # shape = (current_batch_size * sequence_length, number_of_features)\n",
    "                                                            shape = [current_batch_size * params[\"sequence_length\"], number_of_features])\n",
    "\n",
    "            mahalanobis_distance_batch_time = mahalanobis_distance(error_vectors_reshaped = absolute_error_reshaped_batch_time,  # shape = (current_batch_size, sequence_length)\n",
    "                                                                   mean_vector = absolute_error_mean_batch_time_variable, \n",
    "                                                                   inverse_covariance_matrix = absolute_error_inverse_covariance_matrix_batch_time_variable, \n",
    "                                                                   final_shape = params[\"sequence_length\"])\n",
    "\n",
    "            # Features based\n",
    "            absolute_error_mapped_batch_features = tf.map_fn(fn = lambda x: tf.transpose(a = absolute_error[x, :, :]), # shape = (current_batch_size, number_of_features, sequence_length)\n",
    "                                                             elems = tf.range(start = 0, limit = current_batch_size, dtype = tf.int64), \n",
    "                                                             dtype = tf.float64)\n",
    "\n",
    "            absolute_error_reshaped_batch_features = tf.reshape(tensor = absolute_error_mapped_batch_features, # shape = (current_batch_size * number_of_features, sequence_length)\n",
    "                                                                shape = [current_batch_size * number_of_features, params[\"sequence_length\"]])\n",
    "\n",
    "            mahalanobis_distance_batch_features = mahalanobis_distance(error_vectors_reshaped = absolute_error_reshaped_batch_features, # shape = (current_batch_size, number_of_features)\n",
    "                                                                       mean_vector = absolute_error_mean_batch_features_variable, \n",
    "                                                                       inverse_covariance_matrix = absolute_error_inverse_covariance_matrix_batch_features_variable,\n",
    "                                                                       final_shape = number_of_features)\n",
    "            \n",
    "        batch_time_anomaly_flags = tf.where(condition = tf.reduce_any(input_tensor = tf.greater(x = tf.abs(x = mahalanobis_distance_batch_time), # shape = (current_batch_size,)\n",
    "                                                                                                y = params[\"time_anomaly_threshold\"]), \n",
    "                                                                      axis = 1), \n",
    "                                            x = tf.ones(shape = [current_batch_size], dtype = tf.int64), \n",
    "                                            y = tf.zeros(shape = [current_batch_size], dtype = tf.int64))\n",
    "        \n",
    "        batch_features_anomaly_flags = tf.where(condition = tf.reduce_any(input_tensor = tf.greater(x = tf.abs(x = mahalanobis_distance_batch_features), # shape = (current_batch_size,)\n",
    "                                                                                                    y = params[\"features_anomaly_threshold\"]), \n",
    "                                                                          axis = 1), \n",
    "                                                x = tf.ones(shape = [current_batch_size], dtype = tf.int64), \n",
    "                                                y = tf.zeros(shape = [current_batch_size], dtype = tf.int64))\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.EVAL:\n",
    "            # Reconstruction loss on evaluation set\n",
    "            loss = tf.losses.mean_squared_error(labels = Y, predictions = predictions)\n",
    "            \n",
    "            # Anomaly detection eval metrics\n",
    "            def create_anomaly_detection_eval_metric_ops(labels, predictions, params):\n",
    "                batch_anomaly_true_positives = tf.metrics.true_positives(labels = labels, predictions = predictions)\n",
    "                batch_anomaly_false_negatives = tf.metrics.false_negatives(labels = labels, predictions = predictions)\n",
    "                batch_anomaly_false_positives = tf.metrics.false_positives(labels = labels, predictions = predictions)\n",
    "                batch_anomaly_true_negatives = tf.metrics.true_negatives(labels = labels, predictions = predictions)\n",
    "\n",
    "                batch_anomaly_accuracy = tf.metrics.accuracy(labels = labels, predictions = predictions)\n",
    "                batch_anomaly_precision = tf.metrics.precision(labels = labels, predictions = predictions)\n",
    "                batch_anomaly_recall = tf.metrics.recall(labels = labels, predictions = predictions)\n",
    "                batch_anomaly_f_beta_score_metric = (1.0 + params[\"f_score_beta\"]**2) * batch_anomaly_precision[0] * batch_anomaly_recall[0] / (params[\"f_score_beta\"]**2 * batch_anomaly_precision[0] + batch_anomaly_recall[0])\n",
    "                batch_anomaly_f_beta_score_update_op = (1.0 + params[\"f_score_beta\"]**2) * batch_anomaly_precision[1] * batch_anomaly_recall[1] / (params[\"f_score_beta\"]**2 * batch_anomaly_precision[1] + batch_anomaly_recall[1])\n",
    "                \n",
    "                return batch_anomaly_true_positives, batch_anomaly_false_negatives, batch_anomaly_false_positives, batch_anomaly_true_negatives, \\\n",
    "                    batch_anomaly_accuracy, batch_anomaly_precision, batch_anomaly_recall, tuple([batch_anomaly_f_beta_score_metric, batch_anomaly_f_beta_score_update_op])\n",
    "            \n",
    "            # Time based\n",
    "            batch_time_anomaly_true_positives, batch_time_anomaly_false_negatives, batch_time_anomaly_false_positives, batch_time_anomaly_true_negatives, \\\n",
    "                batch_time_anomaly_accuracy, batch_time_anomaly_precision, batch_time_anomaly_recall, batch_time_anomaly_f_beta_score = create_anomaly_detection_eval_metric_ops(labels = labels, predictions = batch_time_anomaly_flags, params = params)\n",
    "            \n",
    "            # Feature based\n",
    "            batch_features_anomaly_true_positives, batch_features_anomaly_false_negatives, batch_features_anomaly_false_positives, batch_features_anomaly_true_negatives, \\\n",
    "                batch_features_anomaly_accuracy, batch_features_anomaly_precision, batch_features_anomaly_recall, batch_features_anomaly_f_beta_score = create_anomaly_detection_eval_metric_ops(labels = labels, predictions = batch_features_anomaly_flags, params = params)\n",
    "            \n",
    "            eval_metric_ops = {\n",
    "                # Time based\n",
    "                \"batch_time_anomaly_true_positives\": batch_time_anomaly_true_positives,\n",
    "                \"batch_time_anomaly_false_negatives\": batch_time_anomaly_false_negatives,\n",
    "                \"batch_time_anomaly_false_positives\": batch_time_anomaly_false_positives,\n",
    "                \"batch_time_anomaly_true_negatives\": batch_time_anomaly_true_negatives,\n",
    "                \n",
    "                \"batch_time_anomaly_accuracy\": batch_time_anomaly_accuracy,\n",
    "                \"batch_time_anomaly_precision\": batch_time_anomaly_precision,\n",
    "                \"batch_time_anomaly_recall\": batch_time_anomaly_recall,\n",
    "                \"batch_time_anomaly_f_beta_score\": batch_time_anomaly_f_beta_score,\n",
    "                \n",
    "                 # Feature based\n",
    "                \"batch_features_anomaly_true_positives\": batch_features_anomaly_true_positives,\n",
    "                \"batch_features_anomaly_false_negatives\": batch_features_anomaly_false_negatives,\n",
    "                \"batch_features_anomaly_false_positives\": batch_features_anomaly_false_positives,\n",
    "                \"batch_features_anomaly_true_negatives\": batch_features_anomaly_true_negatives,\n",
    "                \n",
    "                \"batch_features_anomaly_accuracy\": batch_features_anomaly_accuracy,\n",
    "                \"batch_features_anomaly_precision\": batch_features_anomaly_precision,\n",
    "                \"batch_features_anomaly_recall\": batch_features_anomaly_recall,\n",
    "                \"batch_features_anomaly_f_beta_score\": batch_features_anomaly_f_beta_score\n",
    "            }\n",
    "        else: # mode == tf.estimator.ModeKeys.PREDICT\n",
    "            # Create predictions dictionary\n",
    "            predictions_dict = {\"Y\": Y,\n",
    "                                \"predictions\": predictions, \n",
    "                                \"error\": error,\n",
    "                                \"absolute_error\": absolute_error,\n",
    "                                \"mahalanobis_distance_batch_time\": mahalanobis_distance_batch_time, \n",
    "                                \"mahalanobis_distance_batch_features\": mahalanobis_distance_batch_features, \n",
    "                                \"batch_time_anomaly_flags\": batch_time_anomaly_flags, \n",
    "                                \"batch_features_anomaly_flags\": batch_features_anomaly_flags}\n",
    "\n",
    "            # Create export outputs\n",
    "            export_outputs = {\"predict_export_outputs\": tf.estimator.export.PredictOutput(outputs = predictions_dict)}\n",
    "\n",
    "    # Return EstimatorSpec\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode = mode,\n",
    "        predictions = predictions_dict,\n",
    "        loss = loss,\n",
    "        train_op = train_op,\n",
    "        eval_metric_ops = eval_metric_ops,\n",
    "        export_outputs = export_outputs)\n",
    "\n",
    "# Create our serving input function to accept the data at serving and send it in the right format to our custom estimator\n",
    "def serving_input_fn(sequence_length):\n",
    "    # This function fixes the shape and type of our input strings\n",
    "    def fix_shape_and_type_for_serving(placeholder):\n",
    "        current_batch_size = tf.shape(input = placeholder, out_type = tf.int64)[0]\n",
    "        \n",
    "        # String split each string in the batch and output the values from the resulting SparseTensors\n",
    "        split_string = tf.stack(values = tf.map_fn( # shape = (batch_size, sequence_length)\n",
    "            fn = lambda x: tf.string_split(source = [placeholder[x]], delimiter = ',').values, \n",
    "            elems = tf.range(start = 0, limit = current_batch_size, dtype = tf.int64), \n",
    "            dtype = tf.string), axis = 0)\n",
    "        \n",
    "        # Convert each string in the split tensor to float\n",
    "        feature_tensor = tf.string_to_number(string_tensor = split_string, out_type = tf.float64) # shape = (batch_size, sequence_length)\n",
    "        \n",
    "        return feature_tensor\n",
    "    \n",
    "    # This function fixes dynamic shape ambiguity of last dimension so that we will be able to use it in our DNN (since tf.layers.dense require the last dimension to be known)\n",
    "    def get_shape_and_set_modified_shape_2D(tensor, additional_dimension_sizes):\n",
    "        # Get static shape for tensor and convert it to list\n",
    "        shape = tensor.get_shape().as_list()\n",
    "        # Set outer shape to additional_dimension_sizes[0] since we know that this is the correct size\n",
    "        shape[1] = additional_dimension_sizes[0]\n",
    "        # Set the shape of tensor to our modified shape\n",
    "        tensor.set_shape(shape = shape) # shape = (batch_size, additional_dimension_sizes[0])\n",
    "\n",
    "        return tensor\n",
    "            \n",
    "    # Create placeholders to accept the data sent to the model at serving time\n",
    "    feature_placeholders = { # all features come in as a batch of strings, shape = (batch_size,), this was so because of passing the arrays to online ml-engine prediction\n",
    "        feature: tf.placeholder(dtype = tf.string, shape = [None]) for feature in UNLABELED_CSV_COLUMNS\n",
    "    }\n",
    "    \n",
    "    # Create feature tensors\n",
    "    features = {key: fix_shape_and_type_for_serving(placeholder = tensor) for key, tensor in feature_placeholders.items()}\n",
    "    \n",
    "    # Fix dynamic shape ambiguity of feature tensors for our DNN\n",
    "    features = {key: get_shape_and_set_modified_shape_2D(tensor = tensor, additional_dimension_sizes = [sequence_length]) for key, tensor in features.items()}\n",
    "\n",
    "    return tf.estimator.export.ServingInputReceiver(features = features, receiver_tensors = feature_placeholders)\n",
    "\n",
    "# Create estimator to train and evaluate\n",
    "def train_and_evaluate(args):\n",
    "    # Create our custom estimator using our model function\n",
    "    estimator = tf.estimator.Estimator(\n",
    "        model_fn = lstm_encoder_decoder_autoencoder_anomaly_detection,\n",
    "        model_dir = args[\"output_dir\"],\n",
    "        params = {\n",
    "            \"sequence_length\": args[\"sequence_length\"],\n",
    "            \"reverse_labels_sequence\": args[\"reverse_labels_sequence\"],\n",
    "            \"encoder_lstm_hidden_units\": args[\"encoder_lstm_hidden_units\"],\n",
    "            \"decoder_lstm_hidden_units\": args[\"decoder_lstm_hidden_units\"],\n",
    "            \"lstm_dropout_output_keep_probs\": args[\"lstm_dropout_output_keep_probs\"], \n",
    "            \"dnn_hidden_units\": args[\"dnn_hidden_units\"], \n",
    "            \"learning_rate\": args[\"learning_rate\"],\n",
    "            \"evaluation_mode\": args[\"evaluation_mode\"],\n",
    "            \"time_anomaly_threshold\": args[\"time_anomaly_threshold\"], \n",
    "            \"features_anomaly_threshold\": args[\"features_anomaly_threshold\"],\n",
    "            \"eps\": args[\"eps\"],\n",
    "            \"f_score_beta\": args[\"f_score_beta\"]})\n",
    "    \n",
    "    if args[\"evaluation_mode\"] == \"reconstruction\":\n",
    "        early_stopping_hook = tf.contrib.estimator.stop_if_no_decrease_hook(\n",
    "            estimator = estimator,\n",
    "            metric_name = \"rmse\",\n",
    "            max_steps_without_decrease = 100,\n",
    "            min_steps = 1000,\n",
    "            run_every_secs = 60,\n",
    "            run_every_steps = None)\n",
    "\n",
    "        # Create train spec to read in our training data\n",
    "        train_spec = tf.estimator.TrainSpec(\n",
    "            input_fn = read_dataset(\n",
    "                filename = args[\"train_file_pattern\"],\n",
    "                mode = tf.estimator.ModeKeys.TRAIN, \n",
    "                batch_size = args[\"train_batch_size\"],\n",
    "                params = args),\n",
    "            max_steps = args[\"train_steps\"], \n",
    "            hooks = [early_stopping_hook])\n",
    "\n",
    "        # Create eval spec to read in our validation data and export our model\n",
    "        eval_spec = tf.estimator.EvalSpec(\n",
    "            input_fn = read_dataset(\n",
    "                filename = args[\"eval_file_pattern\"], \n",
    "                mode = tf.estimator.ModeKeys.EVAL, \n",
    "                batch_size = args[\"eval_batch_size\"],\n",
    "                params = args),\n",
    "            steps = None,\n",
    "            start_delay_secs = args[\"start_delay_secs\"], # start evaluating after N seconds\n",
    "            throttle_secs = args[\"throttle_secs\"])    # evaluate every N seconds\n",
    "\n",
    "        # Create train and evaluate loop to train and evaluate our estimator\n",
    "        tf.estimator.train_and_evaluate(estimator = estimator, train_spec = train_spec, eval_spec = eval_spec)\n",
    "    else:\n",
    "        if args[\"evaluation_mode\"] == \"calculate_error_distribution_statistics\":\n",
    "            # Get final mahalanobis statistics over the entire validation_1 dataset\n",
    "            estimator.train(\n",
    "                input_fn = read_dataset(\n",
    "                    filename = args[\"eval_file_pattern\"], \n",
    "                    mode = tf.estimator.ModeKeys.EVAL, \n",
    "                    batch_size = args[\"eval_batch_size\"],\n",
    "                    params = args),\n",
    "                steps = None)\n",
    "\n",
    "        elif args[\"evaluation_mode\"] == \"tune_anomaly_thresholds\":\n",
    "            # Tune anomaly thresholds using valdiation_2 and validation_anomaly datasets\n",
    "            estimator.evaluate(\n",
    "                input_fn = read_dataset(\n",
    "                    filename = args[\"eval_file_pattern\"], \n",
    "                    mode = tf.estimator.ModeKeys.EVAL, \n",
    "                    batch_size = args[\"eval_batch_size\"],\n",
    "                    params = args),\n",
    "                steps = None)\n",
    "\n",
    "        # Export savedmodel with learned error distribution statistics to be used for inference\n",
    "        estimator.export_savedmodel(\n",
    "            export_dir_base = args['output_dir'] + \"/export/exporter\", \n",
    "            serving_input_receiver_fn = lambda: serving_input_fn(args[\"sequence_length\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lstm_encoder_decoder_autoencoder_anomaly_detection_module/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lstm_encoder_decoder_autoencoder_anomaly_detection_module/trainer/task.py\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "from . import model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # File arguments\n",
    "    parser.add_argument(\n",
    "        \"--train_file_pattern\",\n",
    "        help = \"GCS location to read training data\",\n",
    "        required = True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--eval_file_pattern\",\n",
    "        help = \"GCS location to read evaluation data\",\n",
    "        required = True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output_dir\",\n",
    "        help = \"GCS location to write checkpoints and export models\",\n",
    "        required = True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--job-dir\",\n",
    "        help = \"this model ignores this field, but it is required by gcloud\",\n",
    "        default = \"junk\"\n",
    "    )\n",
    "    \n",
    "    # Sequence shape hyperparameters\n",
    "    parser.add_argument(\n",
    "        \"--sequence_length\",\n",
    "        help = \"Number of timesteps to include in each example\",\n",
    "        type = int,\n",
    "        default = 32\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--horizon\",\n",
    "        help = \"Number of timesteps to skip into the future\",\n",
    "        type = int,\n",
    "        default = 0\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--reverse_labels_sequence\",\n",
    "        help = \"Whether we should reverse the labels sequence dimension or not\",\n",
    "        type = bool,\n",
    "        default = True\n",
    "    )\n",
    "    \n",
    "    # Architecture hyperparameters\n",
    "    \n",
    "    # LSTM hyperparameters\n",
    "    parser.add_argument(\n",
    "        \"--shared_encoder_decoder_weights\",\n",
    "        help = \"Whether the weights are shared between the encoder and decoder or not\",\n",
    "        type = bool,\n",
    "        default = False\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--encoder_lstm_hidden_units\",\n",
    "        help = \"Hidden layer sizes to use for LSTM encoder\",\n",
    "        default = \"64 32 16\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--decoder_lstm_hidden_units\",\n",
    "        help = \"Hidden layer sizes to use for LSTM decoder\",\n",
    "        default = \"16 32 64\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lstm_dropout_output_keep_probs\",\n",
    "        help = \"Keep probabilties for LSTM outputs\",\n",
    "        default = \"1.0 1.0 1.0\"\n",
    "    )\n",
    "\n",
    "    # DNN hyperparameters\n",
    "    parser.add_argument(\n",
    "        \"--dnn_hidden_units\",\n",
    "        help = \"Hidden layer sizes to use for DNN\",\n",
    "        default = \"1024 256 64\"\n",
    "    )\n",
    "    \n",
    "    # Training parameters\n",
    "    parser.add_argument(\n",
    "        \"--train_batch_size\",\n",
    "        help = \"Number of examples in training batch\",\n",
    "        type = int,\n",
    "        default = 32\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--eval_batch_size\",\n",
    "        help = \"Number of examples in evaluation batch\",\n",
    "        type = int,\n",
    "        default = 32\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--train_steps\",\n",
    "        help = \"Number of batches to train for\",\n",
    "        type = int,\n",
    "        default = 2000\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--learning_rate\",\n",
    "        help = \"The learning rate, how quickly or slowly we train our model by scaling the gradient\",\n",
    "        type = float,\n",
    "        default = 0.1\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--start_delay_secs\",\n",
    "        help = \"Number of seconds to wait before first evaluation\",\n",
    "        type = int,\n",
    "        default = 60\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--throttle_secs\",\n",
    "        help = \"Number of seconds to wait between evaluations\",\n",
    "        type = int,\n",
    "        default = 120\n",
    "    )\n",
    "    \n",
    "    # Anomaly detection\n",
    "    parser.add_argument(\n",
    "        \"--evaluation_mode\",\n",
    "        help = \"Which evaluation mode we are in (reconstruction, calculate_error_distribution_statistics, tune_anomaly_thresholds)\",\n",
    "        type = str,\n",
    "        default = \"reconstruction\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--time_anomaly_threshold\",\n",
    "        help = \"The anomaly threshold in the time dimension\",\n",
    "        type = float,\n",
    "        default = 2000.0\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--features_anomaly_threshold\",\n",
    "        help = \"The anomaly threshold in the features dimension\",\n",
    "        type = float,\n",
    "        default = 75000.0\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--eps\",\n",
    "        help = \"The precision value to add to the covariance matrix before inversion to avoid being singular\",\n",
    "        type = str,\n",
    "        default = \"1e-12\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--f_score_beta\",\n",
    "        help = \"The value of beta of the f-beta score\",\n",
    "        type = float,\n",
    "        default = 0.05\n",
    "    )\n",
    "    \n",
    "    # Parse all arguments\n",
    "    args = parser.parse_args()\n",
    "    arguments = args.__dict__\n",
    "\n",
    "    # Unused args provided by service\n",
    "    arguments.pop(\"job_dir\", None)\n",
    "    arguments.pop(\"job-dir\", None)\n",
    "    \n",
    "    # Fix list arguments\n",
    "    arguments[\"encoder_lstm_hidden_units\"] = [int(x) for x in arguments[\"encoder_lstm_hidden_units\"].split(' ')]\n",
    "    arguments[\"decoder_lstm_hidden_units\"] = [int(x) for x in arguments[\"decoder_lstm_hidden_units\"].split(' ')]\n",
    "    arguments[\"lstm_dropout_output_keep_probs\"] = [float(x) for x in arguments[\"lstm_dropout_output_keep_probs\"].split(' ')]\n",
    "    arguments[\"dnn_hidden_units\"] = [int(x) for x in arguments[\"dnn_hidden_units\"].split(' ')]\n",
    "    \n",
    "    # Fix eps argument\n",
    "    arguments[\"eps\"] = float(arguments[\"eps\"])\n",
    "\n",
    "    # Append trial_id to path if we are doing hptuning\n",
    "    # This code can be removed if you are not using hyperparameter tuning\n",
    "    arguments[\"output_dir\"] = os.path.join(\n",
    "        arguments[\"output_dir\"],\n",
    "        json.loads(\n",
    "            os.environ.get(\"TF_CONFIG\", \"{}\")\n",
    "        ).get(\"task\", {}).get(\"trial\", \"\")\n",
    "    )\n",
    "\n",
    "    # Run the training job\n",
    "    model.train_and_evaluate(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train reconstruction variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: features = \n",
      "{'tag_0': <tf.Tensor 'IteratorGetNext:0' shape=(?, 30) dtype=float64>, 'tag_1': <tf.Tensor 'IteratorGetNext:1' shape=(?, 30) dtype=float64>, 'tag_2': <tf.Tensor 'IteratorGetNext:2' shape=(?, 30) dtype=float64>, 'tag_3': <tf.Tensor 'IteratorGetNext:3' shape=(?, 30) dtype=float64>, 'tag_4': <tf.Tensor 'IteratorGetNext:4' shape=(?, 30) dtype=float64>}\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: labels = \n",
      "None\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: mode = \n",
      "train\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: params = \n",
      "{'features_anomaly_threshold': 75000.0, 'f_score_beta': 0.05, 'time_anomaly_threshold': 2000.0, 'learning_rate': 0.1, 'dnn_hidden_units': [1024, 256, 64], 'decoder_lstm_hidden_units': [16, 32, 64], 'lstm_dropout_output_keep_probs': [0.9, 0.95, 1.0], 'encoder_lstm_hidden_units': [16, 32, 64], 'reverse_labels_sequence': True, 'sequence_length': 30, 'eps': 1e-12, 'evaluation_mode': 'reconstruction'}\n",
      "\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: features = \n",
      "{'tag_0': <tf.Tensor 'IteratorGetNext:0' shape=(?, 30) dtype=float64>, 'tag_1': <tf.Tensor 'IteratorGetNext:1' shape=(?, 30) dtype=float64>, 'tag_2': <tf.Tensor 'IteratorGetNext:2' shape=(?, 30) dtype=float64>, 'tag_3': <tf.Tensor 'IteratorGetNext:3' shape=(?, 30) dtype=float64>, 'tag_4': <tf.Tensor 'IteratorGetNext:4' shape=(?, 30) dtype=float64>}\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: labels = \n",
      "None\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: mode = \n",
      "eval\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: params = \n",
      "{'features_anomaly_threshold': 75000.0, 'f_score_beta': 0.05, 'time_anomaly_threshold': 2000.0, 'learning_rate': 0.1, 'dnn_hidden_units': [1024, 256, 64], 'decoder_lstm_hidden_units': [16, 32, 64], 'lstm_dropout_output_keep_probs': [0.9, 0.95, 1.0], 'encoder_lstm_hidden_units': [16, 32, 64], 'reverse_labels_sequence': True, 'sequence_length': 30, 'eps': 1e-12, 'evaluation_mode': 'reconstruction'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f33b15a0fd0>, '_model_dir': '/home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_lstm_encoder_decoder_autoencoder/trained_model/', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_lstm_encoder_decoder_autoencoder/lstm_encoder_decoder_autoencoder_anomaly_detection_module/trainer/model.py:127: __init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_lstm_encoder_decoder_autoencoder/lstm_encoder_decoder_autoencoder_anomaly_detection_module/trainer/model.py:136: __init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_lstm_encoder_decoder_autoencoder/lstm_encoder_decoder_autoencoder_anomaly_detection_module/trainer/model.py:153: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_lstm_encoder_decoder_autoencoder/lstm_encoder_decoder_autoencoder_anomaly_detection_module/trainer/model.py:162: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2019-04-10 05:28:21.995622: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2019-04-10 05:28:22.014318: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000185000 Hz\n",
      "2019-04-10 05:28:22.024732: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55f78a3f7ce0 executing computations on platform Host. Devices:\n",
      "2019-04-10 05:28:22.024781: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-04-10 05:28:22.035166: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_lstm_encoder_decoder_autoencoder/trained_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.9111769, step = 1\n",
      "INFO:tensorflow:global_step/sec: 2.20432\n",
      "INFO:tensorflow:loss = 1.8413659, step = 101 (45.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.19722\n",
      "INFO:tensorflow:loss = 1.6130838, step = 201 (12.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.81595\n",
      "INFO:tensorflow:loss = 1.589457, step = 301 (12.795 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.8597\n",
      "INFO:tensorflow:loss = 1.5942634, step = 401 (12.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.93334\n",
      "INFO:tensorflow:loss = 1.5805162, step = 501 (12.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.88014\n",
      "INFO:tensorflow:loss = 1.5876813, step = 601 (12.690 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.94381\n",
      "INFO:tensorflow:loss = 1.5981925, step = 701 (12.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.93645\n",
      "INFO:tensorflow:loss = 1.5776501, step = 801 (12.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.23456\n",
      "INFO:tensorflow:loss = 1.5858054, step = 901 (12.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.07508\n",
      "INFO:tensorflow:loss = 1.5933439, step = 1001 (12.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.2504\n",
      "INFO:tensorflow:loss = 1.5984393, step = 1101 (12.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.05135\n",
      "INFO:tensorflow:loss = 1.5827737, step = 1201 (12.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.1405\n",
      "INFO:tensorflow:loss = 1.5814137, step = 1301 (12.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.7226\n",
      "INFO:tensorflow:loss = 1.587075, step = 1401 (12.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.86142\n",
      "INFO:tensorflow:loss = 1.5800997, step = 1501 (12.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.93344\n",
      "INFO:tensorflow:loss = 1.577145, step = 1601 (12.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.95212\n",
      "INFO:tensorflow:loss = 1.5811185, step = 1701 (12.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.08286\n",
      "INFO:tensorflow:loss = 1.5923618, step = 1801 (12.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.09884\n",
      "INFO:tensorflow:loss = 1.5965233, step = 1901 (12.348 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_lstm_encoder_decoder_autoencoder/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-10T05:33:57Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_lstm_encoder_decoder_autoencoder/trained_model/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-10-05:34:20\n",
      "INFO:tensorflow:Saving dict for global step 2000: global_step = 2000, loss = 1.5925883, mae = 1.1139495, rmse = 1.2619779\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_lstm_encoder_decoder_autoencoder/trained_model/model.ckpt-2000\n",
      "INFO:tensorflow:Loss for final step: 1.6032159.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm -rf trained_model\n",
    "export PYTHONPATH=$PYTHONPATH:$PWD/lstm_encoder_decoder_autoencoder_anomaly_detection_module\n",
    "python -m trainer.task \\\n",
    "    --train_file_pattern=\"data/training_normal_sequences.csv\" \\\n",
    "    --eval_file_pattern=\"data/validation_normal_1_sequences.csv\" \\\n",
    "    --output_dir=$PWD/trained_model \\\n",
    "    --job-dir=./tmp \\\n",
    "    --sequence_length=30 \\\n",
    "    --horizon=0 \\\n",
    "    --reverse_labels_sequence=True \\\n",
    "    --encoder_lstm_hidden_units=\"64 32 16\" \\\n",
    "    --encoder_lstm_hidden_units=\"16 32 64\" \\\n",
    "    --lstm_dropout_output_keep_probs=\"0.9 0.95 1.0\" \\\n",
    "    --dnn_hidden_units=\"1024 256 64\" \\\n",
    "    --train_batch_size=32 \\\n",
    "    --eval_batch_size=32 \\\n",
    "    --train_steps=2000 \\\n",
    "    --learning_rate=0.1 \\\n",
    "    --start_delay_secs=60 \\\n",
    "    --throttle_secs=120 \\\n",
    "    --evaluation_mode=\"reconstruction\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train error distribution statistics variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: features = \n",
      "{'tag_0': <tf.Tensor 'IteratorGetNext:0' shape=(?, 30) dtype=float64>, 'tag_1': <tf.Tensor 'IteratorGetNext:1' shape=(?, 30) dtype=float64>, 'tag_2': <tf.Tensor 'IteratorGetNext:2' shape=(?, 30) dtype=float64>, 'tag_3': <tf.Tensor 'IteratorGetNext:3' shape=(?, 30) dtype=float64>, 'tag_4': <tf.Tensor 'IteratorGetNext:4' shape=(?, 30) dtype=float64>}\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: labels = \n",
      "None\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: mode = \n",
      "train\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: params = \n",
      "{'features_anomaly_threshold': 75000.0, 'f_score_beta': 0.05, 'time_anomaly_threshold': 2000.0, 'learning_rate': 0.1, 'dnn_hidden_units': [1024, 256, 64], 'decoder_lstm_hidden_units': [16, 32, 64], 'lstm_dropout_output_keep_probs': [0.9, 0.95, 1.0], 'encoder_lstm_hidden_units': [16, 32, 64], 'reverse_labels_sequence': True, 'sequence_length': 30, 'eps': 1e-12, 'evaluation_mode': 'calculate_error_distribution_statistics'}\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: features = \n",
      "{'tag_0': <tf.Tensor 'StringToNumber:0' shape=(?, 30) dtype=float64>, 'tag_1': <tf.Tensor 'StringToNumber_1:0' shape=(?, 30) dtype=float64>, 'tag_2': <tf.Tensor 'StringToNumber_2:0' shape=(?, 30) dtype=float64>, 'tag_3': <tf.Tensor 'StringToNumber_3:0' shape=(?, 30) dtype=float64>, 'tag_4': <tf.Tensor 'StringToNumber_4:0' shape=(?, 30) dtype=float64>}\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: labels = \n",
      "None\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: mode = \n",
      "infer\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: params = \n",
      "{'features_anomaly_threshold': 75000.0, 'f_score_beta': 0.05, 'time_anomaly_threshold': 2000.0, 'learning_rate': 0.1, 'dnn_hidden_units': [1024, 256, 64], 'decoder_lstm_hidden_units': [16, 32, 64], 'lstm_dropout_output_keep_probs': [0.9, 0.95, 1.0], 'encoder_lstm_hidden_units': [16, 32, 64], 'reverse_labels_sequence': True, 'sequence_length': 30, 'eps': 1e-12, 'evaluation_mode': 'calculate_error_distribution_statistics'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3edb3a5fd0>, '_model_dir': '/home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_lstm_encoder_decoder_autoencoder/trained_model/', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_lstm_encoder_decoder_autoencoder/lstm_encoder_decoder_autoencoder_anomaly_detection_module/trainer/model.py:127: __init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_lstm_encoder_decoder_autoencoder/lstm_encoder_decoder_autoencoder_anomaly_detection_module/trainer/model.py:136: __init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_lstm_encoder_decoder_autoencoder/lstm_encoder_decoder_autoencoder_anomaly_detection_module/trainer/model.py:153: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_lstm_encoder_decoder_autoencoder/lstm_encoder_decoder_autoencoder_anomaly_detection_module/trainer/model.py:162: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2019-04-10 05:34:29.307530: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2019-04-10 05:34:29.325575: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000185000 Hz\n",
      "2019-04-10 05:34:29.336389: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x558ce21078a0 executing computations on platform Host. Devices:\n",
      "2019-04-10 05:34:29.336416: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-04-10 05:34:29.347084: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_lstm_encoder_decoder_autoencoder/trained_model/model.ckpt-2000\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_lstm_encoder_decoder_autoencoder/trained_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0, step = 2001\n",
      "INFO:tensorflow:Saving checkpoints for 2001 into /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_lstm_encoder_decoder_autoencoder/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default', 'predict_export_outputs']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Restoring parameters from /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_lstm_encoder_decoder_autoencoder/trained_model/model.ckpt-2001\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_lstm_encoder_decoder_autoencoder/trained_model//export/exporter/temp-1554874480/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export PYTHONPATH=$PYTHONPATH:$PWD/lstm_encoder_decoder_autoencoder_anomaly_detection_module\n",
    "python -m trainer.task \\\n",
    "    --train_file_pattern=\"data/training_normal_sequences.csv\" \\\n",
    "    --eval_file_pattern=\"data/validation_normal_1_sequences.csv\" \\\n",
    "    --output_dir=$PWD/trained_model \\\n",
    "    --job-dir=./tmp \\\n",
    "    --sequence_length=30 \\\n",
    "    --horizon=0 \\\n",
    "    --reverse_labels_sequence=True \\\n",
    "    --encoder_lstm_hidden_units=\"64 32 16\" \\\n",
    "    --encoder_lstm_hidden_units=\"16 32 64\" \\\n",
    "    --lstm_dropout_output_keep_probs=\"0.9 0.95 1.0\" \\\n",
    "    --dnn_hidden_units=\"1024 256 64\" \\\n",
    "    --eval_batch_size=32 \\\n",
    "    --evaluation_mode=\"calculate_error_distribution_statistics\" \\\n",
    "    --eps=\"1e-12\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune anomaly thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export PYTHONPATH=$PYTHONPATH:$PWD/lstm_encoder_decoder_autoencoder_anomaly_detection_module\n",
    "python -m trainer.task \\\n",
    "    --train_file_pattern=\"data/training_normal_sequences.csv\" \\\n",
    "    --eval_file_pattern=\"data/labeled_validation_mixed_sequences.csv\" \\\n",
    "    --output_dir=$PWD/trained_model \\\n",
    "    --job-dir=./tmp \\\n",
    "    --sequence_length=30 \\\n",
    "    --horizon=0 \\\n",
    "    --reverse_labels_sequence=True \\\n",
    "    --encoder_lstm_hidden_units=\"64 32 16\" \\\n",
    "    --encoder_lstm_hidden_units=\"16 32 64\" \\\n",
    "    --lstm_dropout_output_keep_probs=\"0.9 0.95 1.0\" \\\n",
    "    --dnn_hidden_units=\"1024 256 64\" \\\n",
    "    --eval_batch_size=32 \\\n",
    "    --evaluation_mode=\"tune_anomaly_thresholds\" \\\n",
    "    --time_anomaly_threshold=2000.0 \\\n",
    "    --features_anomaly_threshold=75000.0 \\\n",
    "    --f_score_beta=0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy data over to bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://data/labeled_test_mixed_sequences.csv [Content-Type=text/csv]...\n",
      "Copying file://data/labeled_validation_mixed_sequences.csv [Content-Type=text/csv]...\n",
      "Copying file://data/training_normal_sequences.csv [Content-Type=text/csv]...\n",
      "Copying file://data/validation_normal_1_sequences.csv [Content-Type=text/csv]...\n",
      "\\\n",
      "Operation completed over 4 objects/158.4 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil -m cp -r data/* gs://$BUCKET/lstm_encoder_decoder_autoencoder_anomaly_detection/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train reconstruction variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://$BUCKET/lstm_encoder_decoder_autoencoder_anomaly_detection/trained_model\n",
    "JOBNAME=job_lstm_encoder_decoder_autoencoder_anomaly_detection_reconstruction_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "    --region=$REGION \\\n",
    "    --module-name=trainer.task \\\n",
    "    --package-path=$PWD/lstm_encoder_decoder_autoencoder_anomaly_detection_module/trainer \\\n",
    "    --job-dir=$OUTDIR \\\n",
    "    --staging-bucket=gs://$BUCKET \\\n",
    "    --scale-tier=STANDARD_1 \\\n",
    "    --runtime-version=1.13 \\\n",
    "    -- \\\n",
    "    --train_file_pattern=gs://$BUCKET/lstm_encoder_decoder_autoencoder_anomaly_detection/data/training_normal_sequences.csv \\\n",
    "    --eval_file_pattern=gs://$BUCKET/lstm_encoder_decoder_autoencoder_anomaly_detection/data/validation_normal_1_sequences.csv \\\n",
    "    --output_dir=$OUTDIR \\\n",
    "    --job-dir=$OUTDIR \\\n",
    "    --sequence_length=30 \\\n",
    "    --horizon=0 \\\n",
    "    --reverse_labels_sequence=True \\\n",
    "    --encoder_lstm_hidden_units=\"64 32 16\" \\\n",
    "    --encoder_lstm_hidden_units=\"16 32 64\" \\\n",
    "    --lstm_dropout_output_keep_probs=\"0.9 0.95 1.0\" \\\n",
    "    --dnn_hidden_units=\"1024 256 64\" \\\n",
    "    --train_batch_size=32 \\\n",
    "    --eval_batch_size=32 \\\n",
    "    --train_steps=2000 \\\n",
    "    --learning_rate=0.1 \\\n",
    "    --start_delay_secs=60 \\\n",
    "    --throttle_secs=120 \\\n",
    "    --evaluation_mode=\"reconstruction\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning of reconstruction hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hyperparam_reconstruction.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile hyperparam_reconstruction.yaml\n",
    "trainingInput:\n",
    "    scaleTier: STANDARD_1\n",
    "    hyperparameters:\n",
    "        hyperparameterMetricTag: rmse\n",
    "        goal: MINIMIZE\n",
    "        maxTrials: 30\n",
    "        maxParallelTrials: 1\n",
    "        params:\n",
    "        - parameterName: encoder_lstm_hidden_units\n",
    "          type: CATEGORICAL\n",
    "          categoricalValues: [\"64 32 16\", \"256 128 16\", \"64 64 64\"]\n",
    "        - parameterName: decoder_lstm_hidden_units\n",
    "          type: CATEGORICAL\n",
    "          categoricalValues: [\"64 32 16\", \"256 128 16\", \"64 64 64\"]\n",
    "        - parameterName: lstm_dropout_output_keep_probs\n",
    "          type: CATEGORICAL\n",
    "          categoricalValues: [\"0.9 1.0 1.0\", \"0.95 0.95 1.0\", \"0.95 0.95 0.95\"]\n",
    "        - parameterName: dnn_hidden_units\n",
    "          type: CATEGORICAL\n",
    "          categoricalValues: [\"256 128 64\", \"256 128 16\", \"64 64 64\"]\n",
    "        - parameterName: train_batch_size\n",
    "          type: INTEGER\n",
    "          minValue: 8\n",
    "          maxValue: 512\n",
    "          scaleType: UNIT_LOG_SCALE\n",
    "        - parameterName: learning_rate\n",
    "          type: DOUBLE\n",
    "          minValue: 0.001\n",
    "          maxValue: 0.1\n",
    "          scaleType: UNIT_LINEAR_SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://$BUCKET/lstm_encoder_decoder_autoencoder_anomaly_detection/hyperparam_reconstruction\n",
    "JOBNAME=job_lstm_encoder_decoder_autoencoder_anomaly_detection_hyperparam_reconstruction_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "    --region=$REGION \\\n",
    "    --module-name=trainer.task \\\n",
    "    --package-path=$PWD/lstm_encoder_decoder_autoencoder_anomaly_detection_module/trainer \\\n",
    "    --job-dir=$OUTDIR \\\n",
    "    --staging-bucket=gs://$BUCKET \\\n",
    "    --scale-tier=STANDARD_1 \\\n",
    "    --config=hyperparam_reconstruction.yaml \\\n",
    "    --runtime-version=1.13 \\\n",
    "    -- \\\n",
    "    --train_file_pattern=gs://$BUCKET/lstm_encoder_decoder_autoencoder_anomaly_detection/data/training_normal_sequences.csv \\\n",
    "    --eval_file_pattern=gs://$BUCKET/lstm_encoder_decoder_autoencoder_anomaly_detection/data/validation_normal_1_sequences.csv \\\n",
    "    --output_dir=$OUTDIR \\\n",
    "    --job-dir=$OUTDIR \\\n",
    "    --sequence_length=30 \\\n",
    "    --horizon=0 \\\n",
    "    --reverse_labels_sequence=True \\\n",
    "    --eval_batch_size=32 \\\n",
    "    --train_steps=2000 \\\n",
    "    --start_delay_secs=60 \\\n",
    "    --throttle_secs=120 \\\n",
    "    --evaluation_mode=\"reconstruction\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train error distribution variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://$BUCKET/lstm_encoder_decoder_autoencoder_anomaly_detection/trained_model\n",
    "JOBNAME=job_lstm_encoder_decoder_autoencoder_anomaly_detection_calculate_error_distribution_statistics_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "    --region=$REGION \\\n",
    "    --module-name=trainer.task \\\n",
    "    --package-path=$PWD/lstm_encoder_decoder_autoencoder_anomaly_detection_module/trainer \\\n",
    "    --job-dir=$OUTDIR \\\n",
    "    --staging-bucket=gs://$BUCKET \\\n",
    "    --scale-tier=STANDARD_1 \\\n",
    "    --runtime-version=1.13 \\\n",
    "    -- \\\n",
    "    --train_file_pattern=gs://$BUCKET/lstm_encoder_decoder_autoencoder_anomaly_detection/data/training_normal_sequences.csv \\\n",
    "    --eval_file_pattern=gs://$BUCKET/lstm_encoder_decoder_autoencoder_anomaly_detection/data/validation_normal_1_sequences.csv \\\n",
    "    --output_dir=$OUTDIR \\\n",
    "    --job-dir=$OUTDIR \\\n",
    "    --sequence_length=30 \\\n",
    "    --horizon=0 \\\n",
    "    --reverse_labels_sequence=True \\\n",
    "    --encoder_lstm_hidden_units=\"64 32 16\" \\\n",
    "    --encoder_lstm_hidden_units=\"16 32 64\" \\\n",
    "    --lstm_dropout_output_keep_probs=\"0.9 0.95 1.0\" \\\n",
    "    --dnn_hidden_units=\"1024 256 64\" \\\n",
    "    --eval_batch_size=32 \\\n",
    "    --evaluation_mode=\"calculate_error_distribution_statistics\" \\\n",
    "    --eps=\"1e-12\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune anomaly thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile hyperparam_tune_time_anomaly_threshold.yaml\n",
    "trainingInput:\n",
    "    scaleTier: STANDARD_1\n",
    "    hyperparameters:\n",
    "        hyperparameterMetricTag: batch_time_anomaly_f_beta_score\n",
    "        goal: MAXIMIZE\n",
    "        maxTrials: 30\n",
    "        maxParallelTrials: 1\n",
    "        params:\n",
    "        - parameterName: time_anomaly_threshold\n",
    "          type: DOUBLE\n",
    "          minValue: 0.0001\n",
    "          maxValue: 10000.0\n",
    "          scaleType: UNIT_LOG_SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://$BUCKET/lstm_encoder_decoder_autoencoder_anomaly_detection/hyperparam_tune_time_anomaly_threshold\n",
    "JOBNAME=job_lstm_encoder_decoder_autoencoder_anomaly_detection_hyperparam_tune_time_anomaly_threshold_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "    --region=$REGION \\\n",
    "    --module-name=trainer.task \\\n",
    "    --package-path=$PWD/lstm_encoder_decoder_autoencoder_anomaly_detection_module/trainer \\\n",
    "    --job-dir=$OUTDIR \\\n",
    "    --staging-bucket=gs://$BUCKET \\\n",
    "    --scale-tier=STANDARD_1 \\\n",
    "    --config=hyperparam_tune_anomaly_thresholds.yaml \\\n",
    "    --runtime-version=1.13 \\\n",
    "    -- \\\n",
    "    --train_file_pattern=gs://$BUCKET/lstm_encoder_decoder_autoencoder_anomaly_detection/data/training_normal_sequences.csv \\\n",
    "    --eval_file_pattern=gs://$BUCKET/lstm_encoder_decoder_autoencoder_anomaly_detection/data/labeled_validation_mixed_sequences.csv \\\n",
    "    --output_dir=$OUTDIR \\\n",
    "    --job-dir=$OUTDIR \\\n",
    "    --sequence_length=30 \\\n",
    "    --horizon=0 \\\n",
    "    --reverse_labels_sequence=True \\\n",
    "    --encoder_lstm_hidden_units=\"64 32 16\" \\\n",
    "    --encoder_lstm_hidden_units=\"16 32 64\" \\\n",
    "    --lstm_dropout_output_keep_probs=\"0.9 0.95 1.0\" \\\n",
    "    --dnn_hidden_units=\"1024 256 64\" \\\n",
    "    --eval_batch_size=32 \\\n",
    "    --evaluation_mode=\"tune_anomaly_thresholds\" \\\n",
    "    --features_anomaly_threshold=75000.0 \\\n",
    "    --f_score_beta=0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile hyperparam_tune_features_anomaly_threshold.yaml\n",
    "trainingInput:\n",
    "    scaleTier: STANDARD_1\n",
    "    hyperparameters:\n",
    "        hyperparameterMetricTag: batch_features_anomaly_f_beta_score\n",
    "        goal: MAXIMIZE\n",
    "        maxTrials: 30\n",
    "        maxParallelTrials: 1\n",
    "        params:\n",
    "        - parameterName: features_anomaly_threshold\n",
    "          type: DOUBLE\n",
    "          minValue: 0.0001\n",
    "          maxValue: 10000.0\n",
    "          scaleType: UNIT_LOG_SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://$BUCKET/lstm_encoder_decoder_autoencoder_anomaly_detection/hyperparam_tune_features_anomaly_threshold\n",
    "JOBNAME=job_lstm_encoder_decoder_autoencoder_anomaly_detection_hyperparam_tune_features_anomaly_threshold_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "    --region=$REGION \\\n",
    "    --module-name=trainer.task \\\n",
    "    --package-path=$PWD/lstm_encoder_decoder_autoencoder_anomaly_detection_module/trainer \\\n",
    "    --job-dir=$OUTDIR \\\n",
    "    --staging-bucket=gs://$BUCKET \\\n",
    "    --scale-tier=STANDARD_1 \\\n",
    "    --config=hyperparam_tune_features_anomaly_threshold.yaml \\\n",
    "    --runtime-version=1.13 \\\n",
    "    -- \\\n",
    "    --train_file_pattern=gs://$BUCKET/lstm_encoder_decoder_autoencoder_anomaly_detection/data/training_normal_sequences.csv \\\n",
    "    --eval_file_pattern=gs://$BUCKET/lstm_encoder_decoder_autoencoder_anomaly_detection/data/labeled_validation_mixed_sequences.csv \\\n",
    "    --output_dir=$OUTDIR \\\n",
    "    --job-dir=$OUTDIR \\\n",
    "    --sequence_length=30 \\\n",
    "    --horizon=0 \\\n",
    "    --reverse_labels_sequence=True \\\n",
    "    --encoder_lstm_hidden_units=\"64 32 16\" \\\n",
    "    --encoder_lstm_hidden_units=\"16 32 64\" \\\n",
    "    --lstm_dropout_output_keep_probs=\"0.9 0.95 1.0\" \\\n",
    "    --dnn_hidden_units=\"1024 256 64\" \\\n",
    "    --eval_batch_size=32 \\\n",
    "    --evaluation_mode=\"tune_anomaly_thresholds\" \\\n",
    "    --time_anomaly_threshold=2000.0 \\\n",
    "    --f_score_beta=0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil -m cp -r trained_model gs://qwiklabs-gcp-8923d4964bfbd247-bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bash\n",
    "MODEL_NAME=\"lstm_autoencoder_anomaly_detection\"\n",
    "MODEL_VERSION=\"v1\"\n",
    "MODEL_LOCATION=$(gsutil ls gs://$BUCKET/trained_model/export/exporter/ | tail -1)\n",
    "echo \"Deleting and deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION ... this will take a few minutes\"\n",
    "#gcloud ml-engine versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#gcloud ml-engine models delete ${MODEL_NAME}\n",
    "gcloud ml-engine models create $MODEL_NAME --regions $REGION\n",
    "gcloud ml-engine versions create $MODEL_VERSION --model $MODEL_NAME --origin $MODEL_LOCATION --runtime-version 1.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_prediction_instances = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local prediction from local model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_normal_sequences.json', 'w') as outfile:\n",
    "    test_data_normal_string_list = [[np.array2string(a = create_time_series_normal(1, sequence_length, tag[\"normal_freq\"], tag[\"normal_ampl\"], tag[\"normal_noise_noise_scale\"]), separator = ',').replace('[','').replace(']','').replace('\\n','') for tag in tag_data_list] for _ in range(0, number_of_prediction_instances)]\n",
    "    json_string = \"\"\n",
    "    for item in test_data_normal_string_list:\n",
    "        json_string += \"{\" + ','.join([\"{0}: \\\"{1}\\\"\".format('\\\"' + UNLABELED_CSV_COLUMNS[i] + '\\\"', item[i]) for i in range(0, len(UNLABELED_CSV_COLUMNS))]) + \"}\\n\"\n",
    "    json_string = json_string.replace(' ', '').replace(':', ': ').replace(',', ', ')\n",
    "    outfile.write(\"%s\" % json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ABSOLUTE_ERROR                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 BATCH_FEATURES_ANOMALY_FLAGS  BATCH_TIME_ANOMALY_FLAGS  ERROR                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    MAHALANOBIS_DISTANCE_BATCH_FEATURES                                                                MAHALANOBIS_DISTANCE_BATCH_TIME                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         PREDICTIONS\n",
      "[[-1.00542476, -0.80659477, -0.863632, -0.06218953, 1.34446305], [0.5791379, -0.44926299, -0.34960704, 1.7527995, 2.46647433], [2.44701721, 1.72038184, 1.32268634, 2.57702716, -0.1505987], [2.37662031, 2.1505015, 2.35295452, 0.0395941, -0.89381772], [0.4987903, 1.17655914, 1.28742723, -1.27622388, 0.04082778], [-1.30587561, -0.62755107, -0.64741672, -0.62503252, 2.05748674], [-1.37962954, -1.01325365, -0.70222667, 1.64900466, 1.26110649], [0.05718497, -0.27739165, -0.0607577, 2.71471361, -1.00933612], [1.54758718, 1.39959878, 1.28630927, 1.27798027, -0.91660261], [1.83539282, 2.14231792, 2.55282537, -0.84602868, 1.06605767], [0.80103775, 1.89897051, 1.47139389, -1.1099036, 2.20313179], [-1.08580883, 0.46651657, 0.29896119, 1.14750917, 0.27565898], [-0.78470049, -0.60737722, -1.62283648, 2.72877966, -1.10532172], [-0.33559951, -0.25302361, -0.63422243, 1.5843356, 0.27910334], [1.70933282, 1.13967581, 1.23270704, -1.22950356, 2.120885], [2.31554561, 2.36154313, 2.25536851, -0.97188948, 1.30186417], [1.19058366, 1.28555213, 2.0557272, 0.84424848, -0.71000747], [-0.15614869, 0.51141361, 0.52122173, 2.1288792, -1.23016101], [-1.09502632, -0.96854619, -1.35073168, 1.65079887, 1.04886259], [-0.68183885, -0.69845285, -0.94631936, -0.42894472, 2.66494313], [1.11268429, 1.22420356, 0.43990695, -1.55604133, 0.3153771], [2.45975441, 1.57383086, 1.89031173, -0.25704996, -1.19988146], [1.50723295, 1.86955997, 1.90574906, 2.21610573, -0.17752344], [0.10662803, -0.02193986, 0.52550401, 1.7078918, 1.8245427], [-1.38062917, -0.8019265, -1.04002518, 0.00450445, 1.34184942], [-0.677721, -0.65794589, -0.89693593, -1.74349225, -0.83753742], [0.36740034, 0.48404318, 0.27137785, -0.67546625, -0.87228221], [2.37434047, 2.12454032, 1.56377386, 1.82657432, 1.52223311], [1.98434751, 2.17238408, 2.2866051, 2.76322235, 2.60923185], [0.66213253, 0.664204, 0.65008303, 0.0676919, 0.89457022]]  [[1.5680426805800038, 1.3247799652773606, 1.3843544920650355, 0.6379324766210092, 0.7603397921198526], [0.016519979419996056, 0.9674481852773604, 0.8703295320650355, 1.177056553378991, 1.8823510721198526], [1.884399289419996, 1.2021966447226395, 0.8019638479349644, 2.001284213378991, 0.7347219578801475], [1.814002389419996, 1.6323163047226394, 1.8322320279349644, 0.5361488466210091, 1.4779409778801476], [0.06382762058000391, 0.6583739447226394, 0.7667047379349645, 1.8519668266210092, 0.5432954778801475], [1.868493530580004, 1.1457362652773604, 1.1681392120650353, 1.200775466621009, 1.4733634821198525], [1.942247460580004, 1.5314388452773606, 1.2229491620650355, 1.0732617133789908, 0.6769832321198525], [0.5054329505800039, 0.7955768452773605, 0.5814801920650355, 2.138970663378991, 1.5934593778801474], [0.9849692594199961, 0.8814135847226395, 0.7655867779349645, 0.7022373233789909, 1.5007258678801474], [1.272774899419996, 1.6241327247226396, 2.0321028779349644, 1.421771626621009, 0.48193441211985244], [0.23841982941999607, 1.3807853147226394, 0.9506713979349646, 1.685646546621009, 1.6190085321198526], [1.6484267505800039, 0.05166862527736049, 0.22176130206503553, 0.5717662233789909, 0.3084642778801475], [1.3473184105800038, 1.1255624152773605, 2.143558972065035, 2.1530367133789907, 1.6894449778801475], [0.8982174305800039, 0.7712088052773605, 1.1549449220650354, 1.0085926533789908, 0.30501991788014754], [1.146714899419996, 0.6214906147226394, 0.7119845479349645, 1.805246506621009, 1.5367617421198525], [1.752927689419996, 1.8433579347226394, 1.7346460179349643, 1.547632426621009, 0.7177409121198525], [0.627965739419996, 0.7673669347226394, 1.5350047079349647, 0.26850553337899086, 1.2941307278801475], [0.7187666105800039, 0.006771585277360548, 0.0004992379349645359, 1.553136253378991, 1.8142842678801476], [1.657644240580004, 1.4867313852773605, 1.8714541720650355, 1.075055923378991, 0.4647393321198524], [1.2444567705800038, 1.2166380452773606, 1.4670418520650355, 1.0046876666210092, 2.0808198721198528], [0.5500663694199961, 0.7060183647226396, 0.0808155420650355, 2.1317842766210093, 0.2687461578801475], [1.897136489419996, 1.0556456647226393, 1.3695892379349646, 0.8327929066210091, 1.7840047178801477], [0.944615029419996, 1.3513747747226397, 1.3850265679349645, 1.640362783378991, 0.7616466978801475], [0.45598989058000394, 0.5401250552773605, 0.004781517934964508, 1.132148853378991, 1.2404194421198524], [1.9432470905800039, 1.3201116952773604, 1.5607476720650355, 0.5712384966210091, 0.7577261621198524], [1.240338920580004, 1.1761310852773605, 1.4176584220650357, 2.319235196621009, 1.4216606778801475], [0.19521758058000394, 0.03414201527736049, 0.24934464206503554, 1.251209196621009, 1.4564054678801475], [1.811722549419996, 1.6063551247226395, 1.0430513679349644, 1.2508313733789909, 0.9381098521198524], [1.4217295894199962, 1.6541988847226397, 1.7658826079349645, 2.187479403378991, 2.0251085921198526], [0.09951460941999613, 0.1460188047226395, 0.1293605379349645, 0.5080510466210091, 0.31044696211985245]]  0                             0                         [[-1.5680426805800038, -1.3247799652773606, -1.3843544920650355, -0.6379324766210092, 0.7603397921198526], [0.016519979419996056, -0.9674481852773604, -0.8703295320650355, 1.177056553378991, 1.8823510721198526], [1.884399289419996, 1.2021966447226395, 0.8019638479349644, 2.001284213378991, -0.7347219578801475], [1.814002389419996, 1.6323163047226394, 1.8322320279349644, -0.5361488466210091, -1.4779409778801476], [-0.06382762058000391, 0.6583739447226394, 0.7667047379349645, -1.8519668266210092, -0.5432954778801475], [-1.868493530580004, -1.1457362652773604, -1.1681392120650353, -1.200775466621009, 1.4733634821198525], [-1.942247460580004, -1.5314388452773606, -1.2229491620650355, 1.0732617133789908, 0.6769832321198525], [-0.5054329505800039, -0.7955768452773605, -0.5814801920650355, 2.138970663378991, -1.5934593778801474], [0.9849692594199961, 0.8814135847226395, 0.7655867779349645, 0.7022373233789909, -1.5007258678801474], [1.272774899419996, 1.6241327247226396, 2.0321028779349644, -1.421771626621009, 0.48193441211985244], [0.23841982941999607, 1.3807853147226394, 0.9506713979349646, -1.685646546621009, 1.6190085321198526], [-1.6484267505800039, -0.05166862527736049, -0.22176130206503553, 0.5717662233789909, -0.3084642778801475], [-1.3473184105800038, -1.1255624152773605, -2.143558972065035, 2.1530367133789907, -1.6894449778801475], [-0.8982174305800039, -0.7712088052773605, -1.1549449220650354, 1.0085926533789908, -0.30501991788014754], [1.146714899419996, 0.6214906147226394, 0.7119845479349645, -1.805246506621009, 1.5367617421198525], [1.752927689419996, 1.8433579347226394, 1.7346460179349643, -1.547632426621009, 0.7177409121198525], [0.627965739419996, 0.7673669347226394, 1.5350047079349647, 0.26850553337899086, -1.2941307278801475], [-0.7187666105800039, -0.006771585277360548, 0.0004992379349645359, 1.553136253378991, -1.8142842678801476], [-1.657644240580004, -1.4867313852773605, -1.8714541720650355, 1.075055923378991, 0.4647393321198524], [-1.2444567705800038, -1.2166380452773606, -1.4670418520650355, -1.0046876666210092, 2.0808198721198528], [0.5500663694199961, 0.7060183647226396, -0.0808155420650355, -2.1317842766210093, -0.2687461578801475], [1.897136489419996, 1.0556456647226393, 1.3695892379349646, -0.8327929066210091, -1.7840047178801477], [0.944615029419996, 1.3513747747226397, 1.3850265679349645, 1.640362783378991, -0.7616466978801475], [-0.45598989058000394, -0.5401250552773605, 0.004781517934964508, 1.132148853378991, 1.2404194421198524], [-1.9432470905800039, -1.3201116952773604, -1.5607476720650355, -0.5712384966210091, 0.7577261621198524], [-1.240338920580004, -1.1761310852773605, -1.4176584220650357, -2.319235196621009, -1.4216606778801475], [-0.19521758058000394, -0.03414201527736049, -0.24934464206503554, -1.251209196621009, -1.4564054678801475], [1.811722549419996, 1.6063551247226395, 1.0430513679349644, 1.2508313733789909, 0.9381098521198524], [1.4217295894199962, 1.6541988847226397, 1.7658826079349645, 2.187479403378991, 2.0251085921198526], [0.09951460941999613, 0.1460188047226395, 0.1293605379349645, -0.5080510466210091, 0.31044696211985245]]  [29.388805030682306, 37.0453116696118, 35.740892577809724, 32.06299273265436, 22.888825893778424]  [1.6589216354095775, 5.707162298952486, 6.0981483528936415, 3.1974839930188854, 4.831225521905395, 2.1265395413389236, 3.2051972898657293, 4.046931021313496, 1.2240701045190672, 4.816694463666432, 6.129059874961011, 10.10071543841429, 10.638074861594722, 2.761297875836471, 2.3945826123160683, 3.2192933065675224, 7.034664298010864, 5.960590912140129, 3.509761450020633, 2.94458863373729, 8.406827243866822, 3.6537084399715236, 1.8327584521246831, 4.292469842419103, 3.1861370107368936, 3.994238214476774, 3.925818547287939, 3.7787301207896413, 6.17238148330048, 6.7822669559866124]  [[0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: 2019-04-10 06:23:25.642854: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2019-04-10 06:23:25.660938: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000185000 Hz\n",
      "2019-04-10 06:23:25.674410: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5557572635b0 executing computations on platform Host. Devices:\n",
      "2019-04-10 06:23:25.674475: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-04-10 06:23:25.685890: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "WARNING:tensorflow:From /usr/lib/google-cloud-sdk/lib/third_party/ml_sdk/cloud/ml/prediction/frameworks/tf_prediction_lib.py:210: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /usr/lib/google-cloud-sdk/lib/third_party/ml_sdk/cloud/ml/prediction/frameworks/tf_prediction_lib.py:210: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "model_dir=$(ls ${PWD}/trained_model/export/exporter | tail -1)\n",
    "gcloud ml-engine local predict \\\n",
    "    --model-dir=${PWD}/trained_model/export/exporter/${model_dir} \\\n",
    "    --json-instances=./test_normal_sequences.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anomalous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_anomalous_sequences.json', 'w') as outfile:\n",
    "    test_data_anomalous_string_list = [[np.array2string(a = create_time_series_with_anomaly(1, sequence_length, percent_sequence_before_anomaly, percent_sequence_after_anomaly, tag[\"normal_freq\"], tag[\"normal_ampl\"], tag[\"normal_noise_noise_scale\"]), separator = ',').replace('[','').replace(']','').replace('\\n','') for tag in tag_data_list] for _ in range(0, number_of_prediction_instances)]\n",
    "    json_string = \"\"\n",
    "    for item in test_data_anomalous_string_list:\n",
    "        json_string += \"{\" + ','.join([\"{0}: \\\"{1}\\\"\".format('\\\"' + UNLABELED_CSV_COLUMNS[i] + '\\\"', item[i]) for i in range(0, len(UNLABELED_CSV_COLUMNS))]) + \"}\\n\"\n",
    "    json_string = json_string.replace(' ', '').replace(':', ': ').replace(',', ', ')\n",
    "    outfile.write(\"%s\" % json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ABSOLUTE_ERROR                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                BATCH_FEATURES_ANOMALY_FLAGS  BATCH_TIME_ANOMALY_FLAGS  ERROR                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              MAHALANOBIS_DISTANCE_BATCH_FEATURES                                                              MAHALANOBIS_DISTANCE_BATCH_TIME                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      PREDICTIONS\n",
      "[[11.15751827, -15.39047699, 18.06461049, -2.33977672, -35.79293626], [-3.8295192, 0.84845152, 4.05186032, -37.02003993, 24.66924978], [-46.60177104, 9.56122178, 16.0067456, -20.26199183, 4.95731481], [24.65303587, 32.36718599, -32.13556266, 1.1789842, 16.86799848], [16.12771128, -33.88720783, 22.03188644, 19.93017232, 0.4578454], [-10.95970496, 5.31091799, -4.35823812, 5.8996958, 39.28728767], [9.34919443, -16.0211988, -11.78055316, 32.86008994, 11.95918414], [7.64346221, -0.80705365, 2.81560508, -31.67056061, 22.62000569], [19.86494186, -11.71548837, -25.71213634, -5.1159086, -9.07653393], [1.8026461, 2.03923858, 1.85550013, -1.60172966, 1.74363838], [0.73087901, 1.84455022, 1.90271058, -0.86402398, 2.16137631], [-0.75078106, -0.10040018, -0.28023339, 1.35846126, 0.17016136], [-0.96105426, -1.06086057, -1.1826531, 2.69407456, -1.30840777], [-0.21231337, -0.94459496, -0.16786537, 1.54952591, 0.57912332], [1.81365284, 0.69958131, 0.94081789, -0.84922299, 2.63955208], [2.54260275, 2.19437306, 2.35862775, -1.65633559, 1.75202168], [0.89994427, 1.66119535, 1.72727681, 0.93995863, -1.19209882], [-0.08532251, -0.11757814, 0.35883522, 1.84545308, -1.27825367], [-1.29366455, -0.8351315, -0.98329435, 1.85347249, 1.44577597], [-0.77971492, -0.33240489, -0.5891476, -0.10436849, 1.84570786], [0.73083258, 0.7449845, 0.7862736, -1.40960045, 0.0611455], [2.17576892, 1.51041511, 2.00817316, 0.24110457, -1.05215503], [2.07376817, 2.09487284, 2.21824615, 2.46171096, -0.20057679], [0.55796395, 0.16997901, 0.043472, 1.92728949, 1.9635417], [-0.97892529, -0.95587407, -0.88707246, -0.30554934, 1.96905962], [-1.08381342, -0.86473477, -1.38345867, -0.97024315, -1.19113887], [0.90326878, 0.79422282, 0.50922924, -0.62399678, -0.74946961], [2.09003521, 2.14647851, 2.21014048, 1.75931706, 1.40900358], [2.34974845, 1.87394614, 2.13097907, 1.96274729, 1.95604485], [0.6235627, 0.61201549, 0.92578522, 0.40244964, 0.75313514]]  [[10.594900349419996, 15.908662185277361, 17.543887997934963, 2.9155196666210093, 36.37705951788015], [4.392137120580004, 0.3302663247226395, 3.531137827934965, 37.595782876621016, 24.085126522119854], [47.164388960580006, 9.043036584722639, 15.486023107934964, 20.83773477662101, 4.373191552119852], [24.090417949419997, 31.84900079472264, 32.65628515206503, 0.6032412533789908, 16.283875222119853], [15.565093359419995, 34.40539302527736, 21.511163947934964, 19.35442937337899, 0.1262778578801475], [11.522322880580004, 4.79273279472264, 4.878960612065036, 5.323952853378991, 38.70316441211985], [8.786576509419996, 16.539383995277362, 12.301275652065035, 32.28434699337899, 11.375060882119852], [7.080844289419996, 1.3252388452773605, 2.2948825879349646, 32.24630355662101, 22.035882432119852], [19.302323939419995, 12.23367356527736, 26.232858832065038, 5.691651546621009, 9.660657187880147], [1.240028179419996, 1.5210533847226397, 1.3347776379349645, 2.1774726066210093, 1.1595151221198523], [0.16826108941999607, 1.3263650247226395, 1.3819880879349644, 1.4397669266210091, 1.5772530521198527], [1.313398980580004, 0.6185853752773605, 0.8009558820650355, 0.7827183133789908, 0.4139618978801475], [1.523672180580004, 1.5790457652773604, 1.7033755920650355, 2.1183316133789907, 1.8925310278801475], [0.7749312905800039, 1.4627801552773605, 0.6885878620650355, 0.973782963378991, 0.00499993788014752], [1.2510349194199961, 0.1813961147226395, 0.42009539793496453, 1.424965936621009, 2.0554288221198527], [1.979984829419996, 1.6761878647226398, 1.8379052579349646, 2.2320785366210094, 1.1678984221198525], [0.33732634941999606, 1.1430101547226394, 1.2065543179349645, 0.3642156833789909, 1.7762220778801474], [0.647940430580004, 0.6357633352773605, 0.1618872720650355, 1.2697101333789909, 1.8623769278801476], [1.8562824705800038, 1.3533166952773605, 1.5040168420650355, 1.2777295433789908, 0.8616527121198524], [1.342332840580004, 0.8505900852773605, 1.1098700920650355, 0.6801114366210091, 1.2615846021198527], [0.16821465941999603, 0.22679930472263954, 0.2655511079349645, 1.985343396621009, 0.5229777578801476], [1.613150999419996, 0.9922299147226395, 1.4874506679349646, 0.33463837662100915, 1.6362782878801476], [1.5111502494199962, 1.5766876447226394, 1.6975236579349646, 1.885968013378991, 0.7847000478801476], [0.004653970580003941, 0.34820618527736047, 0.4772504920650355, 1.3515465433789908, 1.3794184421198525], [1.541543210580004, 1.4740592652773605, 1.4077949520650355, 0.8812922866210091, 1.3849363621198525], [1.646431340580004, 1.3829199652773605, 1.9041811620650355, 1.545986096621009, 1.7752621278801475], [0.34065085941999607, 0.2760376247226395, 0.011493252065035486, 1.1997397266210093, 1.3335928678801476], [1.527417289419996, 1.6282933147226397, 1.6894179879349647, 1.183574113378991, 0.8248803221198525], [1.787130529419996, 1.3557609447226393, 1.6102565779349645, 1.387004343378991, 1.3719215921198527], [0.0609447794199961, 0.09383029472263948, 0.40506272793496445, 0.1732933066210091, 0.16901188211985252]]  0                             1                         [[10.594900349419996, -15.908662185277361, 17.543887997934963, -2.9155196666210093, -36.37705951788015], [-4.392137120580004, 0.3302663247226395, 3.531137827934965, -37.595782876621016, 24.085126522119854], [-47.164388960580006, 9.043036584722639, 15.486023107934964, -20.83773477662101, 4.373191552119852], [24.090417949419997, 31.84900079472264, -32.65628515206503, 0.6032412533789908, 16.283875222119853], [15.565093359419995, -34.40539302527736, 21.511163947934964, 19.35442937337899, -0.1262778578801475], [-11.522322880580004, 4.79273279472264, -4.878960612065036, 5.323952853378991, 38.70316441211985], [8.786576509419996, -16.539383995277362, -12.301275652065035, 32.28434699337899, 11.375060882119852], [7.080844289419996, -1.3252388452773605, 2.2948825879349646, -32.24630355662101, 22.035882432119852], [19.302323939419995, -12.23367356527736, -26.232858832065038, -5.691651546621009, -9.660657187880147], [1.240028179419996, 1.5210533847226397, 1.3347776379349645, -2.1774726066210093, 1.1595151221198523], [0.16826108941999607, 1.3263650247226395, 1.3819880879349644, -1.4397669266210091, 1.5772530521198527], [-1.313398980580004, -0.6185853752773605, -0.8009558820650355, 0.7827183133789908, -0.4139618978801475], [-1.523672180580004, -1.5790457652773604, -1.7033755920650355, 2.1183316133789907, -1.8925310278801475], [-0.7749312905800039, -1.4627801552773605, -0.6885878620650355, 0.973782963378991, -0.00499993788014752], [1.2510349194199961, 0.1813961147226395, 0.42009539793496453, -1.424965936621009, 2.0554288221198527], [1.979984829419996, 1.6761878647226398, 1.8379052579349646, -2.2320785366210094, 1.1678984221198525], [0.33732634941999606, 1.1430101547226394, 1.2065543179349645, 0.3642156833789909, -1.7762220778801474], [-0.647940430580004, -0.6357633352773605, -0.1618872720650355, 1.2697101333789909, -1.8623769278801476], [-1.8562824705800038, -1.3533166952773605, -1.5040168420650355, 1.2777295433789908, 0.8616527121198524], [-1.342332840580004, -0.8505900852773605, -1.1098700920650355, -0.6801114366210091, 1.2615846021198527], [0.16821465941999603, 0.22679930472263954, 0.2655511079349645, -1.985343396621009, -0.5229777578801476], [1.613150999419996, 0.9922299147226395, 1.4874506679349646, -0.33463837662100915, -1.6362782878801476], [1.5111502494199962, 1.5766876447226394, 1.6975236579349646, 1.885968013378991, -0.7847000478801476], [-0.004653970580003941, -0.34820618527736047, -0.4772504920650355, 1.3515465433789908, 1.3794184421198525], [-1.541543210580004, -1.4740592652773605, -1.4077949520650355, -0.8812922866210091, 1.3849363621198525], [-1.646431340580004, -1.3829199652773605, -1.9041811620650355, -1.545986096621009, -1.7752621278801475], [0.34065085941999607, 0.2760376247226395, -0.011493252065035486, -1.1997397266210093, -1.3335928678801476], [1.527417289419996, 1.6282933147226397, 1.6894179879349647, 1.183574113378991, 0.8248803221198525], [1.787130529419996, 1.3557609447226393, 1.6102565779349645, 1.387004343378991, 1.3719215921198527], [0.0609447794199961, 0.09383029472263948, 0.40506272793496445, -0.1732933066210091, 0.16901188211985252]]  [44532.97484873796, 42967.39482746566, 39785.48890299559, 49654.3920111242, 47405.557450438304]  [4013.6249130424626, 5027.4524851809165, 8260.352489789773, 3961.545527980861, 4691.391408647211, 4085.7325071786004, 3485.65442714074, 3918.0526737985924, 2830.4327394712122, 3.4112305577191493, 6.004189375817766, 2.8174439484746796, 5.0246136289433405, 8.97188415086112, 6.590044534251363, 5.659820829569056, 6.111038102599768, 4.478925685697061, 1.811949757261107, 1.21126914534459, 5.181323362357681, 4.267071275506415, 2.9597301600103663, 3.5956633256688915, 1.04083818057307, 4.268232908973347, 3.6796516278738607, 1.6872961733701828, 1.8643569787931575, 9.238181057008427]  [[0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475], [0.5626179205800039, 0.5181851952773605, 0.5207224920650355, 0.5757429466210091, 0.5841232578801475]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: 2019-04-10 06:32:35.687069: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2019-04-10 06:32:35.704725: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000185000 Hz\n",
      "2019-04-10 06:32:35.716004: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x56449b292850 executing computations on platform Host. Devices:\n",
      "2019-04-10 06:32:35.716040: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-04-10 06:32:35.725678: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "WARNING:tensorflow:From /usr/lib/google-cloud-sdk/lib/third_party/ml_sdk/cloud/ml/prediction/frameworks/tf_prediction_lib.py:210: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /usr/lib/google-cloud-sdk/lib/third_party/ml_sdk/cloud/ml/prediction/frameworks/tf_prediction_lib.py:210: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "model_dir=$(ls ${PWD}/trained_model/export/exporter | tail -1)\n",
    "gcloud ml-engine local predict \\\n",
    "    --model-dir=${PWD}/trained_model/export/exporter/${model_dir} \\\n",
    "    --json-instances=./test_anomalous_sequences.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCloud ML-Engine prediction from deployed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format dataframe to instances list to get sent to ML-Engine\n",
    "instances = [{column: np.array2string(a = create_time_series_with_anomaly(1, sequence_length, percent_sequence_before_anomaly, percent_sequence_after_anomaly, tag[\"clean_freq\"], tag[\"clean_ampl\"], tag[\"clean_noise_noise_scale\"]), separator = ',').replace('[','').replace(']','').replace('\\n','') for tag in tag_data_list for column in CSV_COLUMNS} for _ in range(0, number_of_prediction_instances)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send instance dictionary to receive response from ML-Engine for online prediction\n",
    "from googleapiclient import discovery\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import json\n",
    "\n",
    "credentials = GoogleCredentials.get_application_default()\n",
    "api = discovery.build('ml', 'v1', credentials = credentials)\n",
    "\n",
    "request_data = {\"instances\": instances}\n",
    "\n",
    "parent = 'projects/%s/models/%s/versions/%s' % (PROJECT, 'lstm_autoencoder_anomaly_detection', 'v1')\n",
    "response = api.projects().predict(body = request_data, name = parent).execute()\n",
    "print(\"response = {}\".format(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
