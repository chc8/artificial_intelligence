{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "1.16.2\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and modules\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import shutil\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "np.set_printoptions(threshold = np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow==1.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.enable_eager_execution()\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# BUCKET = 'qwiklabs-gcp-8923d4964bfbd247-bucket' # REPLACE WITH A BUCKET NAME (PUT YOUR PROJECT ID AND WE CREATE THE BUCKET ITSELF NEXT)\n",
    "# PROJECT = 'qwiklabs-gcp-8923d4964bfbd247' # REPLACE WITH YOUR PROJECT ID\n",
    "# REGION = 'us-central1' # REPLACE WITH YOUR REGION e.g. us-central1\n",
    "\n",
    "# # Import os environment variables\n",
    "# os.environ['PROJECT'] = PROJECT\n",
    "# os.environ['BUCKET'] =  BUCKET\n",
    "# os.environ['REGION'] = REGION\n",
    "# os.environ['TFVERSION'] = '1.8'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_sequence_before_anomaly = 80.0\n",
    "percent_sequence_after_anomaly = 0.0\n",
    "\n",
    "def create_time_series_normal_parameters():\n",
    "    normal_frequency_noise_scale = 0.1\n",
    "    normal_frequence_noise_shift = 0.0\n",
    "\n",
    "    normal_amplitude_noise_scale = 1.0\n",
    "    normal_amplitude_noise_shift = 1.0\n",
    "\n",
    "    normal_noise_noise_scale = 0.2\n",
    "\n",
    "    normal_freq = (np.random.random() * normal_frequency_noise_scale) + normal_frequence_noise_shift\n",
    "    normal_ampl = np.random.random() * normal_amplitude_noise_scale + normal_amplitude_noise_shift\n",
    "\n",
    "    return {\"normal_freq\": normal_freq, \"normal_ampl\": normal_ampl, \"normal_noise_noise_scale\": normal_noise_noise_scale}\n",
    "  \n",
    "\n",
    "def create_time_series_normal(number_of_sequences, sequence_length, normal_freq, normal_ampl, normal_noise_noise_scale):\n",
    "    # Normal parameters\n",
    "    normal_noise = [np.random.random() * normal_noise_noise_scale for i in range(0, number_of_sequences * sequence_length)]\n",
    "\n",
    "    sequence = np.sin(np.arange(0, number_of_sequences * sequence_length) * normal_freq) * normal_ampl + normal_noise\n",
    "\n",
    "    sequence = sequence.reshape(number_of_sequences, sequence_length)\n",
    "\n",
    "    return sequence\n",
    "\n",
    "def create_time_series_with_anomaly(number_of_sequences, sequence_length, percent_sequence_before_anomaly, percent_sequence_after_anomaly, normal_freq, normal_ampl, normal_noise_noise_scale):\n",
    "    sequence_length_before_anomaly = int(sequence_length * percent_sequence_before_anomaly / 100.0)\n",
    "    sequence_length_after_anomaly = int(sequence_length * percent_sequence_after_anomaly / 100.0)\n",
    "    sequence_length_anomaly = sequence_length - sequence_length_before_anomaly - sequence_length_after_anomaly\n",
    "\n",
    "    # normal parameters\n",
    "    normal_noise_before = [np.random.random() * normal_noise_noise_scale for i in range(0, number_of_sequences * sequence_length_before_anomaly)]\n",
    "    normal_noise_after = [np.random.random() * normal_noise_noise_scale for i in range(0, number_of_sequences * sequence_length_after_anomaly)]\n",
    "\n",
    "    # Anomalous parameters\n",
    "    anomalous_frequency_noise_scale = 2.0\n",
    "    anomalous_frequence_noise_shift = 1.0\n",
    "\n",
    "    anomalous_amplitude_noise_scale = 1.0\n",
    "    anomalous_amplitude_noise_shift = 1.0\n",
    "\n",
    "    anomalous_noise_noise_scale = 1.0\n",
    "\n",
    "    anomalous_freq = (np.random.random() * anomalous_frequency_noise_scale) + anomalous_frequence_noise_shift\n",
    "    anomalous_ampl = np.random.random() * anomalous_amplitude_noise_scale + anomalous_amplitude_noise_shift\n",
    "    anomalous_noise = [np.random.random() * anomalous_noise_noise_scale for i in range(0, number_of_sequences * sequence_length_anomaly)]\n",
    "\n",
    "    sequence_before_anomaly = np.sin(np.arange(0, number_of_sequences * sequence_length_before_anomaly) * normal_freq) * normal_ampl + normal_noise_before\n",
    "    sequence_before_anomaly = sequence_before_anomaly.reshape(number_of_sequences, sequence_length_before_anomaly)\n",
    "\n",
    "    sequence_anomaly = np.sin(np.arange(0, number_of_sequences * sequence_length_anomaly) * anomalous_freq) * anomalous_ampl + anomalous_noise\n",
    "    sequence_anomaly = sequence_anomaly.reshape(number_of_sequences, sequence_length_anomaly)\n",
    "\n",
    "    sequence_after_anomaly = np.sin(np.arange(0, number_of_sequences * sequence_length_after_anomaly) * normal_freq) * normal_ampl + normal_noise_after\n",
    "    sequence_after_anomaly = sequence_after_anomaly.reshape(number_of_sequences, sequence_length_after_anomaly)\n",
    "\n",
    "    return np.concatenate(seq = [sequence_before_anomaly, sequence_anomaly, sequence_after_anomaly], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/seaborn/timeseries.py:183: UserWarning: The `tsplot` function is deprecated and will be removed in a future release. Please update your code to use the new `lineplot` function.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "test_normal_parameters = create_time_series_normal_parameters()\n",
    "\n",
    "flatui = [\"#9b59b6\", \"#3498db\", \"#95a5a6\", \"#e74c3c\", \"#34495e\", \"#2ecc71\"]\n",
    "for i in range(0, 1):\n",
    "    sns.tsplot(create_time_series_normal(5, 50, test_normal_parameters[\"normal_freq\"], test_normal_parameters[\"normal_ampl\"], test_normal_parameters[\"normal_noise_noise_scale\"]).reshape(-1), color=flatui[i%len(flatui)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "flatui = [\"#9b59b6\", \"#3498db\", \"#95a5a6\", \"#e74c3c\", \"#34495e\", \"#2ecc71\"]\n",
    "for i in range(0, 1):\n",
    "    sns.tsplot(create_time_series_with_anomaly(5, 50, percent_sequence_before_anomaly, percent_sequence_after_anomaly, test_normal_parameters[\"normal_freq\"], test_normal_parameters[\"normal_ampl\"], test_normal_parameters[\"normal_noise_noise_scale\"]).reshape(-1), color=flatui[i%len(flatui)] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_training_normal_sequences = 7000\n",
    "\n",
    "number_of_validation_normal_1_sequences = 500\n",
    "number_of_validation_normal_2_sequences = 500\n",
    "number_of_validation_anomalous_sequences = 500\n",
    "\n",
    "number_of_test_normal_sequences = 750\n",
    "number_of_test_anomalous_sequences = 750\n",
    "\n",
    "sequence_length = 30\n",
    "number_of_tags = 3\n",
    "tag_columns = [\"tag_{0}\".format(tag) for tag in range(0, number_of_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'normal_ampl': 1.424846806799189,\n",
       "  'normal_freq': 0.0897530509309381,\n",
       "  'normal_noise_noise_scale': 0.2},\n",
       " {'normal_ampl': 1.1123898721953211,\n",
       "  'normal_freq': 0.011222487729003328,\n",
       "  'normal_noise_noise_scale': 0.2},\n",
       " {'normal_ampl': 1.3008841598393148,\n",
       "  'normal_freq': 0.050599485828091234,\n",
       "  'normal_noise_noise_scale': 0.2}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_data_list = [create_time_series_normal_parameters() for tag in range(0, number_of_tags)]\n",
    "tag_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_normal_sequences_array.shape = \n",
      "(7000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Create training set using normal sequences\n",
    "training_normal_sequences_list = [create_time_series_normal(number_of_training_normal_sequences, sequence_length, tag[\"normal_freq\"], tag[\"normal_ampl\"], tag[\"normal_noise_noise_scale\"]) for tag in tag_data_list]\n",
    "training_normal_sequences_array = np.stack(arrays = list(map(lambda i: np.stack(arrays = list(map(lambda j: np.array2string(a = training_normal_sequences_list[i][j], separator = ',').replace('[', '').replace(']', '').replace(' ', '').replace('\\n', ''), np.arange(0, number_of_training_normal_sequences))), axis = 0), np.arange(0, number_of_tags))), axis = 1)\n",
    "np.random.shuffle(training_normal_sequences_array)\n",
    "print(\"training_normal_sequences_array.shape = \\n{}\".format(training_normal_sequences_array.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation_normal_1_sequences_array.shape = \n",
      "(500, 3)\n",
      "validation_normal_2_sequences_array.shape = \n",
      "(500, 3)\n",
      "validation_anomalous_sequences_array.shape = \n",
      "(500, 3)\n"
     ]
    }
   ],
   "source": [
    "# Create validation sets\n",
    "# Create set vn1 of normal sequences which will be used for early stopping during training as well as using the error vectors to learn mu and sigma for mahalanobis distance\n",
    "validation_normal_1_sequences_list = [create_time_series_normal(number_of_validation_normal_1_sequences, sequence_length, tag[\"normal_freq\"], tag[\"normal_ampl\"], tag[\"normal_noise_noise_scale\"]) for tag in tag_data_list]\n",
    "validation_normal_1_sequences_array = np.stack(arrays = list(map(lambda i: np.stack(arrays = list(map(lambda j: np.array2string(a = validation_normal_1_sequences_list[i][j], separator = ',').replace('[', '').replace(']', '').replace(' ', '').replace('\\n', ''), np.arange(0, number_of_validation_normal_1_sequences))), axis = 0), np.arange(0, number_of_tags))), axis = 1)\n",
    "print(\"validation_normal_1_sequences_array.shape = \\n{}\".format(validation_normal_1_sequences_array.shape))\n",
    "\n",
    "# Create set vn2 of normal sequences which will be used for tuning the anomaly thresholds\n",
    "validation_normal_2_sequences_list = [create_time_series_normal(number_of_validation_normal_2_sequences, sequence_length, tag[\"normal_freq\"], tag[\"normal_ampl\"], tag[\"normal_noise_noise_scale\"]) for tag in tag_data_list]\n",
    "validation_normal_2_sequences_array = np.stack(arrays = list(map(lambda i: np.stack(arrays = list(map(lambda j: np.array2string(a = validation_normal_2_sequences_list[i][j], separator = ',').replace('[', '').replace(']', '').replace(' ', '').replace('\\n', ''), np.arange(0, number_of_validation_normal_2_sequences))), axis = 0), np.arange(0, number_of_tags))), axis = 1)\n",
    "print(\"validation_normal_2_sequences_array.shape = \\n{}\".format(validation_normal_2_sequences_array.shape))\n",
    "\n",
    "# Create set va of anomalous sequences which will be used for tuning the anomaly thresholds\n",
    "validation_anomalous_sequences_list = [create_time_series_with_anomaly(number_of_validation_anomalous_sequences, sequence_length, percent_sequence_before_anomaly, percent_sequence_after_anomaly, tag[\"normal_freq\"], tag[\"normal_ampl\"], tag[\"normal_noise_noise_scale\"]) for tag in tag_data_list]\n",
    "validation_anomalous_sequences_array = np.stack(arrays = list(map(lambda i: np.stack(arrays = list(map(lambda j: np.array2string(a = validation_anomalous_sequences_list[i][j], separator = ',').replace('[', '').replace(']', '').replace(' ', '').replace('\\n', ''), np.arange(0, number_of_validation_anomalous_sequences))), axis = 0), np.arange(0, number_of_tags))), axis = 1)\n",
    "print(\"validation_anomalous_sequences_array.shape = \\n{}\".format(validation_anomalous_sequences_array.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_normal_sequences_array.shape = \n",
      "(750, 3)\n",
      "test_anomalous_sequences_array.shape = \n",
      "(750, 3)\n"
     ]
    }
   ],
   "source": [
    "# Create test sets\n",
    "# Create set tn of normal sequences which will be used for testing model\n",
    "test_normal_sequences_list = [create_time_series_normal(number_of_test_normal_sequences, sequence_length, tag[\"normal_freq\"], tag[\"normal_ampl\"], tag[\"normal_noise_noise_scale\"]) for tag in tag_data_list]\n",
    "test_normal_sequences_array = np.stack(arrays = list(map(lambda i: np.stack(arrays = list(map(lambda j: np.array2string(a = test_normal_sequences_list[i][j], separator = ',').replace('[', '').replace(']', '').replace(' ', '').replace('\\n', ''), np.arange(0, number_of_test_normal_sequences))), axis = 0), np.arange(0, number_of_tags))), axis = 1)\n",
    "print(\"test_normal_sequences_array.shape = \\n{}\".format(test_normal_sequences_array.shape))\n",
    "\n",
    "# Create set ta of anomalous sequences which will be used for testing model\n",
    "test_anomalous_sequences_list = [create_time_series_with_anomaly(number_of_test_anomalous_sequences, sequence_length, percent_sequence_before_anomaly, percent_sequence_after_anomaly, tag[\"normal_freq\"], tag[\"normal_ampl\"], tag[\"normal_noise_noise_scale\"]) for tag in tag_data_list]\n",
    "test_anomalous_sequences_array = np.stack(arrays = list(map(lambda i: np.stack(arrays = list(map(lambda j: np.array2string(a = test_anomalous_sequences_list[i][j], separator = ',').replace('[', '').replace(']', '').replace(' ', '').replace('\\n', ''), np.arange(0, number_of_test_anomalous_sequences))), axis = 0), np.arange(0, number_of_tags))), axis = 1)\n",
    "print(\"test_anomalous_sequences_array.shape = \\n{}\".format(test_anomalous_sequences_array.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled_validation_mixed_sequences_array.shape = \n",
      "(1000, 4)\n",
      "labeled_test_mixed_sequences_array.shape = \n",
      "(1500, 4)\n"
     ]
    }
   ],
   "source": [
    "# Combine vn2 and va sets for tuning anomaly thresholds\n",
    "labeled_validation_normal_2_sequences_array = np.concatenate(seq = [validation_normal_2_sequences_array, np.zeros(shape = [validation_normal_2_sequences_array.shape[0], 1], dtype = np.int64)], axis = 1)\n",
    "labeled_validation_anomalous_sequences_array = np.concatenate(seq = [validation_anomalous_sequences_array, np.ones(shape = [validation_anomalous_sequences_array.shape[0], 1], dtype = np.int64)], axis = 1)\n",
    "labeled_validation_mixed_sequences_array = np.concatenate(seq = [labeled_validation_normal_2_sequences_array, labeled_validation_anomalous_sequences_array], axis = 0)\n",
    "np.random.shuffle(labeled_validation_mixed_sequences_array)\n",
    "print(\"labeled_validation_mixed_sequences_array.shape = \\n{}\".format(labeled_validation_mixed_sequences_array.shape))\n",
    "\n",
    "# Combine tn and ta sets for testing model\n",
    "labeled_test_normal_sequences_array = np.concatenate(seq = [test_normal_sequences_array, np.zeros(shape = [test_normal_sequences_array.shape[0], 1], dtype = np.int64)], axis = 1)\n",
    "labled_test_anomalous_sequences_array = np.concatenate(seq = [test_anomalous_sequences_array, np.ones(shape = [test_anomalous_sequences_array.shape[0], 1], dtype = np.int64)], axis = 1)\n",
    "labeled_test_mixed_sequences_array = np.concatenate(seq = [labeled_test_normal_sequences_array, labled_test_anomalous_sequences_array], axis = 0)\n",
    "np.random.shuffle(labeled_test_mixed_sequences_array)\n",
    "print(\"labeled_test_mixed_sequences_array.shape = \\n{}\".format(labeled_test_mixed_sequences_array.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(fname = \"data/training_normal_sequences.csv\", X = training_normal_sequences_array, fmt = '%s', delimiter = \";\")\n",
    "\n",
    "np.savetxt(fname = \"data/validation_normal_1_sequences.csv\", X = validation_normal_1_sequences_array, fmt = '%s', delimiter = \";\")\n",
    "np.savetxt(fname = \"data/labeled_validation_mixed_sequences.csv\", X = labeled_validation_mixed_sequences_array, fmt = '%s', delimiter = \";\")\n",
    "\n",
    "np.savetxt(fname = \"data/labeled_test_mixed_sequences.csv\", X = labeled_test_mixed_sequences_array, fmt = '%s', delimiter = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.07358858,-1.12320106,-1.2451566,-1.2382363,-1.2479581,-1.23244266,-1.29340564,-1.22926298,-1.23733184,-1.21952752,-1.22751966,-1.09300711,-1.05716098,-1.07356441,-0.82919314,-0.72450531,-0.70805447,-0.61096124,-0.48382469,-0.39380502,-0.22098908,-0.13162068,-0.0026162,0.19210926,0.17838586,0.37963326,0.46240492,0.55594401,0.63958238,0.86943318;-0.91333548,-0.91932393,-0.92057177,-1.06489547,-0.94588388,-1.08865701,-1.08101249,-0.93338974,-1.04697778,-1.05215325,-1.0268492,-0.96085236,-0.91922578,-1.02346045,-1.04115516,-1.07308321,-0.91863087,-1.08783442,-1.10677372,-1.08065298,-0.96219614,-0.96749793,-1.02903258,-1.06575286,-0.93270456,-1.00655188,-1.07124403,-1.06127777,-1.00425545,-1.060611;1.02506694,0.87666807,0.95968152,0.91615907,0.72520563,0.79126027,0.66679897,0.58189839,0.62239639,0.51672984,0.48179287,0.31251583,0.26676813,0.33755368,0.1864841,0.19247779,0.14972351,0.07347115,-0.08135201,-0.21026015,-0.26293717,-0.32246932,-0.40660011,-0.39346838,-0.46994348,-0.43640453,-0.47716559,-0.5512066,-0.68957374,-0.67925505\n"
     ]
    }
   ],
   "source": [
    "!head -1 data/training_normal_sequences.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03157818,0.26439287,0.43630467,0.53776025,0.69713167,0.77266504,0.73322805,0.93477563,1.11715099,1.20705935,1.30346845,1.32122371,1.26105706,1.37383643,1.53783803,1.46301379,1.47922304,1.43918496,1.52082528,1.5654733,1.46000976,1.38301133,1.3608141,1.38305704,1.29876841,1.26850596,1.12677168,0.96933098,0.90215523,0.85161722;0.16425987,0.18616219,0.07789438,0.12372807,0.15717733,0.16836015,0.22688093,0.17828339,0.12654176,0.14437863,0.31823445,0.31648291,0.310553,0.17424365,0.20758943,0.37091974,0.26490334,0.30815461,0.40963396,0.34598053,0.27036763,0.42505193,0.36070153,0.47684545,0.38441838,0.42355895,0.48633467,0.3989633,0.53643827,0.49525703;0.18676626,0.15074606,0.16486193,0.29540759,0.32634344,0.42249205,0.549606,0.55733253,0.54379037,0.62274482,0.8009622,0.76188769,0.83682907,0.94494903,0.85821988,1.04077096,1.03121308,1.00582769,1.05166683,1.15206896,1.23120359,1.23745374,1.22200003,1.29660196,1.25470898,1.29991779,1.37449935,1.44920957,1.30607579,1.40452563\n"
     ]
    }
   ],
   "source": [
    "!head -1 data/validation_normal_1_sequences.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.28250396,-1.40919956,-1.30278298,-1.31443432,-1.38946803,-1.25145181,-1.21566279,-1.24305816,-1.20016856,-1.019681,-1.08440172,-1.00520634,-0.89930009,-0.77505026,-0.59401565,-0.62465382,-0.36974297,-0.25459955,-0.20701304,-0.08852538,0.17869074,0.27904465,0.37250628,0.37185491,0.50028585,0.63846435,0.74124522,0.88736961,1.09903825,1.16510045;-0.77766092,-0.83715375,-0.72879073,-0.74013819,-0.79248851,-0.77758297,-0.76260523,-0.71297325,-0.80615074,-0.86611909,-0.76439958,-0.79155677,-0.68145904,-0.69588308,-0.73298942,-0.77374837,-0.69265816,-0.7310418,-0.65406013,-0.70009598,-0.76028665,-0.75953023,-0.7570052,-0.59932674,-0.66190532,-0.63406203,-0.70156895,-0.60324285,-0.60797471,-0.5912503;-1.09246953,-1.17553267,-1.16683798,-1.03758264,-0.99883628,-1.01154834,-0.86875777,-0.94949924,-0.88156534,-0.74189249,-0.68248849,-0.72616275,-0.57790629,-0.56696094,-0.62699399,-0.47208204,-0.40837431,-0.41264549,-0.34182095,-0.23066661,-0.14672753,-0.08565309,0.0192733,0.05688545,0.17662707,0.23831676,0.21213817,0.31015151,0.38930684,0.43698462;0\n"
     ]
    }
   ],
   "source": [
    "!head -1 data/labeled_validation_mixed_sequences.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.54338012,1.42694401,1.3546681,1.31499096,1.15246537,1.21180008,0.98611413,0.92287224,0.78777793,0.84417638,0.53614336,0.47820579,0.34658801,0.22001935,0.22085259,-0.08553704,-0.05187792,-0.16339163,-0.46618447,-0.57952947,-0.68179376,-0.75115466,-0.78359678,-0.94582155,-1.00545523,-0.05127474,1.82225556,1.39634865,-1.11252985,-0.18747308;-0.45600754,-0.36011805,-0.38243549,-0.3730364,-0.42540602,-0.40412611,-0.32594561,-0.27433266,-0.38986642,-0.40240256,-0.41596605,-0.37595666,-0.36552863,-0.23205706,-0.29869564,-0.20818765,-0.25405568,-0.33054433,-0.2542074,-0.20059119,-0.23847743,-0.08890115,-0.13152268,-0.2382419,0.45696448,-1.12909828,-0.10213089,0.7318132,2.24485751,0.73586897;-0.69839462,-0.51030775,-0.49085041,-0.42808279,-0.31992964,-0.33319803,-0.26573726,-0.20697203,-0.03818173,-0.0857075,0.04360386,0.02036888,0.15151837,0.26651081,0.16529676,0.2764587,0.35957879,0.35577863,0.60329176,0.57132813,0.7074059,0.59983555,0.66715852,0.77454552,0.9518537,1.88957334,1.02097565,-0.41907506,-1.23433882,-0.95446284;1\n"
     ]
    }
   ],
   "source": [
    "!head -1 data/labeled_test_mixed_sequences.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tag_0', 'tag_1', 'tag_2']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logging to be level of INFO\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine CSV and label columns\n",
    "UNLABELED_CSV_COLUMNS = tag_columns\n",
    "\n",
    "LABEL_COLUMN = \"anomalous_sequence_flag\"\n",
    "LABELED_CSV_COLUMNS = UNLABELED_CSV_COLUMNS + [LABEL_COLUMN]\n",
    "\n",
    "# Set default values for each CSV column\n",
    "UNLABELED_DEFAULTS = [[\"\"], [\"\"], [\"\"]]\n",
    "\n",
    "LABELED_DEFAULTS = UNLABELED_DEFAULTS + [[0.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an input function reading a file using the Dataset API\n",
    "# Then provide the results to the Estimator API\n",
    "def read_dataset(filename, mode, batch_size, params):\n",
    "    def _input_fn():\n",
    "#         print(\"\\nread_dataset: _input_fn: filename = \\n{}\".format(filename))\n",
    "#         print(\"read_dataset: _input_fn: mode = \\n{}\".format(mode))\n",
    "#         print(\"read_dataset: _input_fn: batch_size = \\n{}\".format(batch_size))\n",
    "#         print(\"read_dataset: _input_fn: params = \\n{}\\n\".format(params))\n",
    "\n",
    "        def decode_csv(value_column, sequence_length):\n",
    "            def convert_sequences_from_strings_to_floats(features, column_list):\n",
    "                def split_and_convert_string(string_tensor):\n",
    "                    # Split string tensor into a sparse tensor based on delimiter\n",
    "                    split_string = tf.string_split(source = tf.expand_dims(input = string_tensor, axis = 0), delimiter = \",\")\n",
    "#                     print(\"\\nread_dataset: _input_fn: decode_csv: convert_sequences_from_strings_to_floats: split_and_convert_string: split_string = \\n{}\".format(split_string))\n",
    "\n",
    "                    # Converts the values of the sparse tensor to floats\n",
    "                    converted_tensor = tf.string_to_number(split_string.values, out_type = tf.float64)\n",
    "#                     print(\"read_dataset: _input_fn: decode_csv: convert_sequences_from_strings_to_floats: split_and_convert_string: converted_tensor = \\n{}\".format(converted_tensor))\n",
    "\n",
    "                    # Create a new sparse tensor with the new converted values, because the original sparse tensor values are immutable\n",
    "                    new_sparse_tensor = tf.SparseTensor(indices = split_string.indices, values = converted_tensor, dense_shape = split_string.dense_shape)\n",
    "#                     print(\"read_dataset: _input_fn: decode_csv: convert_sequences_from_strings_to_floats: split_and_convert_string: new_sparse_tensor = \\n{}\".format(new_sparse_tensor))\n",
    "\n",
    "                    # Create a dense tensor of the float values that were converted from text csv\n",
    "                    dense_floats = tf.sparse_tensor_to_dense(sp_input = new_sparse_tensor, default_value = 0.0)\n",
    "#                     print(\"read_dataset: _input_fn: decode_csv: convert_sequences_from_strings_to_floats: split_and_convert_string: dense_floats = \\n{}\".format(dense_floats))\n",
    "\n",
    "                    dense_floats_vector = tf.squeeze(input = dense_floats, axis = 0)\n",
    "#                     print(\"read_dataset: _input_fn: decode_csv: convert_sequences_from_strings_to_floats: split_and_convert_string: dense_floats_vector = \\n{}\\n\".format(dense_floats_vector))\n",
    "\n",
    "                    return dense_floats_vector\n",
    "                    \n",
    "#                 print(\"\\nread_dataset: _input_fn: decode_csv: convert_sequences_from_strings_to_floats: features = \\n{}\".format(features))\n",
    "                for column in column_list:\n",
    "#                     print(\"read_dataset: _input_fn: decode_csv: convert_sequences_from_strings_to_floats: column = \\n{}\".format(column))\n",
    "                    features[column] = split_and_convert_string(features[column])\n",
    "                    features[column].set_shape([sequence_length])\n",
    "\n",
    "#                 print(\"read_dataset: _input_fn: decode_csv: convert_sequences_from_strings_to_floats: features = \\n{}\".format(features))\n",
    "\n",
    "                return features\n",
    "                \n",
    "            if mode == tf.estimator.ModeKeys.TRAIN or (mode == tf.estimator.ModeKeys.EVAL and params[\"evaluation_mode\"] != \"tune_anomaly_thresholds\"):\n",
    "                print(\"\\nread_dataset: _input_fn: decode_csv: value_column = \\n{}\".format(value_column))\n",
    "                columns = tf.decode_csv(records = value_column, record_defaults = UNLABELED_DEFAULTS, field_delim = \";\")\n",
    "                print(\"read_dataset: _input_fn: decode_csv: columns = \\n{}\".format(columns))\n",
    "                features = dict(zip(UNLABELED_CSV_COLUMNS, columns))\n",
    "                print(\"read_dataset: _input_fn: decode_csv: features = \\n{}\".format(features))\n",
    "                features = convert_sequences_from_strings_to_floats(features, UNLABELED_CSV_COLUMNS)\n",
    "                print(\"read_dataset: _input_fn: decode_csv: features = \\n{}\".format(features))\n",
    "                return features\n",
    "            else:\n",
    "                print(\"\\nread_dataset: _input_fn: decode_csv: value_column = \\n{}\".format(value_column))\n",
    "                columns = tf.decode_csv(records = value_column, record_defaults = LABELED_DEFAULTS, field_delim = \";\")\n",
    "                print(\"read_dataset: _input_fn: decode_csv: columns = \\n{}\".format(columns))\n",
    "                features = dict(zip(LABELED_CSV_COLUMNS, columns))\n",
    "                print(\"read_dataset: _input_fn: decode_csv: features = \\n{}\".format(features))\n",
    "                labels = tf.cast(x = features.pop(LABEL_COLUMN), dtype = tf.float64)\n",
    "                print(\"read_dataset: _input_fn: decode_csv: labels = \\n{}\".format(labels))\n",
    "                features = convert_sequences_from_strings_to_floats(features, LABELED_CSV_COLUMNS[0:-1])\n",
    "                print(\"read_dataset: _input_fn: decode_csv: features = \\n{}\".format(features))\n",
    "                return features, labels\n",
    "        \n",
    "        # Create list of files that match pattern\n",
    "        file_list = tf.gfile.Glob(filename = filename)\n",
    "#         print(\"\\nread_dataset: _input_fn: file_list = \\n{}\".format(file_list))\n",
    "\n",
    "        # Create dataset from file list\n",
    "        dataset = tf.data.TextLineDataset(filenames = file_list)    # Read text file\n",
    "#         print(\"read_dataset: _input_fn: dataset.TextLineDataset(file_list) = \\n{}\".format(dataset))\n",
    "\n",
    "        # Decode the CSV file into a features dictionary of tensors\n",
    "        dataset = dataset.map(map_func = lambda x: decode_csv(x, params[\"sequence_length\"]))\n",
    "#         print(\"read_dataset: _input_fn: dataset.map(decode_csv) = \\n{}\".format(dataset))\n",
    "        \n",
    "        # Determine amount of times to repeat file based on if we are training or evaluating\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            num_epochs = None # indefinitely\n",
    "        else:\n",
    "            num_epochs = 1 # end-of-input after this\n",
    "\n",
    "        # Repeat files num_epoch times\n",
    "        dataset = dataset.repeat(count = num_epochs)\n",
    "#         print(\"read_dataset: _input_fn: dataset.repeat(num_epochs) = \\n{}\".format(dataset))\n",
    "\n",
    "        # Group the data into batches\n",
    "        dataset = dataset.batch(batch_size = batch_size)\n",
    "#         print(\"read_dataset: _input_fn: dataset.batch(batch_size) = \\n{}\".format(dataset))\n",
    "        \n",
    "        # Determine if we should shuffle based on if we are training or evaluating\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            dataset = dataset.shuffle(buffer_size = 10 * batch_size)\n",
    "#             print(\"read_dataset: _input_fn: dataset.shuffle(buffer_size = 10 * batch_size) = \\n{}\".format(dataset))\n",
    "\n",
    "        # Create a iterator and then pull the next batch of features from the example queue\n",
    "        batched_dataset = dataset.make_one_shot_iterator().get_next()\n",
    "#         print(\"read_dataset: _input_fn: batched_dataset = \\n{}\".format(batched_dataset))\n",
    "\n",
    "        return batched_dataset\n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_out_input_function():\n",
    "    with tf.Session() as sess:\n",
    "        fn = read_dataset(\n",
    "          filename = \"data/labeled_validation_mixed_sequences.csv\",\n",
    "          mode = tf.estimator.ModeKeys.EVAL,\n",
    "          batch_size = 8,\n",
    "          params = {\"sequence_length\": sequence_length,\n",
    "                    \"evaluation_mode\": \"tune_anomaly_thresholds\"})\n",
    "\n",
    "        features = sess.run(fn())\n",
    "        print(\"try_out_input_function: features = \\n{}\".format(features))\n",
    "\n",
    "#         print(\"try_out_input_function: features[tag_0].shape = {}\".format(features[\"tag_0\"].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try_out_input_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our model function to be used in our custom estimator\n",
    "def lstm_encoder_decoder_autoencoder_anomaly_detection(features, labels, mode, params):\n",
    "    print(\"\\nlstm_encoder_decoder_autoencoder_anomaly_detection: features = \\n{}\".format(features))\n",
    "    print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: labels = \\n{}\".format(labels))\n",
    "    print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: mode = \\n{}\".format(mode))\n",
    "    print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: params = \\n{}\".format(params))\n",
    "\n",
    "    # 0. Get input sequence tensor into correct shape\n",
    "    # Get dynamic batch size in case there was a partially filled batch\n",
    "    current_batch_size = tf.shape(input = features[UNLABELED_CSV_COLUMNS[0]], out_type = tf.int64)[0]\n",
    "    print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: current_batch_size = \\n{}\".format(current_batch_size))\n",
    "\n",
    "    # Get the number of features \n",
    "    number_of_features = len(UNLABELED_CSV_COLUMNS)\n",
    "    print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: number_of_features = \\n{}\".format(number_of_features))\n",
    "\n",
    "    # Stack all of the features into a 3-D tensor\n",
    "    X = tf.stack(values = list(features.values()), axis = 2) # shape = (current_batch_size, sequence_length, number_of_features)\n",
    "    print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: X = \\n{}\".format(X))\n",
    "\n",
    "    # Unstack all of 3-D features tensor into a sequence(list) of 2-D tensors of shape = (current_batch_size, number_of_features)\n",
    "    X_sequence = tf.unstack(value = X, num = params[\"sequence_length\"], axis = 1)\n",
    "    print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: X_sequence = \\n{}\".format(X_sequence))\n",
    "\n",
    "    # Since this is an autoencoder, the features are the labels. It works better though to have the labels in reverse order\n",
    "    if params[\"reverse_labels_sequence\"] == True:\n",
    "        Y = tf.reverse_sequence(input = X,  # shape = (current_batch_size, sequence_length, number_of_features)\n",
    "                                seq_lengths = tf.tile(input = tf.constant(value = [params[\"sequence_length\"]], dtype = tf.int64), \n",
    "                                                      multiples = tf.expand_dims(input = current_batch_size, axis = 0)), \n",
    "                                seq_axis = 1, \n",
    "                                batch_axis = 0)\n",
    "    else:\n",
    "        Y = X  # shape = (current_batch_size, sequence_length, number_of_features)\n",
    "    print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: Y = \\n{}\".format(Y))\n",
    "  \n",
    "  ################################################################################\n",
    "  \n",
    "    # 1. Create encoder of encoder-decoder LSTM stacks\n",
    "    def create_LSTM_stack(lstm_hidden_units, lstm_dropout_output_keep_probs):\n",
    "        # First create a list of LSTM cells using our list of lstm hidden unit sizes\n",
    "        lstm_cells = [tf.contrib.rnn.BasicLSTMCell(num_units = units, forget_bias = 1.0, state_is_tuple = True) for units in lstm_hidden_units] # list of LSTM cells\n",
    "#         print(\"\\nlstm_encoder_decoder_autoencoder_anomaly_detection: create_LSTM_stack: lstm_cells = \\n{}\".format(lstm_cells))\n",
    "\n",
    "        # Next apply a dropout wrapper to our stack of LSTM cells, in this case just on the outputs\n",
    "        dropout_lstm_cells = [tf.nn.rnn_cell.DropoutWrapper(cell = lstm_cells[cell_index], \n",
    "                                                            input_keep_prob = 1.0, \n",
    "                                                            output_keep_prob = lstm_dropout_output_keep_probs[cell_index], \n",
    "                                                            state_keep_prob = 1.0) for cell_index in range(len(lstm_cells))]\n",
    "#         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: create_LSTM_stack: dropout_lstm_cells = \\n{}\".format(dropout_lstm_cells))\n",
    "\n",
    "        # Create a stack of layers of LSTM cells\n",
    "        stacked_lstm_cells = tf.contrib.rnn.MultiRNNCell(cells = dropout_lstm_cells, state_is_tuple = True) # combines list into MultiRNNCell object\n",
    "#         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: create_LSTM_stack: stacked_lstm_cells = \\n{}\\n\".format(stacked_lstm_cells))\n",
    "\n",
    "        return stacked_lstm_cells\n",
    "  \n",
    "    # Create our decoder now\n",
    "    decoder_stacked_lstm_cells = create_LSTM_stack(params[\"decoder_lstm_hidden_units\"], params[\"lstm_dropout_output_keep_probs\"])\n",
    "#     print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: decoder_stacked_lstm_cells = \\n{}\".format(decoder_stacked_lstm_cells))\n",
    "  \n",
    "    # Create the encoder variable scope\n",
    "    with tf.variable_scope(\"encoder\"):\n",
    "        # Create separate encoder cells with their own weights separate from decoder\n",
    "        encoder_stacked_lstm_cells = create_LSTM_stack(params[\"encoder_lstm_hidden_units\"], params[\"lstm_dropout_output_keep_probs\"])\n",
    "#         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: encoder_stacked_lstm_cells = {}\".format(encoder_stacked_lstm_cells))\n",
    "\n",
    "        # Encode the input sequence using our encoder stack of LSTMs\n",
    "        encoder_outputs, encoder_states = tf.nn.static_rnn(cell = encoder_stacked_lstm_cells, \n",
    "                                                           inputs = X_sequence, \n",
    "                                                           initial_state = encoder_stacked_lstm_cells.zero_state(batch_size = tf.cast(x = current_batch_size, dtype = tf.int32), dtype = tf.float64), \n",
    "                                                           dtype = tf.float64)\n",
    "#         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: encoder_outputs = \\n{}\".format(encoder_outputs)) # list sequence_length long of shape = (current_batch_size, lstm_hidden_units[-1])\n",
    "#         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: encoder_states = \\n{}\".format(encoder_states)) # tuple of final encoder c_state and h_state for each layer\n",
    "\n",
    "        # We just pass on the final c and h states of the encoder\"s last layer, so extract that and drop the others\n",
    "        encoder_final_states = encoder_states[-1]\n",
    "#         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: encoder_final_states = \\n{}\".format(encoder_final_states))\n",
    "\n",
    "        # Extract the c and h states from the tuple\n",
    "        encoder_final_c, encoder_final_h = encoder_final_states\n",
    "#         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: encoder_final_c = \\n{}\".format(encoder_final_c))\n",
    "#         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: encoder_final_h = \\n{}\".format(encoder_final_h))\n",
    "\n",
    "        # In case the decoder\"s first layer\"s number of units is different than encoder\"s last layer\"s number of units, use a dense layer to map to the correct shape\n",
    "        encoder_final_c_dense = tf.layers.dense(inputs = encoder_final_c, units = params[\"decoder_lstm_hidden_units\"][0], activation = None)\n",
    "        encoder_final_h_dense = tf.layers.dense(inputs = encoder_final_h, units = params[\"decoder_lstm_hidden_units\"][0], activation = None)\n",
    "\n",
    "        # The decoder\"s first layer\"s state comes from the encoder, the rest of the layers\" initial states are zero\n",
    "        decoder_intial_states = tuple([tf.contrib.rnn.LSTMStateTuple(c = encoder_final_c_dense, h = encoder_final_h_dense)] + [tf.contrib.rnn.LSTMStateTuple(c = tf.zeros(shape = [current_batch_size, units], dtype = tf.float64), h = tf.zeros(shape = [current_batch_size, units], dtype = tf.float64)) for units in params[\"decoder_lstm_hidden_units\"][1:]])\n",
    "#         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: decoder_intial_states = \\n{}\".format(decoder_intial_states))\n",
    "    \n",
    "    ################################################################################\n",
    "\n",
    "    # 2. Create decoder of encoder-decoder LSTM stacks\n",
    "    # The rnn_decoder function takes labels during TRAIN/EVAL and a start token followed by its previous predictions during PREDICT\n",
    "    # Starts with an intial state of the final encoder states\n",
    "    def rnn_decoder(decoder_inputs, initial_state, cell, inference):\n",
    "        # Create the decoder variable scope\n",
    "        with tf.variable_scope(\"decoder\"):\n",
    "            # Load in our initial state from our encoder\n",
    "            state = initial_state # tuple of final encoder c_state and h_state of final encoder layer\n",
    "#             print(\"\\nlstm_encoder_decoder_autoencoder_anomaly_detection: rnn_decoder: state = \\n{}\".format(state))\n",
    "            \n",
    "            # Create an empty list to store our hidden state output for every timestep\n",
    "            outputs = []\n",
    "            \n",
    "            # Begin with no previous output\n",
    "            previous_output = None\n",
    "            \n",
    "            # Loop over all of our decoder_inputs which will be sequence_length long\n",
    "            for index, decoder_input in enumerate(decoder_inputs):\n",
    "                # If there has been a previous output then we will determine the next input\n",
    "                if previous_output is not None:\n",
    "                    # Create the input layer to our DNN\n",
    "                    network = previous_output # shape = (current_batch_size, lstm_hidden_units[-1])\n",
    "#                     print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: rnn_decoder: network = \\n{}\".format(network))\n",
    "                    \n",
    "                    # Create our dnn variable scope\n",
    "                    with tf.variable_scope(name_or_scope = \"dnn\", reuse = tf.AUTO_REUSE):\n",
    "                        # Add hidden layers with the given number of units/neurons per layer\n",
    "                        for units in params[\"dnn_hidden_units\"]:\n",
    "                            network = tf.layers.dense(inputs = network, units = units, activation = tf.nn.relu) # shape = (current_batch_size, dnn_hidden_units[i])\n",
    "#                             print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: rnn_decoder: network = {}, units = {}\".format(network, units))\n",
    "                            \n",
    "                        # Connect the final hidden layer to a dense layer with no activation to get the logits\n",
    "                        logits = tf.layers.dense(inputs = network, units = number_of_features, activation = None) # shape = (current_batch_size, number_of_features)\n",
    "#                         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: rnn_decoder: logits = \\n{}\\n\".format(logits))\n",
    "                    \n",
    "                    # If we are in inference then we will overwrite our next decoder_input with the logits we just calculated.\n",
    "                    # Otherwise, we leave the decoder_input input as it was from the enumerated list\n",
    "                    # We have to calculate the logits even when not using them so that the correct dnn subgraph will be generated here and after the encoder-decoder for both training and inference\n",
    "                    if inference == True:\n",
    "                        decoder_input = logits # shape = (current_batch_size, number_of_features)\n",
    "\n",
    "#                     print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: rnn_decoder: decoder_input = \\n{}\\n\".format(decoder_input))\n",
    "                \n",
    "                # If this isn\"t our first time through the loop, just reuse(share) the same variables for each iteration within the current variable scope\n",
    "                if index > 0:\n",
    "                    tf.get_variable_scope().reuse_variables()\n",
    "                \n",
    "                # Run the decoder input through the decoder stack picking up from the previous state\n",
    "                output, state = cell(decoder_input, state)\n",
    "#                 print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: rnn_decoder: output = \\n{}\".format(output)) # shape = (current_batch_size, lstm_hidden_units[-1])\n",
    "#                 print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: rnn_decoder: state = \\n{}\".format(state)) # tuple of final decoder c_state and h_state\n",
    "                \n",
    "                # Append the current decoder hidden state output to the outputs list\n",
    "                outputs.append(output) # growing list eventually sequence_length long of shape = (current_batch_size, lstm_hidden_units[-1])\n",
    "                \n",
    "                # Set the previous output to the output just calculated\n",
    "                previous_output = output # shape = (current_batch_size, lstm_hidden_units[-1])\n",
    "        return outputs, state\n",
    "  \n",
    "    # Train our decoder now\n",
    "  \n",
    "    # Encoder-decoders work differently during training/evaluation and inference so we will have two separate subgraphs for each\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN    or mode == tf.estimator.ModeKeys.EVAL:\n",
    "        # Break 3-D labels tensor into a list of 2-D tensors\n",
    "        unstacked_labels = tf.unstack(value = Y, num = params[\"sequence_length\"], axis = 1) # list of sequence_length long of shape = (current_batch_size, number_of_features)\n",
    "#         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: unstacked_labels = \\n{}\".format(unstacked_labels))\n",
    "\n",
    "        # Call our decoder using the labels as our inputs, the encoder final state as our initial state, our other LSTM stack as our cells, and inference set to false\n",
    "        decoder_outputs, decoder_states = rnn_decoder(decoder_inputs = unstacked_labels, initial_state = decoder_intial_states, cell = decoder_stacked_lstm_cells, inference = False)\n",
    "    else:\n",
    "        # Since this is inference create fake labels. The list length needs to be the output sequence length even though only the first element is actually used (as our go signal)\n",
    "        fake_labels = [tf.zeros(shape = [current_batch_size, number_of_features], dtype = tf.float64) for _ in range(params[\"sequence_length\"])]\n",
    "#         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: fake_labels = \\n{}\".format(fake_labels))\n",
    "        \n",
    "        # Call our decoder using fake labels as our inputs, the encoder final state as our initial state, our other LSTM stack as our cells, and inference set to true\n",
    "        decoder_outputs, decoder_states = rnn_decoder(decoder_inputs = fake_labels, initial_state = decoder_intial_states, cell = decoder_stacked_lstm_cells, inference = True)\n",
    "#     print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: decoder_outputs = \\n{}\".format(decoder_outputs)) # list sequence_length long of shape = (current_batch_size, lstm_hidden_units[-1])\n",
    "#     print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: decoder_states = \\n{}\".format(decoder_states)) # tuple of final decoder c_state and h_state\n",
    "    \n",
    "    # Stack together the list of rank 2 decoder output tensors into one rank 3 tensor\n",
    "    stacked_decoder_outputs = tf.stack(values = decoder_outputs, axis = 1) # shape = (current_batch_size, sequence_length, lstm_hidden_units[-1])\n",
    "#     print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: stacked_decoder_outputs = \\n{}\".format(stacked_decoder_outputs))\n",
    "    \n",
    "    # Reshape rank 3 decoder outputs into rank 2 by folding sequence length into batch size\n",
    "    reshaped_stacked_decoder_outputs = tf.reshape(tensor = stacked_decoder_outputs, shape = [current_batch_size * params[\"sequence_length\"], params[\"decoder_lstm_hidden_units\"][-1]]) # shape = (current_batch_size * sequence_length, lstm_hidden_units[-1])\n",
    "#     print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: reshaped_stacked_decoder_outputs = \\n{}\".format(reshaped_stacked_decoder_outputs))\n",
    "\n",
    "    ################################################################################\n",
    "    \n",
    "    # 3. Create the DNN structure now after the encoder-decoder LSTM stack\n",
    "    # Create the input layer to our DNN\n",
    "    network = reshaped_stacked_decoder_outputs # shape = (current_batch_size * sequence_length, lstm_hidden_units[-1])\n",
    "#     print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: network = \\n{}\".format(network))\n",
    "    \n",
    "    # Reuse the same variable scope as we used within our decoder (for inference)\n",
    "    with tf.variable_scope(name_or_scope = \"dnn\", reuse = tf.AUTO_REUSE):\n",
    "        # Add hidden layers with the given number of units/neurons per layer\n",
    "        for units in params[\"dnn_hidden_units\"]:\n",
    "            network = tf.layers.dense(inputs = network, units = units, activation = tf.nn.relu) # shape = (current_batch_size * sequence_length, dnn_hidden_units[i])\n",
    "#             print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: network = {}, units = {}\".format(network, units))\n",
    "\n",
    "        # Connect the final hidden layer to a dense layer with no activation to get the logits\n",
    "        logits = tf.layers.dense(inputs = network, units = number_of_features, activation = None) # shape = (current_batch_size * sequence_length, number_of_features)\n",
    "#         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: logits = \\n{}\".format(logits))\n",
    "    \n",
    "    # Now that we are through the final DNN for each sequence element for each example in the batch, reshape the predictions to match our labels\n",
    "    predictions = tf.reshape(tensor = logits, shape = [current_batch_size, params[\"sequence_length\"], number_of_features]) # shape = (current_batch_size, sequence_length, number_of_features)\n",
    "#     print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: predictions = \\n{}\".format(predictions))\n",
    "    \n",
    "    with tf.variable_scope(name_or_scope = \"mahalanobis_distance_variables\", reuse = tf.AUTO_REUSE):\n",
    "        # Time based\n",
    "        absolute_error_count_batch_time_variable = tf.get_variable(name = \"absolute_error_count_batch_time_variable\", # shape = ()\n",
    "                                                                   dtype = tf.int64,\n",
    "                                                                   initializer = tf.zeros(shape = [], \n",
    "                                                                                          dtype = tf.int64),\n",
    "                                                                   trainable = False)\n",
    "        \n",
    "        absolute_error_mean_batch_time_variable = tf.get_variable(name = \"absolute_error_mean_batch_time_variable\", # shape = (number_of_features,)\n",
    "                                                                  dtype = tf.float64,\n",
    "                                                                  initializer = tf.zeros(shape = [number_of_features], \n",
    "                                                                                         dtype = tf.float64),\n",
    "                                                                  trainable = False)\n",
    "        \n",
    "        absolute_error_covariance_matrix_batch_time_variable = tf.get_variable(name = \"absolute_error_covariance_matrix_batch_time_variable\", # shape = (number_of_features, number_of_features)\n",
    "                                                                               dtype = tf.float64,\n",
    "                                                                               initializer = tf.zeros(shape = [number_of_features, number_of_features], \n",
    "                                                                                                      dtype = tf.float64),\n",
    "                                                                               trainable = False)\n",
    "\n",
    "        absolute_error_inverse_covariance_matrix_batch_time_variable = tf.get_variable(name = \"absolute_error_inverse_covariance_matrix_batch_time_variable\", # shape = (number_of_features, number_of_features)\n",
    "                                                                                       dtype = tf.float64,\n",
    "                                                                                       initializer = tf.zeros(shape = [number_of_features, number_of_features], \n",
    "                                                                                                              dtype = tf.float64),\n",
    "                                                                                       trainable = False)\n",
    "\n",
    "        # Features based\n",
    "        absolute_error_count_batch_features_variable = tf.get_variable(name = \"absolute_error_count_batch_features_variable\", # shape = ()\n",
    "                                                                       dtype = tf.int64,\n",
    "                                                                       initializer = tf.zeros(shape = [], \n",
    "                                                                                              dtype = tf.int64),\n",
    "                                                                       trainable = False)\n",
    "        \n",
    "        absolute_error_mean_batch_features_variable = tf.get_variable(name = \"absolute_error_mean_batch_features_variable\", # shape = (sequence_length,)\n",
    "                                                                      dtype = tf.float64,\n",
    "                                                                      initializer = tf.zeros(shape = [params[\"sequence_length\"]], \n",
    "                                                                                             dtype = tf.float64),\n",
    "                                                                      trainable = False)\n",
    "        \n",
    "        absolute_error_covariance_matrix_batch_features_variable = tf.get_variable(name = \"absolute_error_covariance_matrix_batch_features_variable\", # shape = (sequence_length, sequence_length)\n",
    "                                                                                   dtype = tf.float64,\n",
    "                                                                                   initializer = tf.zeros(shape = [params[\"sequence_length\"], params[\"sequence_length\"]], \n",
    "                                                                                                          dtype = tf.float64),\n",
    "                                                                                   trainable = False)\n",
    "\n",
    "        absolute_error_inverse_covariance_matrix_batch_features_variable = tf.get_variable(name = \"absolute_error_inverse_covariance_matrix_batch_features_variable\", # shape = (sequence_length, sequence_length)\n",
    "                                                                                           dtype = tf.float64,\n",
    "                                                                                           initializer = tf.zeros(shape = [params[\"sequence_length\"], params[\"sequence_length\"]], \n",
    "                                                                                                                  dtype = tf.float64),\n",
    "                                                                                           trainable = False)\n",
    "    \n",
    "    # Now branch off based on which mode we are in\n",
    "    predictions_dict = None\n",
    "    loss = None\n",
    "    train_op = None\n",
    "    eval_metric_ops = None\n",
    "    export_outputs = None\n",
    "    \n",
    "    # 3. Loss function, training/eval ops\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        loss = tf.losses.mean_squared_error(labels = Y, predictions = predictions)\n",
    "        \n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss = loss,\n",
    "            global_step = tf.train.get_global_step(),\n",
    "            learning_rate = params[\"learning_rate\"],\n",
    "            optimizer = \"Adam\")\n",
    "    elif mode == tf.estimator.ModeKeys.EVAL and params[\"evaluation_mode\"] != \"tune_anomaly_thresholds\":\n",
    "        # Reconstruction loss on evaluation set\n",
    "        loss = tf.losses.mean_squared_error(labels = Y, predictions = predictions)\n",
    "        \n",
    "        if params[\"evaluation_mode\"] == \"reconstruction\": # if reconstruction during train_and_evaluate\n",
    "            # Reconstruction eval metrics\n",
    "            eval_metric_ops = {\n",
    "                \"rmse\": tf.metrics.root_mean_squared_error(labels = Y, predictions = predictions),\n",
    "                \"mae\": tf.metrics.mean_absolute_error(labels = Y, predictions = predictions)\n",
    "            }\n",
    "        elif params[\"evaluation_mode\"] == \"calculate_error_distribution_statistics\":\n",
    "            absolute_error = tf.abs(x = Y - predictions) # shape = (current_batch_size, sequence_length, number_of_features)\n",
    "#             print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: absolute_error = \\n{}\".format(absolute_error))\n",
    "\n",
    "            ################################################################################\n",
    "    \n",
    "            with tf.variable_scope(name_or_scope = \"mahalanobis_distance_variables\", reuse = tf.AUTO_REUSE):\n",
    "                # This function updates the count of records used\n",
    "                def update_count(count_a, count_b):\n",
    "                    return count_a + count_b\n",
    "                \n",
    "                # This function updates the mahalanobis distance variables when the current_batch_size equals 1\n",
    "                def singleton_batch_mahalanobis_distance_variable_updating(absolute_error, absolute_error_count_batch_time_variable, absolute_error_mean_batch_time_variable, absolute_error_covariance_matrix_batch_time_variable, absolute_error_inverse_covariance_matrix_batch_time_variable, absolute_error_count_batch_features_variable, absolute_error_mean_batch_features_variable, absolute_error_covariance_matrix_batch_features_variable, absolute_error_inverse_covariance_matrix_batch_features_variable):\n",
    "                    # This function updates the mean vector incrementally\n",
    "                    def update_mean_incremental(count_a, mean_a, value_b):\n",
    "#                         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: update_mean_incremental: count_a = \\n{}\".format(count_a))\n",
    "#                         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: update_mean_incremental: mean_a = \\n{}\".format(mean_a))\n",
    "#                         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: update_mean_incremental: value_b = \\n{}\".format(value_b))\n",
    "                        return (mean_a * tf.cast(x = count_a, dtype = tf.float64) + tf.squeeze(input = value_b, axis = 0)) / tf.cast(x = count_a + 1, dtype = tf.float64)\n",
    "\n",
    "                    # This function updates the covariance matrix incrementally\n",
    "                    def update_covariance_incremental(count_a, mean_a, cov_a, value_b, mean_ab, sample_covariance):\n",
    "#                         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: update_covariance_incremental: count_a = \\n{}\".format(count_a))\n",
    "#                         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: update_covariance_incremental: mean_a = \\n{}\".format(mean_a))\n",
    "#                         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: update_covariance_incremental: cov_a = \\n{}\".format(cov_a))\n",
    "#                         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: update_covariance_incremental: value_b = \\n{}\".format(value_b))\n",
    "#                         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: update_covariance_incremental: mean_ab = \\n{}\".format(mean_ab))\n",
    "#                         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: update_covariance_incremental: sample_covariance = \\n{}\".format(sample_covariance))\n",
    "                        if sample_covariance == True:\n",
    "                            cov_ab = (cov_a * tf.cast(x = count_a - 1, dtype = tf.float64) + tf.matmul(a = value_b - mean_a, b = value_b - mean_ab, transpose_a = True)) / tf.cast(x = count_a, dtype = tf.float64)\n",
    "                        else:\n",
    "                            cov_ab = (cov_a * tf.cast(x = count_a, dtype = tf.float64) + tf.matmul(a = value_b - mean_a, b = value_b - mean_ab, transpose_a = True)) / tf.cast(x = count_a + 1, dtype = tf.float64)\n",
    "                        return cov_ab\n",
    "                    \n",
    "                    # Time based\n",
    "                    absolute_error_reshaped_batch_time = tf.reshape(tensor = absolute_error, shape = [current_batch_size * params[\"sequence_length\"], number_of_features]) # shape = (current_batch_size * sequence_length, number_of_features)\n",
    "#                     print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: absolute_error_reshaped_batch_time = \\n{}\".format(absolute_error_reshaped_batch_time))\n",
    "                    \n",
    "                    # Calculate new combined mean to use for incremental covariance matrix calculation\n",
    "                    mean_ab = update_mean_incremental(count_a = absolute_error_count_batch_time_variable, \n",
    "                                                      mean_a = absolute_error_mean_batch_time_variable, \n",
    "                                                      value_b = absolute_error_reshaped_batch_time) # shape = (number_of_features,)\n",
    "\n",
    "                    # Update running variables from single example\n",
    "                    absolute_error_covariance_matrix_batch_time_variable.assign(value = update_covariance_incremental(count_a = absolute_error_count_batch_time_variable, \n",
    "                                                                                                                      mean_a = absolute_error_mean_batch_time_variable, \n",
    "                                                                                                                      cov_a = absolute_error_covariance_matrix_batch_time_variable, \n",
    "                                                                                                                      value_b = absolute_error_reshaped_batch_time, \n",
    "                                                                                                                      mean_ab = mean_ab, \n",
    "                                                                                                                      sample_covariance = True)) # shape = (number_of_features, number_of_features)\n",
    "                    absolute_error_mean_batch_time_variable.assign(value = mean_ab) # shape = (number_of_features,)\n",
    "                    absolute_error_count_batch_time_variable.assign(value = update_count(count_a = absolute_error_count_batch_time_variable, \n",
    "                                                                                     count_b = 1)) # shape = ()\n",
    "                    \n",
    "                    absolute_error_inverse_covariance_matrix_batch_time_variable.assign(value = tf.matrix_inverse(input = absolute_error_covariance_matrix_batch_time_variable)) # shape = (number_of_features, number_of_features)\n",
    "                    \n",
    "                    ################################################################################\n",
    "                    \n",
    "                    # Features based\n",
    "                    absolute_error_mapped_batch_features = tf.map_fn(fn = lambda x: tf.transpose(a = absolute_error[x, :, :]), # shape = (current_batch_size, number_of_features, sequence_length)\n",
    "                                                                       elems = tf.range(start = 0, limit = current_batch_size, dtype = tf.int64), \n",
    "                                                                       dtype = tf.float64)\n",
    "#                     print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: absolute_error_mapped_batch_features = \\n{}\".format(absolute_error_mapped_batch_features))\n",
    "                    absolute_error_reshaped_batch_features = tf.reshape(tensor = absolute_error_mapped_batch_features, shape = [current_batch_size * number_of_features, params[\"sequence_length\"]]) # shape = (current_batch_size * number_of_features, sequence_length)\n",
    "#                     print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: absolute_error_reshaped_batch_features = \\n{}\".format(absolute_error_reshaped_batch_features))\n",
    "                    \n",
    "                    # Calculate new combined mean to use for incremental covariance matrix calculation\n",
    "                    mean_ab = update_mean_incremental(count_a = absolute_error_count_batch_features_variable, \n",
    "                                                      mean_a = absolute_error_mean_batch_features_variable, \n",
    "                                                      value_b = absolute_error_reshaped_batch_features) # shape = (sequence_length,)\n",
    "\n",
    "                    # Update running variables from single example\n",
    "                    absolute_error_covariance_matrix_batch_features_variable.assign(value = update_covariance_incremental(count_a = absolute_error_count_batch_features_variable, \n",
    "                                                                                                                          mean_a = absolute_error_mean_batch_features_variable, \n",
    "                                                                                                                          cov_a = absolute_error_covariance_matrix_batch_features_variable, \n",
    "                                                                                                                          value_b = absolute_error_reshaped_batch_features, \n",
    "                                                                                                                          mean_ab = mean_ab, \n",
    "                                                                                                                          sample_covariance = True)) # shape = (sequence_length, sequence_length)\n",
    "                    absolute_error_mean_batch_features_variable.assign(value = mean_ab) # shape = (sequence_length,)\n",
    "                    absolute_error_count_batch_features_variable.assign(value = update_count(count_a = absolute_error_count_batch_features_variable, \n",
    "                                                                                         count_b = 1)) # shape = ()\n",
    "                    \n",
    "                    absolute_error_inverse_covariance_matrix_batch_features_variable.assign(value = tf.matrix_inverse(input = absolute_error_covariance_matrix_batch_features_variable)) # shape = (sequence_length, sequence_length)\n",
    "                    \n",
    "                    return absolute_error_count_batch_time_variable, absolute_error_mean_batch_time_variable, absolute_error_covariance_matrix_batch_time_variable, absolute_error_inverse_covariance_matrix_batch_time_variable, absolute_error_count_batch_features_variable, absolute_error_mean_batch_features_variable, absolute_error_covariance_matrix_batch_features_variable, absolute_error_inverse_covariance_matrix_batch_features_variable\n",
    "\n",
    "                # This function updates the mahalanobis distance variables when the current_batch_size does NOT equal 1\n",
    "                def non_singleton_batch_mahalanobis_distance_variable_updating(absolute_error, absolute_error_count_batch_time_variable, absolute_error_mean_batch_time_variable, absolute_error_covariance_matrix_batch_time_variable, absolute_error_inverse_covariance_matrix_batch_time_variable, absolute_error_count_batch_features_variable, absolute_error_mean_batch_features_variable, absolute_error_covariance_matrix_batch_features_variable, absolute_error_inverse_covariance_matrix_batch_features_variable):\n",
    "                    # This function updates the mean vector using a batch of data\n",
    "                    def update_mean_batch(count_a, mean_a, count_b, mean_b):\n",
    "#                         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: update_mean_batch: count_a = \\n{}\".format(count_a))\n",
    "#                         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: update_mean_batch: mean_a = \\n{}\".format(mean_a))\n",
    "#                         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: update_mean_batch: count_b = \\n{}\".format(count_b))\n",
    "#                         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: update_mean_batch: mean_b = \\n{}\".format(mean_b))\n",
    "                        return (mean_a * tf.cast(x = count_a, dtype = tf.float64) + mean_b * tf.cast(x = count_b, dtype = tf.float64)) / tf.cast(x = count_a + count_b, dtype = tf.float64)\n",
    "\n",
    "                    # This function updates the covariance matrix using a batch of data\n",
    "                    def update_covariance_batch(count_a, mean_a, cov_a, count_b, mean_b, cov_b, sample_covariance):\n",
    "#                         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: update_covariance_batch: count_a = \\n{}\".format(count_a))\n",
    "#                         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: update_covariance_batch: mean_a = \\n{}\".format(mean_a))\n",
    "#                         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: update_covariance_batch: cov_a = \\n{}\".format(cov_a))\n",
    "#                         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: update_covariance_batch: count_b = \\n{}\".format(count_b))\n",
    "#                         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: update_covariance_batch: mean_b = \\n{}\".format(mean_b))\n",
    "#                         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: update_covariance_batch: cov_b = \\n{}\".format(cov_b))\n",
    "#                         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: update_covariance_batch: sample_covariance = \\n{}\".format(sample_covariance))\n",
    "                        \n",
    "                        mean_diff = tf.expand_dims(input = mean_a - mean_b, axis = 0)\n",
    "\n",
    "                        if sample_covariance == True:\n",
    "                            cov_ab = (cov_a * tf.cast(x = count_a - 1, dtype = tf.float64) + cov_b * tf.cast(x = count_b - 1, dtype = tf.float64) + tf.matmul(a = mean_diff, b = mean_diff, transpose_a = True) * tf.cast(x = count_a * count_b, dtype = tf.float64) / tf.cast(x = count_a + count_b, dtype = tf.float64)) / tf.cast(x = count_a + count_b - 1, dtype = tf.float64)\n",
    "                        else:\n",
    "                            cov_ab = (cov_a * tf.cast(x = count_a, dtype = tf.float64) + cov_b * tf.cast(x = count_b, dtype = tf.float64) + tf.matmul(a = mean_diff, b = mean_diff, transpose_a = True) * tf.cast(x = count_a * count_b, dtype = tf.float64) / tf.cast(x = count_a + count_b, dtype = tf.float64)) / tf.cast(x = count_a + count_b, dtype = tf.float64)\n",
    "                        return cov_ab\n",
    "                    \n",
    "                    # Time based\n",
    "                    \n",
    "                    # Find statistics of batch\n",
    "                    absolute_error_reshaped_batch_time = tf.reshape(tensor = absolute_error, shape = [current_batch_size * params[\"sequence_length\"], number_of_features]) # shape = (current_batch_size * sequence_length, number_of_features)\n",
    "#                     print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: absolute_error_reshaped_batch_time = \\n{}\".format(absolute_error_reshaped_batch_time))\n",
    "\n",
    "                    absolute_error_mean_batch_time = tf.reduce_mean(input_tensor = absolute_error_reshaped_batch_time, axis = 0) # shape = (current_batch_size * sequence_length,)\n",
    "#                     print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: absolute_error_mean_batch_time = \\n{}\".format(absolute_error_mean_batch_time))\n",
    "\n",
    "                    absolute_error_reshaped_batch_time_centered = absolute_error_reshaped_batch_time - absolute_error_mean_batch_time # shape = (current_batch_size * sequence_length, number_of_features)\n",
    "#                     print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: absolute_error_reshaped_batch_time_centered = \\n{}\".format(absolute_error_reshaped_batch_time_centered))\n",
    "\n",
    "                    absolute_error_reshaped_batch_time_covariance_matrix = tf.matmul(a = absolute_error_reshaped_batch_time_centered, # shape = (number_of_features, number_of_features)\n",
    "                                                                                     b = absolute_error_reshaped_batch_time_centered, \n",
    "                                                                                     transpose_a = True) / tf.cast(x = current_batch_size * params[\"sequence_length\"] - 1, dtype = tf.float64)\n",
    "#                     print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: absolute_error_reshaped_batch_time_covariance_matrix = \\n{}\".format(absolute_error_reshaped_batch_time_covariance_matrix))\n",
    "                    \n",
    "                    # Update running variables from batch statistics\n",
    "                    absolute_error_covariance_matrix_batch_time_variable.assign(value = update_covariance_batch(count_a = absolute_error_count_batch_time_variable, \n",
    "                                                                                                                mean_a = absolute_error_mean_batch_time_variable, \n",
    "                                                                                                                cov_a = absolute_error_covariance_matrix_batch_time_variable, \n",
    "                                                                                                                count_b = current_batch_size, \n",
    "                                                                                                                mean_b = absolute_error_mean_batch_time, \n",
    "                                                                                                                cov_b = absolute_error_reshaped_batch_time_covariance_matrix, \n",
    "                                                                                                                sample_covariance = True)) # shape = (number_of_features, number_of_features)\n",
    "                    \n",
    "                    absolute_error_mean_batch_time_variable.assign(value = update_mean_batch(count_a = absolute_error_count_batch_time_variable, \n",
    "                                                                                             mean_a = absolute_error_mean_batch_time_variable, \n",
    "                                                                                             count_b = current_batch_size, \n",
    "                                                                                             mean_b = absolute_error_mean_batch_time)) # shape = (number_of_features,)\n",
    "                    \n",
    "                    absolute_error_count_batch_time_variable.assign(value = update_count(count_a = absolute_error_count_batch_time_variable, \n",
    "                                                                                         count_b = current_batch_size)) # shape = ()\n",
    "\n",
    "                    absolute_error_inverse_covariance_matrix_batch_time_variable.assign(value = tf.matrix_inverse(input = absolute_error_covariance_matrix_batch_time_variable)) # shape = (number_of_features, number_of_features)\n",
    "\n",
    "                    ################################################################################\n",
    "\n",
    "                    # Features based\n",
    "                    \n",
    "                    # Find statistics of batch\n",
    "                    absolute_error_mapped_batch_features = tf.map_fn(fn = lambda x: tf.transpose(a = absolute_error[x, :, :]), # shape = (current_batch_size, number_of_features, sequence_length)\n",
    "                                                                       elems = tf.range(start = 0, limit = current_batch_size, dtype = tf.int64), \n",
    "                                                                       dtype = tf.float64)\n",
    "#                     print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: absolute_error_mapped_batch_features = \\n{}\".format(absolute_error_mapped_batch_features))\n",
    "                    absolute_error_reshaped_batch_features = tf.reshape(tensor = absolute_error_mapped_batch_features, shape = [current_batch_size * number_of_features, params[\"sequence_length\"]]) # shape = (current_batch_size * number_of_features, sequence_length)\n",
    "#                     print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: absolute_error_reshaped_batch_features = \\n{}\".format(absolute_error_reshaped_batch_features))\n",
    "\n",
    "                    absolute_error_mean_batch_features = tf.reduce_mean(input_tensor = absolute_error_reshaped_batch_features, axis = 0) # shape = (sequence_length,)\n",
    "#                     print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: absolute_error_mean_batch_features = \\n{}\".format(absolute_error_mean_batch_features))\n",
    "\n",
    "                    absolute_error_reshaped_batch_features_centered = absolute_error_reshaped_batch_features - absolute_error_mean_batch_features # shape = (current_batch_size * number_of_features, sequence_length)\n",
    "#                     print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: absolute_error_reshaped_batch_features_centered = \\n{}\".format(absolute_error_reshaped_batch_features_centered))\n",
    "\n",
    "                    absolute_error_reshaped_batch_features_covariance_matrix = tf.matmul(a = absolute_error_reshaped_batch_features_centered, # shape = (sequence_length, sequence_length)\n",
    "                                                                                         b = absolute_error_reshaped_batch_features_centered, \n",
    "                                                                                         transpose_a = True) / tf.cast(x = current_batch_size * number_of_features - 1, dtype = tf.float64)\n",
    "#                     print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: absolute_error_reshaped_batch_features_covariance_matrix = \\n{}\".format(absolute_error_reshaped_batch_features_covariance_matrix))\n",
    "\n",
    "                    # Update running variables from batch statistics\n",
    "                    absolute_error_covariance_matrix_batch_features_variable.assign(value = update_covariance_batch(count_a = absolute_error_count_batch_features_variable, \n",
    "                                                                                                                    mean_a = absolute_error_mean_batch_features_variable, \n",
    "                                                                                                                    cov_a = absolute_error_covariance_matrix_batch_features_variable, \n",
    "                                                                                                                    count_b = current_batch_size, \n",
    "                                                                                                                    mean_b = absolute_error_mean_batch_features, \n",
    "                                                                                                                    cov_b = absolute_error_reshaped_batch_features_covariance_matrix, \n",
    "                                                                                                                    sample_covariance = True)) # shape = (sequence_length, sequence_length)\n",
    "                    \n",
    "                    absolute_error_mean_batch_features_variable.assign(value = update_mean_batch(count_a = absolute_error_count_batch_features_variable, \n",
    "                                                                                                 mean_a = absolute_error_mean_batch_features_variable, \n",
    "                                                                                                 count_b = current_batch_size, \n",
    "                                                                                                 mean_b = absolute_error_mean_batch_features)) # shape = (sequence_length,)\n",
    "                    \n",
    "                    absolute_error_count_batch_features_variable.assign(value = update_count(count_a = absolute_error_count_batch_features_variable, \n",
    "                                                                                             count_b = current_batch_size)) # shape = ()\n",
    "\n",
    "                    absolute_error_inverse_covariance_matrix_batch_features_variable.assign(value = tf.matrix_inverse(input = absolute_error_covariance_matrix_batch_features_variable)) # shape = (sequence_length, sequence_length)\n",
    "\n",
    "                    return absolute_error_count_batch_time_variable, absolute_error_mean_batch_time_variable, absolute_error_covariance_matrix_batch_time_variable, absolute_error_inverse_covariance_matrix_batch_time_variable, absolute_error_count_batch_features_variable, absolute_error_mean_batch_features_variable, absolute_error_covariance_matrix_batch_features_variable, absolute_error_inverse_covariance_matrix_batch_features_variable\n",
    "                \n",
    "                # Check if batch is a singleton or not, very important for covariance math\n",
    "                singleton_batch_condition = tf.equal(x = current_batch_size, y = 1) # shape = ()\n",
    "                \n",
    "                absolute_error_count_batch_time_variable, absolute_error_mean_batch_time_variable, absolute_error_covariance_matrix_batch_time_variable, absolute_error_inverse_covariance_matrix_batch_time_variable, absolute_error_count_batch_features_variable, absolute_error_mean_batch_features_variable, absolute_error_covariance_matrix_batch_features_variable, absolute_error_inverse_covariance_matrix_batch_features_variable = \\\n",
    "                    tf.cond(pred = singleton_batch_condition, \n",
    "                            true_fn = lambda: singleton_batch_mahalanobis_distance_variable_updating(absolute_error, absolute_error_count_batch_time_variable, absolute_error_mean_batch_time_variable, absolute_error_covariance_matrix_batch_time_variable, absolute_error_inverse_covariance_matrix_batch_time_variable, absolute_error_count_batch_features_variable, absolute_error_mean_batch_features_variable, absolute_error_covariance_matrix_batch_features_variable, absolute_error_inverse_covariance_matrix_batch_features_variable), \n",
    "                            false_fn = lambda: non_singleton_batch_mahalanobis_distance_variable_updating(absolute_error, absolute_error_count_batch_time_variable, absolute_error_mean_batch_time_variable, absolute_error_covariance_matrix_batch_time_variable, absolute_error_inverse_covariance_matrix_batch_time_variable, absolute_error_count_batch_features_variable, absolute_error_mean_batch_features_variable, absolute_error_covariance_matrix_batch_features_variable, absolute_error_inverse_covariance_matrix_batch_features_variable))\n",
    "    else: # mode == tf.estimator.ModeKeys.PREDICT or (mode == tf.estimator.ModeKeys.EVAL and params[\"evaluation_mode\"] == \"tune_anomaly_thresholds\")\n",
    "        def mahalanobis_distance(error_vectors_reshaped, mean_vector, inverse_covariance_matrix, final_shape):\n",
    "            error_vectors_reshaped_centered = error_vectors_reshaped - mean_vector # time_shape = (current_batch_size * sequence_length, number_of_features), features_shape = (current_batch_size * number_of_features, sequence_length)\n",
    "#             print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: mahalanobis_distance: error_vectors_reshaped_centered = \\n{}\".format(error_vectors_reshaped_centered))\n",
    "\n",
    "            mahalanobis_right_matrix_product = tf.matmul(a = inverse_covariance_matrix, # time_shape = (number_of_features, current_batch_size * sequence_length), features_shape = (sequence_length, current_batch_size * number_of_features)\n",
    "                                                         b = error_vectors_reshaped_centered,\n",
    "                                                         transpose_b = True)\n",
    "#             print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: mahalanobis_distance: mahalanobis_right_matrix_product = \\n{}\".format(mahalanobis_right_matrix_product))\n",
    "\n",
    "\n",
    "            mahalanobis_distance_vectorized = tf.matmul(a = error_vectors_reshaped_centered, # time_shape = (current_batch_size * sequence_length, current_batch_size * sequence_length), features_shape = (current_batch_size * number_of_features, current_batch_size * number_of_features)\n",
    "                                                        b = mahalanobis_right_matrix_product)\n",
    "#             print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: mahalanobis_distance: mahalanobis_distance_vectorized = \\n{}\".format(mahalanobis_distance_vectorized))\n",
    "#             print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: mahalanobis_distance: mahalanobis_distance_vectorized.shape = \\n{}\".format(mahalanobis_distance_vectorized.shape))\n",
    "\n",
    "            mahalanobis_distance_flat = tf.diag_part(input = mahalanobis_distance_vectorized) # time_shape = (current_batch_size * sequence_length,), features_shape = (current_batch_size * number_of_features,)\n",
    "#             print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: mahalanobis_distance: mahalanobis_distance_flat = \\n{}\".format(mahalanobis_distance_flat))\n",
    "#             print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: mahalanobis_distance: mahalanobis_distance_flat.shape = \\n{}\".format(mahalanobis_distance_flat.shape))\n",
    "\n",
    "            mahalanobis_distance_final_shaped = tf.reshape(tensor = mahalanobis_distance_flat, shape = [-1, final_shape]) # time_shape = (current_batch_size, sequence_length), features_shape = (current_batch_size, number_of_features)\n",
    "#             print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: mahalanobis_distance: mahalanobis_distance_final_shaped = \\n{}\".format(mahalanobis_distance_final_shaped))\n",
    "\n",
    "            mahalanobis_distance_final_shaped_abs = tf.abs(x = mahalanobis_distance_final_shaped) # time_shape = (current_batch_size, sequence_length), features_shape = (current_batch_size, number_of_features)\n",
    "#             print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: mahalanobis_distance: mahalanobis_distance_final_shaped_abs = \\n{}\".format(mahalanobis_distance_final_shaped_abs))\n",
    "            \n",
    "            return mahalanobis_distance_final_shaped_abs\n",
    "          \n",
    "        absolute_error = tf.abs(x = Y - predictions) # shape = (current_batch_size, sequence_length, number_of_features)\n",
    "#         print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: absolute_error = \\n{}\".format(absolute_error))\n",
    "        \n",
    "        with tf.variable_scope(name_or_scope = \"mahalanobis_distance_variables\", reuse = tf.AUTO_REUSE):\n",
    "            # Time based\n",
    "            absolute_error_reshaped_batch_time = tf.reshape(tensor = absolute_error,  # shape = (current_batch_size * sequence_length, number_of_features)\n",
    "                                                            shape = [current_batch_size * params[\"sequence_length\"], number_of_features])\n",
    "#             print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: absolute_error_reshaped_batch_time = \\n{}\".format(absolute_error_reshaped_batch_time))\n",
    "\n",
    "            mahalanobis_distance_batch_time = mahalanobis_distance(error_vectors_reshaped = absolute_error_reshaped_batch_time,  # shape = (current_batch_size, sequence_length)\n",
    "                                                                   mean_vector = absolute_error_mean_batch_time_variable, \n",
    "                                                                   inverse_covariance_matrix = absolute_error_inverse_covariance_matrix_batch_time_variable, \n",
    "                                                                   final_shape = params[\"sequence_length\"])\n",
    "#             print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: mahalanobis_distance_batch_time = \\n{}\".format(mahalanobis_distance_batch_time))\n",
    "#             print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: mahalanobis_distance_batch_time.shape = \\n{}\".format(mahalanobis_distance_batch_time.shape))\n",
    "\n",
    "            # Features based\n",
    "            absolute_error_mapped_batch_features = tf.map_fn(fn = lambda x: tf.transpose(a = absolute_error[x, :, :]), # shape = (current_batch_size, number_of_features, sequence_length)\n",
    "                                                             elems = tf.range(start = 0, limit = current_batch_size, dtype = tf.int64), \n",
    "                                                             dtype = tf.float64)\n",
    "#             print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: absolute_error_mapped_batch_features = \\n{}\".format(absolute_error_mapped_batch_features))\n",
    "\n",
    "            absolute_error_reshaped_batch_features = tf.reshape(tensor = absolute_error_mapped_batch_features, # shape = (current_batch_size * number_of_features, sequence_length)\n",
    "                                                                shape = [current_batch_size * number_of_features, params[\"sequence_length\"]])\n",
    "#             print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: absolute_error_reshaped_batch_features = \\n{}\".format(absolute_error_reshaped_batch_features))\n",
    "\n",
    "            mahalanobis_distance_batch_features = mahalanobis_distance(error_vectors_reshaped = absolute_error_reshaped_batch_features, # shape = (current_batch_size, number_of_features)\n",
    "                                                                       mean_vector = absolute_error_mean_batch_features_variable, \n",
    "                                                                       inverse_covariance_matrix = absolute_error_inverse_covariance_matrix_batch_features_variable,\n",
    "                                                                       final_shape = number_of_features)\n",
    "#             print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: mahalanobis_distance_batch_features = \\n{}\".format(mahalanobis_distance_batch_features))\n",
    "#             print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: mahalanobis_distance_batch_features.shape = \\n{}\".format(mahalanobis_distance_batch_features.shape))\n",
    "            \n",
    "        batch_time_anomaly_flags = tf.where(condition = tf.reduce_any(input_tensor = tf.greater(x = tf.abs(x = mahalanobis_distance_batch_time), # shape = (current_batch_size,)\n",
    "                                                                                                y = params[\"time_anomaly_threshold\"]), \n",
    "                                                                      axis = 1), \n",
    "                                            x = tf.ones(shape = [current_batch_size], dtype = tf.int64), \n",
    "                                            y = tf.zeros(shape = [current_batch_size], dtype = tf.int64))\n",
    "        \n",
    "        batch_features_anomaly_flags = tf.where(condition = tf.reduce_any(input_tensor = tf.greater(x = tf.abs(x = mahalanobis_distance_batch_features), # shape = (current_batch_size,)\n",
    "                                                                                                    y = params[\"features_anomaly_threshold\"]), \n",
    "                                                                          axis = 1), \n",
    "                                                x = tf.ones(shape = [current_batch_size], dtype = tf.int64), \n",
    "                                                y = tf.zeros(shape = [current_batch_size], dtype = tf.int64))\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.EVAL:\n",
    "            # Reconstruction loss on evaluation set\n",
    "            loss = tf.losses.mean_squared_error(labels = Y, predictions = predictions)\n",
    "            \n",
    "            # Anomaly detection eval metrics\n",
    "            # Time based\n",
    "            batch_time_anomaly_true_positives = tf.metrics.true_positives(labels = labels, predictions = batch_time_anomaly_flags)\n",
    "            print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: batch_time_anomaly_true_positives = \\n{}\".format(batch_time_anomaly_true_positives))\n",
    "            batch_time_anomaly_false_negatives = tf.metrics.false_negatives(labels = labels, predictions = batch_time_anomaly_flags)\n",
    "            print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: batch_time_anomaly_false_negatives = \\n{}\".format(batch_time_anomaly_false_negatives))\n",
    "            batch_time_anomaly_false_positives = tf.metrics.false_positives(labels = labels, predictions = batch_time_anomaly_flags)\n",
    "            print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: batch_time_anomaly_false_positives = \\n{}\".format(batch_time_anomaly_false_positives))\n",
    "            batch_time_anomaly_true_negatives = tf.metrics.true_negatives(labels = labels, predictions = batch_time_anomaly_flags)\n",
    "            print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: batch_time_anomaly_true_negatives = \\n{}\".format(batch_time_anomaly_true_negatives))\n",
    "            \n",
    "            batch_time_anomaly_accuracy = tf.metrics.accuracy(labels = labels, predictions = batch_time_anomaly_flags)\n",
    "            print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: batch_time_anomaly_accuracy = \\n{}\".format(batch_time_anomaly_accuracy))\n",
    "            batch_time_anomaly_precision = tf.metrics.precision(labels = labels, predictions = batch_time_anomaly_flags)\n",
    "            print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: batch_time_anomaly_precision = \\n{}\".format(batch_time_anomaly_precision))\n",
    "            batch_time_anomaly_recall = tf.metrics.recall(labels = labels, predictions = batch_time_anomaly_flags)\n",
    "            print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: batch_time_anomaly_recall = \\n{}\".format(batch_time_anomaly_recall))\n",
    "#             batch_time_anomaly_f_beta_score = (1.0 + params[\"f_score_beta\"]**2) * batch_time_anomaly_precision * batch_time_anomaly_recall / (params[\"f_score_beta\"]**2 * batch_time_anomaly_precision + batch_time_anomaly_recall)\n",
    "#             print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: batch_time_anomaly_f_beta_score = \\n{}\".format(batch_time_anomaly_f_beta_score))\n",
    "            \n",
    "            # Feature based\n",
    "            batch_features_anomaly_true_positives = tf.metrics.true_positives(labels = labels, predictions = batch_features_anomaly_flags)\n",
    "            print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: batch_features_anomaly_true_positives = \\n{}\".format(batch_features_anomaly_true_positives))\n",
    "            batch_features_anomaly_false_negatives = tf.metrics.false_negatives(labels = labels, predictions = batch_features_anomaly_flags)\n",
    "            print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: batch_features_anomaly_false_negatives = \\n{}\".format(batch_features_anomaly_false_negatives))\n",
    "            batch_features_anomaly_false_positives = tf.metrics.false_positives(labels = labels, predictions = batch_features_anomaly_flags)\n",
    "            print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: batch_features_anomaly_false_positives = \\n{}\".format(batch_features_anomaly_false_positives))\n",
    "            batch_features_anomaly_true_negatives = tf.metrics.true_negatives(labels = labels, predictions = batch_features_anomaly_flags)\n",
    "            print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: batch_features_anomaly_true_negatives = \\n{}\".format(batch_features_anomaly_true_negatives))\n",
    "        \n",
    "            batch_features_anomaly_accuracy = tf.metrics.accuracy(labels = labels, predictions = batch_features_anomaly_flags)\n",
    "            print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: batch_features_anomaly_accuracy = \\n{}\".format(batch_features_anomaly_accuracy))\n",
    "            batch_features_anomaly_precision = tf.metrics.precision(labels = labels, predictions = batch_features_anomaly_flags)\n",
    "            print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: batch_features_anomaly_precision = \\n{}\".format(batch_features_anomaly_precision))\n",
    "            batch_features_anomaly_recall = tf.metrics.recall(labels = labels, predictions = batch_features_anomaly_flags)\n",
    "            print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: batch_features_anomaly_recall = \\n{}\".format(batch_features_anomaly_recall))\n",
    "#             batch_features_anomaly_f_beta_score = (1.0 + params[\"f_score_beta\"]**2) * batch_features_anomaly_precision * batch_features_anomaly_recall / (params[\"f_score_beta\"]**2 * batch_features_anomaly_precision + batch_features_anomaly_recall)\n",
    "#             print(\"lstm_encoder_decoder_autoencoder_anomaly_detection: batch_features_anomaly_f_beta_score = \\n{}\".format(batch_features_anomaly_f_beta_score))\n",
    "            \n",
    "            eval_metric_ops = {\n",
    "                # Time based\n",
    "                \"batch_time_anomaly_true_positives\": batch_time_anomaly_true_positives,\n",
    "                \"batch_time_anomaly_false_negatives\": batch_time_anomaly_false_negatives,\n",
    "                \"batch_time_anomaly_false_positives\": batch_time_anomaly_false_positives,\n",
    "                \"batch_time_anomaly_true_negatives\": batch_time_anomaly_true_negatives,\n",
    "                \n",
    "                \"batch_time_anomaly_accuracy\": batch_time_anomaly_accuracy,\n",
    "                \"batch_time_anomaly_precision\": batch_time_anomaly_precision,\n",
    "                \"batch_time_anomaly_recall\": batch_time_anomaly_recall,\n",
    "#                 \"batch_time_anomaly_f_beta_score\": batch_time_anomaly_f_beta_score,\n",
    "                \n",
    "                 # Feature based\n",
    "                \"batch_features_anomaly_true_positives\": batch_features_anomaly_true_positives,\n",
    "                \"batch_features_anomaly_false_negatives\": batch_features_anomaly_false_negatives,\n",
    "                \"batch_features_anomaly_false_positives\": batch_features_anomaly_false_positives,\n",
    "                \"batch_features_anomaly_true_negatives\": batch_features_anomaly_true_negatives,\n",
    "                \n",
    "                \"batch_features_anomaly_accuracy\": batch_features_anomaly_accuracy,\n",
    "                \"batch_features_anomaly_precision\": batch_features_anomaly_precision,\n",
    "                \"batch_features_anomaly_recall\": batch_features_anomaly_recall,\n",
    "#                 \"batch_features_anomaly_f_beta_score\": batch_features_anomaly_f_beta_score\n",
    "            }\n",
    "        else: # mode == tf.estimator.ModeKeys.PREDICT\n",
    "            # Create predictions dictionary\n",
    "            predictions_dict = {\"predictions\": predictions, \n",
    "                                \"mahalanobis_distance_batch_time\": mahalanobis_distance_batch_time, \n",
    "                                \"mahalanobis_distance_batch_features\": mahalanobis_distance_batch_features, \n",
    "                                \"batch_time_anomaly_flags\": batch_time_anomaly_flags, \n",
    "                                \"batch_features_anomaly_flags\": batch_features_anomaly_flags}\n",
    "\n",
    "            # Create export outputs\n",
    "            export_outputs = {\"predict_export_outputs\": tf.estimator.export.PredictOutput(outputs = predictions_dict)}\n",
    "\n",
    "    # Return EstimatorSpec\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode = mode,\n",
    "        predictions = predictions_dict,\n",
    "        loss = loss,\n",
    "        train_op = train_op,\n",
    "        eval_metric_ops = eval_metric_ops,\n",
    "        export_outputs = export_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our serving input function to accept the data at serving and send it in the right format to our custom estimator\n",
    "def serving_input_fn(sequence_length):\n",
    "    # This function fixes the shape and type of our input strings\n",
    "    def fix_shape_and_type_for_serving(placeholder):\n",
    "        current_batch_size = tf.shape(input = placeholder, out_type = tf.int64)[0]\n",
    "        \n",
    "        # String split each string in the batch and output the values from the resulting SparseTensors\n",
    "        split_string = tf.stack(values = tf.map_fn( # shape = (batch_size, sequence_length)\n",
    "            fn = lambda x: tf.string_split(source = [placeholder[x]], delimiter = ',').values, \n",
    "            elems = tf.range(start = 0, limit = current_batch_size, dtype = tf.int64), \n",
    "            dtype = tf.string), axis = 0)\n",
    "#         print(\"serving_input_fn: fix_shape_and_type_for_serving: split_string = {}\".format(split_string))\n",
    "        \n",
    "        # Convert each string in the split tensor to float\n",
    "        feature_tensor = tf.string_to_number(string_tensor = split_string, out_type = tf.float64) # shape = (batch_size, sequence_length)\n",
    "#         print(\"serving_input_fn: fix_shape_and_type_for_serving: feature_tensor = {}\".format(feature_tensor))\n",
    "        \n",
    "        return feature_tensor\n",
    "    \n",
    "    # This function fixes dynamic shape ambiguity of last dimension so that we will be able to use it in our DNN (since tf.layers.dense require the last dimension to be known)\n",
    "    def get_shape_and_set_modified_shape_2D(tensor, additional_dimension_sizes):\n",
    "        # Get static shape for tensor and convert it to list\n",
    "        shape = tensor.get_shape().as_list()\n",
    "        # Set outer shape to additional_dimension_sizes[0] since we know that this is the correct size\n",
    "        shape[1] = additional_dimension_sizes[0]\n",
    "        # Set the shape of tensor to our modified shape\n",
    "        tensor.set_shape(shape = shape) # shape = (batch_size, additional_dimension_sizes[0])\n",
    "#         print(\"serving_input_fn: get_shape_and_set_modified_shape_2D: tensor = {}, additional_dimension_sizes = {}\".format(tensor, additional_dimension_sizes))\n",
    "        return tensor\n",
    "            \n",
    "    # Create placeholders to accept the data sent to the model at serving time\n",
    "    feature_placeholders = { # all features come in as a batch of strings, shape = (batch_size,), this was so because of passing the arrays to online ml-engine prediction\n",
    "        feature: tf.placeholder(dtype = tf.string, shape = [None]) for feature in UNLABELED_CSV_COLUMNS\n",
    "    }\n",
    "#     print(\"\\nserving_input_fn: feature_placeholders = {}\".format(feature_placeholders))\n",
    "    \n",
    "    # Create feature tensors\n",
    "    features = {key: fix_shape_and_type_for_serving(placeholder = tensor) for key, tensor in feature_placeholders.items()}\n",
    "#     print(\"serving_input_fn: features = {}\".format(features))\n",
    "    \n",
    "    # Fix dynamic shape ambiguity of feature tensors for our DNN\n",
    "    features = {key: get_shape_and_set_modified_shape_2D(tensor = tensor, additional_dimension_sizes = [sequence_length]) for key, tensor in features.items()}\n",
    "#     print(\"serving_input_fn: features = {}\".format(features))\n",
    "\n",
    "    return tf.estimator.export.ServingInputReceiver(features = features, receiver_tensors = feature_placeholders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create estimator to train and evaluate\n",
    "def train_and_evaluate(args):\n",
    "    # Create our custom estimator using our model function\n",
    "    estimator = tf.estimator.Estimator(\n",
    "        model_fn = lstm_encoder_decoder_autoencoder_anomaly_detection,\n",
    "        model_dir = args['output_dir'],\n",
    "        params = {\n",
    "            \"sequence_length\": args[\"sequence_length\"],\n",
    "            \"reverse_labels_sequence\": args[\"reverse_labels_sequence\"],\n",
    "            \"encoder_lstm_hidden_units\": args[\"encoder_lstm_hidden_units\"],\n",
    "            \"decoder_lstm_hidden_units\": args[\"decoder_lstm_hidden_units\"],\n",
    "            \"lstm_dropout_output_keep_probs\": args[\"lstm_dropout_output_keep_probs\"], \n",
    "            \"dnn_hidden_units\": args[\"dnn_hidden_units\"], \n",
    "            \"learning_rate\": args[\"learning_rate\"],\n",
    "            \"evaluation_mode\": args[\"evaluation_mode\"],\n",
    "            \"time_anomaly_threshold\": args[\"time_anomaly_threshold\"], \n",
    "            \"features_anomaly_threshold\": args[\"features_anomaly_threshold\"]})\n",
    "    \n",
    "    if args[\"evaluation_mode\"] == \"reconstruction\":\n",
    "        early_stopping_hook = tf.contrib.estimator.stop_if_no_decrease_hook(\n",
    "            estimator = estimator,\n",
    "            metric_name = \"rmse\",\n",
    "            max_steps_without_decrease = 100,\n",
    "            min_steps = 1000,\n",
    "            run_every_secs = 60,\n",
    "            run_every_steps = None)\n",
    "\n",
    "        # Create train spec to read in our training data\n",
    "        train_spec = tf.estimator.TrainSpec(\n",
    "            input_fn = read_dataset(\n",
    "                filename = args[\"train_file_pattern\"],\n",
    "                mode = tf.estimator.ModeKeys.TRAIN, \n",
    "                batch_size = args[\"train_batch_size\"],\n",
    "                params = args),\n",
    "            max_steps = args[\"train_steps\"], \n",
    "            hooks = [early_stopping_hook])\n",
    "\n",
    "        # Create eval spec to read in our validation data and export our model\n",
    "        eval_spec = tf.estimator.EvalSpec(\n",
    "            input_fn = read_dataset(\n",
    "                filename = args[\"eval_file_pattern\"], \n",
    "                mode = tf.estimator.ModeKeys.EVAL, \n",
    "                batch_size = args[\"eval_batch_size\"],\n",
    "                params = args),\n",
    "            steps = None,\n",
    "            start_delay_secs = args[\"start_delay_secs\"], # start evaluating after N seconds\n",
    "            throttle_secs = args[\"throttle_secs\"])    # evaluate every N seconds\n",
    "\n",
    "        # Create train and evaluate loop to train and evaluate our estimator\n",
    "        tf.estimator.train_and_evaluate(estimator = estimator, train_spec = train_spec, eval_spec = eval_spec)\n",
    "    else:\n",
    "        if args[\"evaluation_mode\"] == \"calculate_error_distribution_statistics\":\n",
    "            # Get final mahalanobis statistics over the entire validation_1 dataset\n",
    "            estimator.evaluate(\n",
    "                input_fn = read_dataset(\n",
    "                    filename = arguments[\"eval_file_pattern\"], \n",
    "                    mode = tf.estimator.ModeKeys.EVAL, \n",
    "                    batch_size = 32,\n",
    "                    params = args),\n",
    "                steps = None)\n",
    "\n",
    "        elif args[\"evaluation_mode\"] == \"tune_anomaly_thresholds\":\n",
    "            # Tune anomaly thresholds using valdiation_2 and validation_anomaly datasets\n",
    "            estimator.evaluate(\n",
    "                input_fn = read_dataset(\n",
    "                    filename = arguments[\"eval_file_pattern\"], \n",
    "                    mode = tf.estimator.ModeKeys.EVAL, \n",
    "                    batch_size = 32,\n",
    "                    params = args),\n",
    "                steps = None)\n",
    "\n",
    "        # Export savedmodel with learned error distribution statistics to be used for inference\n",
    "        estimator.export_savedmodel(\n",
    "            export_dir_base = args['output_dir'] + \"/export/exporter\", \n",
    "            serving_input_receiver_fn = lambda: serving_input_fn(args[\"sequence_length\"]))\n",
    "        \n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {}\n",
    "# File arguments\n",
    "arguments[\"train_file_pattern\"] = \"data/training_normal_sequences.csv\"\n",
    "arguments[\"eval_file_pattern\"] = \"data/validation_normal_1_sequences.csv\"\n",
    "arguments[\"output_dir\"] = \"trained_model\"\n",
    "\n",
    "# Sequence shape hyperparameters\n",
    "arguments[\"sequence_length\"] = sequence_length\n",
    "arguments[\"horizon\"] = 0\n",
    "arguments[\"reverse_labels_sequence\"] = True\n",
    "\n",
    "# Architecture hyperparameters\n",
    "\n",
    "# LSTM hyperparameters\n",
    "arguments[\"encoder_lstm_hidden_units\"] = [64, 32, 16]\n",
    "arguments[\"decoder_lstm_hidden_units\"] = [16, 32, 64]\n",
    "arguments[\"lstm_dropout_output_keep_probs\"] = [1.0, 1.0, 1.0]\n",
    "\n",
    "# DNN hyperparameters\n",
    "arguments[\"dnn_hidden_units\"] = [1024, 256, 64]\n",
    "\n",
    "# Training parameters\n",
    "arguments[\"train_batch_size\"] = 32\n",
    "arguments[\"eval_batch_size\"] = 32\n",
    "arguments[\"train_steps\"] = 1000\n",
    "arguments[\"learning_rate\"] = 0.01\n",
    "arguments[\"start_delay_secs\"] = 60\n",
    "arguments[\"throttle_secs\"] = 120\n",
    "\n",
    "# Anomaly thresholds\n",
    "arguments[\"evaluation_mode\"] = \"reconstruction\"\n",
    "arguments[\"time_anomaly_threshold\"] = 2.0\n",
    "arguments[\"features_anomaly_threshold\"] = 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_master': '', '_num_ps_replicas': 0, '_save_checkpoints_steps': None, '_global_id_in_cluster': 0, '_train_distribute': None, '_task_type': 'worker', '_evaluation_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2035a4ff98>, '_log_step_count_steps': 100, '_save_checkpoints_secs': 600, '_device_fn': None, '_keep_checkpoint_max': 5, '_experimental_distribute': None, '_num_worker_replicas': 1, '_tf_random_seed': None, '_service': None, '_save_summary_steps': 100, '_is_chief': True, '_task_id': 0, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_model_dir': 'trained_model', '_eval_distribute': None, '_protocol': None, '_keep_checkpoint_every_n_hours': 10000}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "\n",
      "read_dataset: _input_fn: decode_csv: value_column = \n",
      "Tensor(\"arg0:0\", shape=(), dtype=string, device=/device:CPU:0)\n",
      "read_dataset: _input_fn: decode_csv: columns = \n",
      "[<tf.Tensor 'DecodeCSV:0' shape=() dtype=string>, <tf.Tensor 'DecodeCSV:1' shape=() dtype=string>, <tf.Tensor 'DecodeCSV:2' shape=() dtype=string>]\n",
      "read_dataset: _input_fn: decode_csv: features = \n",
      "{'tag_1': <tf.Tensor 'DecodeCSV:1' shape=() dtype=string>, 'tag_2': <tf.Tensor 'DecodeCSV:2' shape=() dtype=string>, 'tag_0': <tf.Tensor 'DecodeCSV:0' shape=() dtype=string>}\n",
      "read_dataset: _input_fn: decode_csv: features = \n",
      "{'tag_1': <tf.Tensor 'Squeeze_1:0' shape=(30,) dtype=float64>, 'tag_2': <tf.Tensor 'Squeeze_2:0' shape=(30,) dtype=float64>, 'tag_0': <tf.Tensor 'Squeeze:0' shape=(30,) dtype=float64>}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: features = \n",
      "{'tag_1': <tf.Tensor 'IteratorGetNext:1' shape=(?, 30) dtype=float64>, 'tag_2': <tf.Tensor 'IteratorGetNext:2' shape=(?, 30) dtype=float64>, 'tag_0': <tf.Tensor 'IteratorGetNext:0' shape=(?, 30) dtype=float64>}\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: labels = \n",
      "None\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: mode = \n",
      "train\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: params = \n",
      "{'learning_rate': 0.01, 'features_anomaly_threshold': 3.0, 'sequence_length': 30, 'encoder_lstm_hidden_units': [64, 32, 16], 'dnn_hidden_units': [1024, 256, 64], 'decoder_lstm_hidden_units': [16, 32, 64], 'time_anomaly_threshold': 2.0, 'reverse_labels_sequence': True, 'evaluation_mode': 'reconstruction', 'lstm_dropout_output_keep_probs': [1.0, 1.0, 1.0]}\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: current_batch_size = \n",
      "Tensor(\"strided_slice:0\", shape=(), dtype=int64)\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: number_of_features = \n",
      "3\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: X = \n",
      "Tensor(\"stack:0\", shape=(?, 30, 3), dtype=float64)\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: X_sequence = \n",
      "[<tf.Tensor 'unstack:0' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:1' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:2' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:3' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:4' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:5' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:6' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:7' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:8' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:9' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:10' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:11' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:12' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:13' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:14' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:15' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:16' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:17' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:18' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:19' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:20' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:21' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:22' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:23' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:24' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:25' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:26' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:27' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:28' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:29' shape=(?, 3) dtype=float64>]\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: Y = \n",
      "Tensor(\"ReverseSequence:0\", shape=(?, 30, 3), dtype=float64)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into trained_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.93317187, step = 0\n",
      "INFO:tensorflow:global_step/sec: 5.67836\n",
      "INFO:tensorflow:loss = 0.015570603, step = 100 (17.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0243\n",
      "INFO:tensorflow:loss = 0.011136667, step = 200 (7.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1094\n",
      "INFO:tensorflow:loss = 0.00664661, step = 300 (7.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1902\n",
      "INFO:tensorflow:loss = 0.0067727803, step = 400 (7.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1047\n",
      "INFO:tensorflow:loss = 0.00468029, step = 500 (7.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0459\n",
      "INFO:tensorflow:loss = 0.0039028204, step = 600 (7.663 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0974\n",
      "INFO:tensorflow:loss = 0.0052485825, step = 700 (7.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1071\n",
      "INFO:tensorflow:loss = 0.0025750848, step = 800 (7.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1371\n",
      "INFO:tensorflow:loss = 0.0023117566, step = 900 (7.610 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into trained_model/model.ckpt.\n",
      "\n",
      "read_dataset: _input_fn: decode_csv: value_column = \n",
      "Tensor(\"arg0:0\", shape=(), dtype=string, device=/device:CPU:0)\n",
      "read_dataset: _input_fn: decode_csv: columns = \n",
      "[<tf.Tensor 'DecodeCSV:0' shape=() dtype=string>, <tf.Tensor 'DecodeCSV:1' shape=() dtype=string>, <tf.Tensor 'DecodeCSV:2' shape=() dtype=string>]\n",
      "read_dataset: _input_fn: decode_csv: features = \n",
      "{'tag_1': <tf.Tensor 'DecodeCSV:1' shape=() dtype=string>, 'tag_2': <tf.Tensor 'DecodeCSV:2' shape=() dtype=string>, 'tag_0': <tf.Tensor 'DecodeCSV:0' shape=() dtype=string>}\n",
      "read_dataset: _input_fn: decode_csv: features = \n",
      "{'tag_1': <tf.Tensor 'Squeeze_1:0' shape=(30,) dtype=float64>, 'tag_2': <tf.Tensor 'Squeeze_2:0' shape=(30,) dtype=float64>, 'tag_0': <tf.Tensor 'Squeeze:0' shape=(30,) dtype=float64>}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: features = \n",
      "{'tag_1': <tf.Tensor 'IteratorGetNext:1' shape=(?, 30) dtype=float64>, 'tag_2': <tf.Tensor 'IteratorGetNext:2' shape=(?, 30) dtype=float64>, 'tag_0': <tf.Tensor 'IteratorGetNext:0' shape=(?, 30) dtype=float64>}\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: labels = \n",
      "None\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: mode = \n",
      "eval\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: params = \n",
      "{'learning_rate': 0.01, 'features_anomaly_threshold': 3.0, 'sequence_length': 30, 'encoder_lstm_hidden_units': [64, 32, 16], 'dnn_hidden_units': [1024, 256, 64], 'decoder_lstm_hidden_units': [16, 32, 64], 'time_anomaly_threshold': 2.0, 'reverse_labels_sequence': True, 'evaluation_mode': 'reconstruction', 'lstm_dropout_output_keep_probs': [1.0, 1.0, 1.0]}\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: current_batch_size = \n",
      "Tensor(\"strided_slice:0\", shape=(), dtype=int64)\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: number_of_features = \n",
      "3\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: X = \n",
      "Tensor(\"stack:0\", shape=(?, 30, 3), dtype=float64)\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: X_sequence = \n",
      "[<tf.Tensor 'unstack:0' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:1' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:2' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:3' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:4' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:5' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:6' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:7' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:8' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:9' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:10' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:11' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:12' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:13' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:14' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:15' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:16' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:17' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:18' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:19' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:20' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:21' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:22' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:23' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:24' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:25' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:26' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:27' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:28' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:29' shape=(?, 3) dtype=float64>]\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: Y = \n",
      "Tensor(\"ReverseSequence:0\", shape=(?, 30, 3), dtype=float64)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-25T21:18:38Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from trained_model/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-25-21:18:40\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.0024370076, mae = 0.039468903, rmse = 0.049375236\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: trained_model/model.ckpt-1000\n",
      "INFO:tensorflow:Loss for final step: 0.0025756713.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "shutil.rmtree(path = arguments[\"output_dir\"], ignore_errors = True) # start fresh each time\n",
    "estimator = train_and_evaluate(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_master': '', '_num_ps_replicas': 0, '_save_checkpoints_steps': None, '_global_id_in_cluster': 0, '_train_distribute': None, '_task_type': 'worker', '_evaluation_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2035a4f0f0>, '_log_step_count_steps': 100, '_save_checkpoints_secs': 600, '_device_fn': None, '_keep_checkpoint_max': 5, '_experimental_distribute': None, '_num_worker_replicas': 1, '_tf_random_seed': None, '_service': None, '_save_summary_steps': 100, '_is_chief': True, '_task_id': 0, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_model_dir': 'trained_model', '_eval_distribute': None, '_protocol': None, '_keep_checkpoint_every_n_hours': 10000}\n",
      "\n",
      "read_dataset: _input_fn: decode_csv: value_column = \n",
      "Tensor(\"arg0:0\", shape=(), dtype=string, device=/device:CPU:0)\n",
      "read_dataset: _input_fn: decode_csv: columns = \n",
      "[<tf.Tensor 'DecodeCSV:0' shape=() dtype=string>, <tf.Tensor 'DecodeCSV:1' shape=() dtype=string>, <tf.Tensor 'DecodeCSV:2' shape=() dtype=string>]\n",
      "read_dataset: _input_fn: decode_csv: features = \n",
      "{'tag_1': <tf.Tensor 'DecodeCSV:1' shape=() dtype=string>, 'tag_2': <tf.Tensor 'DecodeCSV:2' shape=() dtype=string>, 'tag_0': <tf.Tensor 'DecodeCSV:0' shape=() dtype=string>}\n",
      "read_dataset: _input_fn: decode_csv: features = \n",
      "{'tag_1': <tf.Tensor 'Squeeze_1:0' shape=(30,) dtype=float64>, 'tag_2': <tf.Tensor 'Squeeze_2:0' shape=(30,) dtype=float64>, 'tag_0': <tf.Tensor 'Squeeze:0' shape=(30,) dtype=float64>}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: features = \n",
      "{'tag_1': <tf.Tensor 'IteratorGetNext:1' shape=(?, 30) dtype=float64>, 'tag_2': <tf.Tensor 'IteratorGetNext:2' shape=(?, 30) dtype=float64>, 'tag_0': <tf.Tensor 'IteratorGetNext:0' shape=(?, 30) dtype=float64>}\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: labels = \n",
      "None\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: mode = \n",
      "eval\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: params = \n",
      "{'learning_rate': 0.01, 'features_anomaly_threshold': 3.0, 'sequence_length': 30, 'encoder_lstm_hidden_units': [64, 32, 16], 'dnn_hidden_units': [1024, 256, 64], 'decoder_lstm_hidden_units': [16, 32, 64], 'time_anomaly_threshold': 2.0, 'reverse_labels_sequence': True, 'evaluation_mode': 'calculate_error_distribution_statistics', 'lstm_dropout_output_keep_probs': [1.0, 1.0, 1.0]}\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: current_batch_size = \n",
      "Tensor(\"strided_slice:0\", shape=(), dtype=int64)\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: number_of_features = \n",
      "3\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: X = \n",
      "Tensor(\"stack:0\", shape=(?, 30, 3), dtype=float64)\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: X_sequence = \n",
      "[<tf.Tensor 'unstack:0' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:1' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:2' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:3' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:4' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:5' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:6' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:7' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:8' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:9' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:10' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:11' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:12' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:13' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:14' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:15' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:16' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:17' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:18' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:19' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:20' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:21' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:22' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:23' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:24' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:25' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:26' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:27' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:28' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:29' shape=(?, 3) dtype=float64>]\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: Y = \n",
      "Tensor(\"ReverseSequence:0\", shape=(?, 30, 3), dtype=float64)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-25T21:18:46Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from trained_model/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-25-21:18:48\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.0024370076\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: trained_model/model.ckpt-1000\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: features = \n",
      "{'tag_1': <tf.Tensor 'StringToNumber:0' shape=(?, 30) dtype=float64>, 'tag_2': <tf.Tensor 'StringToNumber_1:0' shape=(?, 30) dtype=float64>, 'tag_0': <tf.Tensor 'StringToNumber_2:0' shape=(?, 30) dtype=float64>}\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: labels = \n",
      "None\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: mode = \n",
      "infer\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: params = \n",
      "{'learning_rate': 0.01, 'features_anomaly_threshold': 3.0, 'sequence_length': 30, 'encoder_lstm_hidden_units': [64, 32, 16], 'dnn_hidden_units': [1024, 256, 64], 'decoder_lstm_hidden_units': [16, 32, 64], 'time_anomaly_threshold': 2.0, 'reverse_labels_sequence': True, 'evaluation_mode': 'calculate_error_distribution_statistics', 'lstm_dropout_output_keep_probs': [1.0, 1.0, 1.0]}\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: current_batch_size = \n",
      "Tensor(\"strided_slice_3:0\", shape=(), dtype=int64)\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: number_of_features = \n",
      "3\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: X = \n",
      "Tensor(\"stack:0\", shape=(?, 30, 3), dtype=float64)\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: X_sequence = \n",
      "[<tf.Tensor 'unstack:0' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:1' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:2' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:3' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:4' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:5' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:6' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:7' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:8' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:9' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:10' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:11' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:12' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:13' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:14' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:15' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:16' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:17' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:18' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:19' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:20' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:21' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:22' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:23' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:24' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:25' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:26' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:27' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:28' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:29' shape=(?, 3) dtype=float64>]\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: Y = \n",
      "Tensor(\"ReverseSequence:0\", shape=(?, 30, 3), dtype=float64)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from trained_model/model.ckpt-1000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: trained_model/export/exporter/temp-b'1553548728'/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "arguments[\"evaluation_mode\"] = \"calculate_error_distribution_statistics\"\n",
    "estimator = train_and_evaluate(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_master': '', '_num_ps_replicas': 0, '_save_checkpoints_steps': None, '_global_id_in_cluster': 0, '_train_distribute': None, '_task_type': 'worker', '_evaluation_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2035a4f198>, '_log_step_count_steps': 100, '_save_checkpoints_secs': 600, '_device_fn': None, '_keep_checkpoint_max': 5, '_experimental_distribute': None, '_num_worker_replicas': 1, '_tf_random_seed': None, '_service': None, '_save_summary_steps': 100, '_is_chief': True, '_task_id': 0, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_model_dir': 'trained_model', '_eval_distribute': None, '_protocol': None, '_keep_checkpoint_every_n_hours': 10000}\n",
      "\n",
      "read_dataset: _input_fn: decode_csv: value_column = \n",
      "Tensor(\"arg0:0\", shape=(), dtype=string, device=/device:CPU:0)\n",
      "read_dataset: _input_fn: decode_csv: columns = \n",
      "[<tf.Tensor 'DecodeCSV:0' shape=() dtype=string>, <tf.Tensor 'DecodeCSV:1' shape=() dtype=string>, <tf.Tensor 'DecodeCSV:2' shape=() dtype=string>, <tf.Tensor 'DecodeCSV:3' shape=() dtype=float32>]\n",
      "read_dataset: _input_fn: decode_csv: features = \n",
      "{'anomalous_sequence_flag': <tf.Tensor 'DecodeCSV:3' shape=() dtype=float32>, 'tag_1': <tf.Tensor 'DecodeCSV:1' shape=() dtype=string>, 'tag_2': <tf.Tensor 'DecodeCSV:2' shape=() dtype=string>, 'tag_0': <tf.Tensor 'DecodeCSV:0' shape=() dtype=string>}\n",
      "read_dataset: _input_fn: decode_csv: labels = \n",
      "Tensor(\"Cast:0\", shape=(), dtype=float64, device=/device:CPU:0)\n",
      "read_dataset: _input_fn: decode_csv: features = \n",
      "{'tag_1': <tf.Tensor 'Squeeze_1:0' shape=(30,) dtype=float64>, 'tag_2': <tf.Tensor 'Squeeze_2:0' shape=(30,) dtype=float64>, 'tag_0': <tf.Tensor 'Squeeze:0' shape=(30,) dtype=float64>}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: features = \n",
      "{'tag_1': <tf.Tensor 'IteratorGetNext:1' shape=(?, 30) dtype=float64>, 'tag_2': <tf.Tensor 'IteratorGetNext:2' shape=(?, 30) dtype=float64>, 'tag_0': <tf.Tensor 'IteratorGetNext:0' shape=(?, 30) dtype=float64>}\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: labels = \n",
      "Tensor(\"IteratorGetNext:3\", shape=(?,), dtype=float64, device=/device:CPU:0)\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: mode = \n",
      "eval\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: params = \n",
      "{'learning_rate': 0.01, 'features_anomaly_threshold': 3.0, 'sequence_length': 30, 'encoder_lstm_hidden_units': [64, 32, 16], 'dnn_hidden_units': [1024, 256, 64], 'decoder_lstm_hidden_units': [16, 32, 64], 'time_anomaly_threshold': 2.0, 'reverse_labels_sequence': True, 'evaluation_mode': 'tune_anomaly_thresholds', 'lstm_dropout_output_keep_probs': [1.0, 1.0, 1.0]}\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: current_batch_size = \n",
      "Tensor(\"strided_slice:0\", shape=(), dtype=int64)\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: number_of_features = \n",
      "3\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: X = \n",
      "Tensor(\"stack:0\", shape=(?, 30, 3), dtype=float64)\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: X_sequence = \n",
      "[<tf.Tensor 'unstack:0' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:1' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:2' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:3' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:4' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:5' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:6' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:7' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:8' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:9' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:10' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:11' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:12' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:13' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:14' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:15' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:16' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:17' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:18' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:19' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:20' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:21' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:22' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:23' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:24' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:25' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:26' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:27' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:28' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:29' shape=(?, 3) dtype=float64>]\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: Y = \n",
      "Tensor(\"ReverseSequence:0\", shape=(?, 30, 3), dtype=float64)\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: batch_time_anomaly_true_positives = \n",
      "(<tf.Tensor 'true_positives/Identity:0' shape=() dtype=float32>, <tf.Tensor 'true_positives/AssignAdd:0' shape=() dtype=float32_ref>)\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: batch_time_anomaly_false_negatives = \n",
      "(<tf.Tensor 'false_negatives/Identity:0' shape=() dtype=float32>, <tf.Tensor 'false_negatives/AssignAdd:0' shape=() dtype=float32_ref>)\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: batch_time_anomaly_false_positives = \n",
      "(<tf.Tensor 'false_positives/Identity:0' shape=() dtype=float32>, <tf.Tensor 'false_positives/AssignAdd:0' shape=() dtype=float32_ref>)\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: batch_time_anomaly_true_negatives = \n",
      "(<tf.Tensor 'true_negatives/Identity:0' shape=() dtype=float32>, <tf.Tensor 'true_negatives/AssignAdd:0' shape=() dtype=float32_ref>)\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: batch_time_anomaly_accuracy = \n",
      "(<tf.Tensor 'accuracy/value:0' shape=() dtype=float32>, <tf.Tensor 'accuracy/update_op:0' shape=() dtype=float32>)\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: batch_time_anomaly_precision = \n",
      "(<tf.Tensor 'precision/value:0' shape=() dtype=float32>, <tf.Tensor 'precision/update_op:0' shape=() dtype=float32>)\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: batch_time_anomaly_recall = \n",
      "(<tf.Tensor 'recall/value:0' shape=() dtype=float32>, <tf.Tensor 'recall/update_op:0' shape=() dtype=float32>)\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: batch_features_anomaly_true_positives = \n",
      "(<tf.Tensor 'true_positives_1/Identity:0' shape=() dtype=float32>, <tf.Tensor 'true_positives_1/AssignAdd:0' shape=() dtype=float32_ref>)\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: batch_features_anomaly_false_negatives = \n",
      "(<tf.Tensor 'false_negatives_1/Identity:0' shape=() dtype=float32>, <tf.Tensor 'false_negatives_1/AssignAdd:0' shape=() dtype=float32_ref>)\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: batch_features_anomaly_false_positives = \n",
      "(<tf.Tensor 'false_positives_1/Identity:0' shape=() dtype=float32>, <tf.Tensor 'false_positives_1/AssignAdd:0' shape=() dtype=float32_ref>)\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: batch_features_anomaly_true_negatives = \n",
      "(<tf.Tensor 'true_negatives_1/Identity:0' shape=() dtype=float32>, <tf.Tensor 'true_negatives_1/AssignAdd:0' shape=() dtype=float32_ref>)\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: batch_features_anomaly_accuracy = \n",
      "(<tf.Tensor 'accuracy_1/value:0' shape=() dtype=float32>, <tf.Tensor 'accuracy_1/update_op:0' shape=() dtype=float32>)\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: batch_features_anomaly_precision = \n",
      "(<tf.Tensor 'precision_1/value:0' shape=() dtype=float32>, <tf.Tensor 'precision_1/update_op:0' shape=() dtype=float32>)\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: batch_features_anomaly_recall = \n",
      "(<tf.Tensor 'recall_1/value:0' shape=() dtype=float32>, <tf.Tensor 'recall_1/update_op:0' shape=() dtype=float32>)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-25T21:18:57Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from trained_model/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-25-21:19:01\n",
      "INFO:tensorflow:Saving dict for global step 1000: batch_features_anomaly_accuracy = 0.5, batch_features_anomaly_false_negatives = 500.0, batch_features_anomaly_false_positives = 0.0, batch_features_anomaly_precision = 0.0, batch_features_anomaly_recall = 0.0, batch_features_anomaly_true_negatives = 500.0, batch_features_anomaly_true_positives = 0.0, batch_time_anomaly_accuracy = 0.5, batch_time_anomaly_false_negatives = 500.0, batch_time_anomaly_false_positives = 0.0, batch_time_anomaly_precision = 0.0, batch_time_anomaly_recall = 0.0, batch_time_anomaly_true_negatives = 500.0, batch_time_anomaly_true_positives = 0.0, global_step = 1000, loss = 0.080945894\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: trained_model/model.ckpt-1000\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: features = \n",
      "{'tag_1': <tf.Tensor 'StringToNumber:0' shape=(?, 30) dtype=float64>, 'tag_2': <tf.Tensor 'StringToNumber_1:0' shape=(?, 30) dtype=float64>, 'tag_0': <tf.Tensor 'StringToNumber_2:0' shape=(?, 30) dtype=float64>}\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: labels = \n",
      "None\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: mode = \n",
      "infer\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: params = \n",
      "{'learning_rate': 0.01, 'features_anomaly_threshold': 3.0, 'sequence_length': 30, 'encoder_lstm_hidden_units': [64, 32, 16], 'dnn_hidden_units': [1024, 256, 64], 'decoder_lstm_hidden_units': [16, 32, 64], 'time_anomaly_threshold': 2.0, 'reverse_labels_sequence': True, 'evaluation_mode': 'tune_anomaly_thresholds', 'lstm_dropout_output_keep_probs': [1.0, 1.0, 1.0]}\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: current_batch_size = \n",
      "Tensor(\"strided_slice_3:0\", shape=(), dtype=int64)\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: number_of_features = \n",
      "3\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: X = \n",
      "Tensor(\"stack:0\", shape=(?, 30, 3), dtype=float64)\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: X_sequence = \n",
      "[<tf.Tensor 'unstack:0' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:1' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:2' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:3' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:4' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:5' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:6' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:7' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:8' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:9' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:10' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:11' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:12' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:13' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:14' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:15' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:16' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:17' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:18' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:19' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:20' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:21' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:22' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:23' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:24' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:25' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:26' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:27' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:28' shape=(?, 3) dtype=float64>, <tf.Tensor 'unstack:29' shape=(?, 3) dtype=float64>]\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection: Y = \n",
      "Tensor(\"ReverseSequence:0\", shape=(?, 30, 3), dtype=float64)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from trained_model/model.ckpt-1000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: trained_model/export/exporter/temp-b'1553548741'/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "arguments[\"evaluation_mode\"] = \"tune_anomaly_thresholds\"\n",
    "arguments[\"eval_file_pattern\"] = \"data/labeled_validation_mixed_sequences.csv\"\n",
    "estimator = train_and_evaluate(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now write into a python module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bash\n",
    "rm -rf trained_model\n",
    "export PYTHONPATH=$PYTHONPATH:$PWD/lstm_autoencoder_anomaly_detection_module\n",
    "python -m trainer.task \\\n",
    "    --train_file_pattern=\"data/training_normal_sequences.csv\" \\\n",
    "    --eval_file_pattern=\"data/validation_normal_1_sequences.csv\"  \\\n",
    "    --output_dir=$PWD/trained_model \\\n",
    "    --job-dir=./tmp \\\n",
    "    --batch_size=32 \\\n",
    "    --sequence_length=13 \\\n",
    "    --horizon=0 \\\n",
    "    --reverse_labels_sequence=True \\\n",
    "    --encoder_lstm_hidden_units=\"64 32 16\" \\\n",
    "    --encoder_lstm_hidden_units=\"16 32 64\" \\\n",
    "    --lstm_dropout_output_keep_probs=\"0.9 0.95 1.0\" \\\n",
    "    --dnn_hidden_units=\"1024 256 64\" \\\n",
    "    --train_steps=1000 \\\n",
    "    --learning_rate=0.1 \\\n",
    "    --start_delay_secs=60 \\\n",
    "    --throttle_secs=120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil -m cp -r data gs://$BUCKET/lstm_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bash\n",
    "OUTDIR=gs://$BUCKET/lstm_autoencoder/trained_model\n",
    "JOBNAME=job_lstm_autoencoder$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=$PWD/lstm_autoencoder_anomaly_detection_module/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=STANDARD_1 \\\n",
    "  --runtime-version=1.8 \\\n",
    "  -- \\\n",
    "  --train_file_pattern=gs://$BUCKET/lstm_autoencoder/data/training_normal_sequences.csv \\\n",
    "  --eval_file_pattern=gs://$BUCKET/lstm_autoencoder/data/validation_normal_1_sequences.csv  \\\n",
    "  --output_dir=$OUTDIR \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --batch_size=32 \\\n",
    "  --sequence_length=13 \\\n",
    "  --horizon=0 \\\n",
    "  --reverse_labels_sequence=True \\\n",
    "  --encoder_lstm_hidden_units=\"64 32 16\" \\\n",
    "  --encoder_lstm_hidden_units=\"16 32 64\" \\\n",
    "  --lstm_dropout_output_keep_probs=\"0.9 0.95 1.0\" \\\n",
    "  --dnn_hidden_units=\"1024 256 64\" \\\n",
    "  --train_steps=1000 \\\n",
    "  --learning_rate=0.1 \\\n",
    "  --start_delay_secs=60 \\\n",
    "  --throttle_secs=120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%writefile hyperparam.yaml\n",
    "trainingInput:\n",
    "  scaleTier: STANDARD_1\n",
    "  hyperparameters:\n",
    "    hyperparameterMetricTag: mae\n",
    "    goal: MINIMIZE\n",
    "    maxTrials: 30\n",
    "    maxParallelTrials: 1\n",
    "    params:\n",
    "    - parameterName: batch_size\n",
    "      type: INTEGER\n",
    "      minValue: 8\n",
    "      maxValue: 512\n",
    "      scaleType: UNIT_LOG_SCALE\n",
    "    - parameterName: sequence_length\n",
    "      type: INTEGER\n",
    "      minValue: 10\n",
    "      maxValue: 120\n",
    "      scaleType: UNIT_LOG_SCALE\n",
    "    - parameterName: encoder_lstm_hidden_units\n",
    "      type: CATEGORICAL\n",
    "      categoricalValues: [\"64 32 16\", \"256 128 16\", \"64 64 64\"]\n",
    "    - parameterName: decoder_lstm_hidden_units\n",
    "      type: CATEGORICAL\n",
    "      categoricalValues: [\"64 32 16\", \"256 128 16\", \"64 64 64\"]\n",
    "    - parameterName: lstm_dropout_output_keep_probs\n",
    "      type: CATEGORICAL\n",
    "      categoricalValues: [\"0.9 1.0 1.0\", \"0.95 0.95 1.0\", \"0.95 0.95 0.95\"]\n",
    "    - parameterName: dnn_hidden_units\n",
    "      type: CATEGORICAL\n",
    "      categoricalValues: [\"256 128 64\", \"256 128 16\", \"64 64 64\"]\n",
    "    - parameterName: learning_rate\n",
    "      type: DOUBLE\n",
    "      minValue: 0.001\n",
    "      maxValue: 0.1\n",
    "      scaleType: UNIT_LINEAR_SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bash\n",
    "OUTDIR=gs://$BUCKET/lstm_autoencoder/hyperparam\n",
    "JOBNAME=job_lstm_autoencoder$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=$PWD/lstm_autoencoder_anomaly_detection_module/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET/lstm_autoencoder/staging \\\n",
    "  --scale-tier=STANDARD_1 \\\n",
    "  --config=hyperparam.yaml \\\n",
    "  --runtime-version=1.8 \\\n",
    "  -- \\\n",
    "  --train_file_pattern=gs://$BUCKET/lstm_autoencoder/data/train.csv \\\n",
    "  --eval_file_pattern=gs://$BUCKET/lstm_autoencoder/data/eval.csv  \\\n",
    "  --output_dir=$OUTDIR \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --sequence_length=13 \\\n",
    "  --horizon=0 \\\n",
    "  --reverse_labels_sequence=True \\\n",
    "  --train_steps=1000 \\\n",
    "  --start_delay_secs=60 \\\n",
    "  --throttle_secs=120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil -m cp -r trained_model gs://qwiklabs-gcp-8923d4964bfbd247-bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bash\n",
    "MODEL_NAME=\"lstm_autoencoder_anomaly_detection\"\n",
    "MODEL_VERSION=\"v1\"\n",
    "MODEL_LOCATION=$(gsutil ls gs://$BUCKET/trained_model/export/exporter/ | tail -1)\n",
    "echo \"Deleting and deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION ... this will take a few minutes\"\n",
    "#gcloud ml-engine versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#gcloud ml-engine models delete ${MODEL_NAME}\n",
    "gcloud ml-engine models create $MODEL_NAME --regions $REGION\n",
    "gcloud ml-engine versions create $MODEL_VERSION --model $MODEL_NAME --origin $MODEL_LOCATION --runtime-version 1.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_prediction_instances = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local prediction from local model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sequences.json', 'w') as outfile:\n",
    "    test_data_anomalous_string_list = [[np.array2string(a = create_time_series_with_anomaly(1, sequence_length, percent_sequence_before_anomaly, percent_sequence_after_anomaly, tag[\"normal_freq\"], tag[\"normal_ampl\"], tag[\"normal_noise_noise_scale\"]), separator = ',').replace('[','').replace(']','').replace('\\n','') for tag in tag_data_list] for _ in range(0, number_of_prediction_instances)]\n",
    "    json_string = \"\"\n",
    "    for item in test_data_anomalous_string_list:\n",
    "        json_string += \"{\" + ','.join([\"{0}: \\\"{1}\\\"\".format('\\\"' + UNLABELED_CSV_COLUMNS[i] + '\\\"', item[i]) for i in range(0, len(UNLABELED_CSV_COLUMNS))]) + \"}\\n\"\n",
    "    json_string = json_string.replace(' ', '').replace(':', ': ').replace(',', ', ')\n",
    "    outfile.write(\"%s\" % json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "model_dir=$(ls ${PWD}/trained_model/export/exporter | tail -1)\n",
    "gcloud ml-engine local predict \\\n",
    "    --model-dir=${PWD}/trained_model/export/exporter/${model_dir} \\\n",
    "    --json-instances=./sequences.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCloud ML-Engine prediction from deployed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format dataframe to instances list to get sent to ML-Engine\n",
    "instances = [{column: np.array2string(a = create_time_series_with_anomaly(1, sequence_length, percent_sequence_before_anomaly, percent_sequence_after_anomaly, tag[\"clean_freq\"], tag[\"clean_ampl\"], tag[\"clean_noise_noise_scale\"]), separator = ',').replace('[','').replace(']','').replace('\\n','') for tag in tag_data_list for column in CSV_COLUMNS} for _ in range(0, number_of_prediction_instances)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send instance dictionary to receive response from ML-Engine for online prediction\n",
    "from googleapiclient import discovery\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import json\n",
    "\n",
    "credentials = GoogleCredentials.get_application_default()\n",
    "api = discovery.build('ml', 'v1', credentials=credentials)\n",
    "\n",
    "request_data = {\"instances\": instances}\n",
    "\n",
    "parent = 'projects/%s/models/%s/versions/%s' % (PROJECT, 'lstm_autoencoder_anomaly_detection', 'v1')\n",
    "response = api.projects().predict(body = request_data, name = parent).execute()\n",
    "print(\"response = {}\".format(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r ../../../../tutorials/machine_learning_deepdive/06_structured/babyweight/* lstm_encoder_decoder_autoencoder_anomaly_detection_module/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection.ipynb\n",
      "lstm_encoder_decoder_autoencoder_anomaly_detection_module\n",
      "tf_mahalanobis_test.ipynb\n",
      "trained_model\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PKG-INFO  setup.cfg  setup.py  trainer\n"
     ]
    }
   ],
   "source": [
    "!ls lstm_encoder_decoder_autoencoder_anomaly_detection_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
