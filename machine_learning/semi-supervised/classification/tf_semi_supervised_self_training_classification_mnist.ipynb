{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-supervised Self-learning Classification with mnist Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (60000, 28, 28)\n",
      "y_train.shape = (60000,)\n",
      "x_test.shape = (10000, 28, 28)\n",
      "y_test.shape = (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train.shape = {}\".format(x_train.shape))\n",
    "print(\"y_train.shape = {}\".format(y_train.shape))\n",
    "print(\"x_test.shape = {}\".format(x_test.shape))\n",
    "print(\"y_test.shape = {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 28\n",
    "WIDTH = 28\n",
    "NCLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.eye(N = NCLASSES)[y_train]\n",
    "y_test = np.eye(N = NCLASSES)[y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (60000, 28, 28)\n",
      "y_train.shape = (60000, 10)\n",
      "x_test.shape = (10000, 28, 28)\n",
      "y_test.shape = (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train.shape = {}\".format(x_train.shape))\n",
    "print(\"y_train.shape = {}\".format(y_train.shape))\n",
    "print(\"x_test.shape = {}\".format(x_test.shape))\n",
    "print(\"y_test.shape = {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create fully supervised model for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {\"image\": x_train},\n",
    "    y = y_train,\n",
    "    batch_size = 100,\n",
    "    num_epochs = None,\n",
    "    shuffle = True,\n",
    "    queue_capacity = 5000)\n",
    "\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {\"image\": x_test},\n",
    "    y = y_test,\n",
    "    batch_size = 100,\n",
    "    num_epochs = 1,\n",
    "    shuffle = False,\n",
    "    queue_capacity = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(img, mode, hparams):\n",
    "    X = tf.reshape(tensor = img, shape = [-1,HEIGHT * WIDTH]) # flatten\n",
    "    ylogits = tf.layers.dense(inputs = X, units = NCLASSES, activation = None)\n",
    "    return ylogits, NCLASSES\n",
    "\n",
    "def dnn_model(img, mode, hparams):\n",
    "    X = tf.reshape(tensor = img, shape = [-1, HEIGHT * WIDTH]) # flatten\n",
    "    h1 = tf.layers.dense(inputs = X, units = 300, activation = tf.nn.relu)\n",
    "    h2 = tf.layers.dense(inputs = h1, units = 100, activation = tf.nn.relu)\n",
    "    h3 = tf.layers.dense(inputs = h2, units = 30, activation = tf.nn.relu)\n",
    "    ylogits = tf.layers.dense(inputs = h3, units = NCLASSES, activation = None)\n",
    "    return ylogits, NCLASSES\n",
    "\n",
    "def dnn_dropout_model(img, mode, hparams):\n",
    "    dprob = hparams.get(\"dprob\", 0.1)\n",
    "\n",
    "    X = tf.reshape(tensor = img, shape = [-1, HEIGHT * WIDTH]) #flatten\n",
    "    h1 = tf.layers.dense(inputs = X, units = 300, activation = tf.nn.relu)\n",
    "    h2 = tf.layers.dense(inputs = h1, units = 100, activation = tf.nn.relu)\n",
    "    h3 = tf.layers.dense(inputs = h2, units = 30, activation = tf.nn.relu)\n",
    "    h3d = tf.layers.dropout(inputs = h3, rate = dprob, training = (mode == tf.estimator.ModeKeys.TRAIN)) # only dropout when training\n",
    "    ylogits = tf.layers.dense(inputs = h3d, units = NCLASSES, activation = None)\n",
    "    return ylogits, NCLASSES\n",
    "\n",
    "def cnn_model(img, mode, hparams):\n",
    "    ksize1 = hparams.get(\"ksize1\", 5)\n",
    "    ksize2 = hparams.get(\"ksize2\", 5)\n",
    "    nfil1 = hparams.get(\"nfil1\", 10)\n",
    "    nfil2 = hparams.get(\"nfil2\", 20)\n",
    "    dprob = hparams.get(\"dprob\", 0.25)\n",
    "\n",
    "    c1 = tf.layers.conv2d(inputs = img, filters = nfil1,\n",
    "                          kernel_size = ksize1, strides = 1, # ?x28x28x10\n",
    "                          padding = \"same\", activation = tf.nn.relu)\n",
    "    p1 = tf.layers.max_pooling2d(inputs = c1, pool_size = 2, strides = 2) # ?x14x14x10\n",
    "    c2 = tf.layers.conv2d(inputs = p1, filters = nfil2,\n",
    "                          kernel_size = ksize2, strides = 1, \n",
    "                          padding = \"same\", activation = tf.nn.relu)\n",
    "    p2 = tf.layers.max_pooling2d(inputs = c2, pool_size = 2, strides = 2) # ?x7x7x20\n",
    "    \n",
    "    outlen = p2.shape[1] * p2.shape[2] * p2.shape[3] #980\n",
    "    p2flat = tf.reshape(tensor = p2, shape = [-1, outlen]) # flattened\n",
    "\n",
    "    # Apply batch normalization\n",
    "    if hparams[\"batch_norm\"]:\n",
    "        h3 = tf.layers.dense(inputs = p2flat, units = 300, activation = None)\n",
    "        h3 = tf.layers.batch_normalization(x = h3, training = (mode == tf.estimator.ModeKeys.TRAIN)) #only batchnorm when training\n",
    "        h3 = tf.nn.relu(x = h3)\n",
    "    else:    \n",
    "        h3 = tf.layers.dense(inputs = p2flat, units = 300, activation = tf.nn.relu)\n",
    "    \n",
    "    # Apply dropout\n",
    "    h3d = tf.layers.dropout(inputs = h3, rate = dprob, training = (mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    ylogits = tf.layers.dense(inputs = h3d, units = NCLASSES, activation = None)\n",
    "        \n",
    "    # Apply batch normalization once more\n",
    "    if hparams[\"batch_norm\"]:\n",
    "         ylogits = tf.layers.batch_normalization(x = ylogits, training = (mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    return ylogits, NCLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_classifier(features, labels, mode, params):\n",
    "    print(\"\\nfeatures = \\n{}\".format(features))\n",
    "    print(\"labels = \\n{}\".format(labels))\n",
    "    print(\"mode = \\n{}\".format(mode))\n",
    "    print(\"params = \\n{}\".format(params))\n",
    "    \n",
    "    model_functions = {\n",
    "        \"linear\":linear_model,\n",
    "        \"dnn\":dnn_model,\n",
    "        \"dnn_dropout\":dnn_dropout_model,\n",
    "        \"cnn\":cnn_model}\n",
    "    \n",
    "    model_function = model_functions[params[\"model\"]]    \n",
    "    \n",
    "    ylogits, nclasses = model_function(features[\"image\"], mode, params)\n",
    "    print(\"ylogits = \\n{}\".format(ylogits))\n",
    "    probabilities = tf.nn.softmax(logits = ylogits) # shape = (current_batch_size, NCLASSES)\n",
    "    print(\"probabilities = \\n{}\".format(probabilities))\n",
    "    class_ids = tf.cast(x = tf.argmax(input = probabilities, axis = 1), dtype = tf.uint8) # shape = (current_batch_size,)\n",
    "    print(\"class_ids = \\n{}\".format(class_ids))\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n",
    "        loss = tf.reduce_mean(input_tensor = tf.nn.softmax_cross_entropy_with_logits_v2(logits = ylogits, labels = labels))\n",
    "        eval_metric_ops = {\"accuracy\": tf.metrics.accuracy(labels = tf.argmax(input = labels, axis = 1), predictions = class_ids)}\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            # This is needed for batch normalization, but has no effect otherwise\n",
    "            update_ops = tf.get_collection(key = tf.GraphKeys.UPDATE_OPS)\n",
    "            with tf.control_dependencies(update_ops):\n",
    "                train_op = tf.contrib.layers.optimize_loss(\n",
    "                    loss = loss, \n",
    "                    global_step = tf.train.get_global_step(),\n",
    "                    learning_rate = params[\"learning_rate\"], \n",
    "                    optimizer = \"Adam\")\n",
    "        else:\n",
    "            train_op = None\n",
    "    else:\n",
    "        loss = None\n",
    "        train_op = None\n",
    "        eval_metric_ops = None\n",
    " \n",
    "    return tf.estimator.EstimatorSpec(\n",
    "                mode = mode,\n",
    "                predictions = {\"probabilities\": probabilities, \"class_ids\": class_ids},\n",
    "                loss = loss,\n",
    "                train_op = train_op,\n",
    "                eval_metric_ops = eval_metric_ops,\n",
    "                export_outputs = {\"classes\": tf.estimator.export.PredictOutput({\"probabilities\": probabilities, \"class_ids\": class_ids})})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn():\n",
    "    # Input will be rank 3\n",
    "    feature_placeholders = {\"image\": tf.placeholder(dtype = tf.float64, shape = [None, HEIGHT, WIDTH])}\n",
    "    # But model function requires rank 4\n",
    "    features = {\"image\": tf.expand_dims(input = feature_placeholders[\"image\"], axis = -1)} \n",
    "    return tf.estimator.export.ServingInputReceiver(features = features, receiver_tensors = feature_placeholders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(output_dir, hparams):\n",
    "    tf.summary.FileWriterCache.clear() # ensure filewriter cache is clear for TensorBoard events file\n",
    "    EVAL_INTERVAL = 60\n",
    "\n",
    "    supervised_estimator = tf.estimator.Estimator(model_fn = image_classifier,\n",
    "                                                  params = hparams,\n",
    "                                                  config = tf.estimator.RunConfig(save_checkpoints_secs = EVAL_INTERVAL),\n",
    "                                                  model_dir = output_dir)\n",
    "    \n",
    "    train_spec = tf.estimator.TrainSpec(input_fn = train_input_fn,\n",
    "                                        max_steps = hparams[\"train_steps\"])\n",
    "    \n",
    "    exporter = tf.estimator.LatestExporter(\"exporter\", serving_input_fn)\n",
    "    \n",
    "    eval_spec = tf.estimator.EvalSpec(input_fn = eval_input_fn,\n",
    "                                      steps = None,\n",
    "                                      exporters = exporter,\n",
    "                                      throttle_secs = EVAL_INTERVAL)\n",
    "    \n",
    "    tf.estimator.train_and_evaluate(supervised_estimator, train_spec, eval_spec)\n",
    "    \n",
    "    return supervised_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {}\n",
    "hparams[\"train_batch_size\"] = 100\n",
    "hparams[\"learning_rate\"] = 0.01\n",
    "hparams[\"train_steps\"] = 1000\n",
    "hparams[\"ksize1\"] = 5\n",
    "hparams[\"ksize2\"] = 5\n",
    "hparams[\"nfil1\"] = 10\n",
    "hparams[\"nfil2\"] = 20\n",
    "hparams[\"dprob\"] = 0.1\n",
    "hparams[\"batch_norm\"] = False\n",
    "hparams[\"model\"] = \"linear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'supervised_trained', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 60, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0xb3ccb7fd0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 60.\n",
      "WARNING:tensorflow:From /Users/ryangillard/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /Users/ryangillard/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "features = \n",
      "{'image': <tf.Tensor 'random_shuffle_queue_DequeueMany:1' shape=(100, 28, 28) dtype=float64>}\n",
      "labels = \n",
      "Tensor(\"random_shuffle_queue_DequeueMany:2\", shape=(100, 10), dtype=float64, device=/device:CPU:0)\n",
      "mode = \n",
      "train\n",
      "params = \n",
      "{'train_batch_size': 100, 'learning_rate': 0.01, 'train_steps': 1000, 'ksize1': 5, 'ksize2': 5, 'nfil1': 10, 'nfil2': 20, 'dprob': 0.1, 'batch_norm': False, 'model': 'linear'}\n",
      "ylogits = \n",
      "Tensor(\"dense/BiasAdd:0\", shape=(100, 10), dtype=float64)\n",
      "probabilities = \n",
      "Tensor(\"Softmax:0\", shape=(100, 10), dtype=float64)\n",
      "class_ids = \n",
      "Tensor(\"Cast:0\", shape=(100,), dtype=uint8)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /Users/ryangillard/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into supervised_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.408619868216438, step = 1\n",
      "INFO:tensorflow:global_step/sec: 247.926\n",
      "INFO:tensorflow:loss = 0.2876858550860294, step = 101 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.566\n",
      "INFO:tensorflow:loss = 0.247698802824142, step = 201 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.174\n",
      "INFO:tensorflow:loss = 0.37134566387742235, step = 301 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.621\n",
      "INFO:tensorflow:loss = 0.33231885850200904, step = 401 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.882\n",
      "INFO:tensorflow:loss = 0.2593446828247385, step = 501 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.331\n",
      "INFO:tensorflow:loss = 0.12997243919407725, step = 601 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.218\n",
      "INFO:tensorflow:loss = 0.3004149502668582, step = 701 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.005\n",
      "INFO:tensorflow:loss = 0.19638973428070597, step = 801 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.528\n",
      "INFO:tensorflow:loss = 0.37672645698335655, step = 901 (0.394 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into supervised_trained/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "features = \n",
      "{'image': <tf.Tensor 'fifo_queue_DequeueUpTo:1' shape=(?, 28, 28) dtype=float64>}\n",
      "labels = \n",
      "Tensor(\"fifo_queue_DequeueUpTo:2\", shape=(?, 10), dtype=float64, device=/device:CPU:0)\n",
      "mode = \n",
      "eval\n",
      "params = \n",
      "{'train_batch_size': 100, 'learning_rate': 0.01, 'train_steps': 1000, 'ksize1': 5, 'ksize2': 5, 'nfil1': 10, 'nfil2': 20, 'dprob': 0.1, 'batch_norm': False, 'model': 'linear'}\n",
      "ylogits = \n",
      "Tensor(\"dense/BiasAdd:0\", shape=(?, 10), dtype=float64)\n",
      "probabilities = \n",
      "Tensor(\"Softmax:0\", shape=(?, 10), dtype=float64)\n",
      "class_ids = \n",
      "Tensor(\"Cast:0\", shape=(?,), dtype=uint8)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-15-20:11:24\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from supervised_trained/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-15-20:11:24\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.9165, global_step = 1000, loss = 0.2960023\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: supervised_trained/model.ckpt-1000\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "features = \n",
      "{'image': <tf.Tensor 'ExpandDims:0' shape=(?, 28, 28, 1) dtype=float64>}\n",
      "labels = \n",
      "None\n",
      "mode = \n",
      "infer\n",
      "params = \n",
      "{'train_batch_size': 100, 'learning_rate': 0.01, 'train_steps': 1000, 'ksize1': 5, 'ksize2': 5, 'nfil1': 10, 'nfil2': 20, 'dprob': 0.1, 'batch_norm': False, 'model': 'linear'}\n",
      "ylogits = \n",
      "Tensor(\"dense/BiasAdd:0\", shape=(?, 10), dtype=float64)\n",
      "probabilities = \n",
      "Tensor(\"Softmax:0\", shape=(?, 10), dtype=float64)\n",
      "class_ids = \n",
      "Tensor(\"Cast:0\", shape=(?,), dtype=uint8)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['classes', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from supervised_trained/model.ckpt-1000\n",
      "WARNING:tensorflow:From /Users/ryangillard/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py:1044: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Pass your op to the equivalent parameter main_op instead.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: supervised_trained/export/exporter/temp-b'1552680684'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 0.34382430809847664.\n"
     ]
    }
   ],
   "source": [
    "SUPERVISED_MODEL_DIR = \"supervised_trained\"\n",
    "shutil.rmtree(path = SUPERVISED_MODEL_DIR, ignore_errors = True) # start fresh each time\n",
    "supervised_estimator = train_and_evaluate(SUPERVISED_MODEL_DIR, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "features = \n",
      "{'image': <tf.Tensor 'fifo_queue_DequeueUpTo:1' shape=(?, 28, 28) dtype=float64>}\n",
      "labels = \n",
      "Tensor(\"fifo_queue_DequeueUpTo:2\", shape=(?, 10), dtype=float64, device=/device:CPU:0)\n",
      "mode = \n",
      "eval\n",
      "params = \n",
      "{'train_batch_size': 100, 'learning_rate': 0.01, 'train_steps': 1000, 'ksize1': 5, 'ksize2': 5, 'nfil1': 10, 'nfil2': 20, 'dprob': 0.1, 'batch_norm': False, 'model': 'linear'}\n",
      "ylogits = \n",
      "Tensor(\"dense/BiasAdd:0\", shape=(?, 10), dtype=float64)\n",
      "probabilities = \n",
      "Tensor(\"Softmax:0\", shape=(?, 10), dtype=float64)\n",
      "class_ids = \n",
      "Tensor(\"Cast:0\", shape=(?,), dtype=uint8)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-15-20:11:24\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from supervised_trained/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-15-20:11:25\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.9165, global_step = 1000, loss = 0.2960023\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: supervised_trained/model.ckpt-1000\n"
     ]
    }
   ],
   "source": [
    "eval_metrics = supervised_estimator.evaluate(input_fn = eval_input_fn, steps = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now create semi-supervised model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_train_examples = 60000\n"
     ]
    }
   ],
   "source": [
    "number_of_train_examples = x_train.shape[0]\n",
    "print(\"number_of_train_examples = {}\".format(number_of_train_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_labeled_train_examples = 3000 & number_of_unlabeled_train_examples = 57000\n"
     ]
    }
   ],
   "source": [
    "number_of_labeled_train_examples = int(number_of_train_examples * 0.05)\n",
    "number_of_unlabeled_train_examples = number_of_train_examples - number_of_labeled_train_examples\n",
    "print(\"number_of_labeled_train_examples = {} & number_of_unlabeled_train_examples = {}\".format(number_of_labeled_train_examples, number_of_unlabeled_train_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "semi_supervised_labeled_x_train_original_arr = x_train[0:number_of_labeled_train_examples]\n",
    "semi_supervised_labeled_y_train_original_arr = y_train[0:number_of_labeled_train_examples]\n",
    "semi_supervised_unlabeled_x_train_original_arr = x_train[number_of_labeled_train_examples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "semi_supervised_labeled_x_train_original_arr.shape = (3000, 28, 28)\n",
      "semi_supervised_labeled_y_train_original_arr.shape = (3000, 10)\n",
      "semi_supervised_unlabeled_x_train_original_arr.shape = (57000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"semi_supervised_labeled_x_train_original_arr.shape = {}\".format(semi_supervised_labeled_x_train_original_arr.shape))\n",
    "print(\"semi_supervised_labeled_y_train_original_arr.shape = {}\".format(semi_supervised_labeled_y_train_original_arr.shape))\n",
    "print(\"semi_supervised_unlabeled_x_train_original_arr.shape = {}\".format(semi_supervised_unlabeled_x_train_original_arr.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create semi-supervised model using sparse labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEMI_SUPERVISED_MODEL_DIR = \"semi_supervised_trained\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'semi_supervised_trained', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 30, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c6aa4e7b8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "EVAL_INTERVAL = 30\n",
    "semi_supervised_estimator = tf.estimator.Estimator(model_fn = image_classifier,\n",
    "                                                   params = hparams,\n",
    "                                                   config = tf.estimator.RunConfig(save_checkpoints_secs = EVAL_INTERVAL),\n",
    "                                                   model_dir = SEMI_SUPERVISED_MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_threshold = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loop_counter = 0, number_of_labeled_examples = 3000, number_of_unlabeled_examples = 57000\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "features = \n",
      "{'image': <tf.Tensor 'random_shuffle_queue_DequeueMany:1' shape=(32, 28, 28) dtype=float64>}\n",
      "labels = \n",
      "Tensor(\"random_shuffle_queue_DequeueMany:2\", shape=(32, 10), dtype=float64, device=/device:CPU:0)\n",
      "mode = \n",
      "train\n",
      "params = \n",
      "{'train_batch_size': 100, 'learning_rate': 0.01, 'train_steps': 1000, 'ksize1': 5, 'ksize2': 5, 'nfil1': 10, 'nfil2': 20, 'dprob': 0.1, 'batch_norm': False, 'model': 'linear'}\n",
      "ylogits = \n",
      "Tensor(\"dense/BiasAdd:0\", shape=(32, 10), dtype=float64)\n",
      "probabilities = \n",
      "Tensor(\"Softmax:0\", shape=(32, 10), dtype=float64)\n",
      "class_ids = \n",
      "Tensor(\"Cast:0\", shape=(32,), dtype=uint8)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into semi_supervised_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.458171013671546, step = 1\n",
      "INFO:tensorflow:global_step/sec: 360.834\n",
      "INFO:tensorflow:loss = 0.4620192376525701, step = 101 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.828\n",
      "INFO:tensorflow:loss = 0.2877856211964262, step = 201 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.923\n",
      "INFO:tensorflow:loss = 0.24369675215501932, step = 301 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.888\n",
      "INFO:tensorflow:loss = 0.1939510781308265, step = 401 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.496\n",
      "INFO:tensorflow:loss = 0.15282235837034408, step = 501 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.989\n",
      "INFO:tensorflow:loss = 0.25055191257332055, step = 601 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.675\n",
      "INFO:tensorflow:loss = 0.11214244325353492, step = 701 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.29\n",
      "INFO:tensorflow:loss = 0.07878694296429731, step = 801 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 483.391\n",
      "INFO:tensorflow:loss = 0.11075917331956359, step = 901 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.141\n",
      "INFO:tensorflow:loss = 0.01632729220356041, step = 1001 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.645\n",
      "INFO:tensorflow:loss = 0.04831669013219618, step = 1101 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 485.333\n",
      "INFO:tensorflow:loss = 0.035417131284566944, step = 1201 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.139\n",
      "INFO:tensorflow:loss = 0.031451601987223056, step = 1301 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.406\n",
      "INFO:tensorflow:loss = 0.05698579004435095, step = 1401 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 482.141\n",
      "INFO:tensorflow:loss = 0.038641706386700024, step = 1501 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.176\n",
      "INFO:tensorflow:loss = 0.060423126280925346, step = 1601 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.602\n",
      "INFO:tensorflow:loss = 0.04459970570002931, step = 1701 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.781\n",
      "INFO:tensorflow:loss = 0.05938495660443617, step = 1801 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.85\n",
      "INFO:tensorflow:loss = 0.03518594100027604, step = 1901 (0.216 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into semi_supervised_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.03768467857591165.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "features = \n",
      "{'image': <tf.Tensor 'fifo_queue_DequeueUpTo:1' shape=(?, 28, 28) dtype=float64>}\n",
      "labels = \n",
      "Tensor(\"fifo_queue_DequeueUpTo:2\", shape=(?, 10), dtype=float64, device=/device:CPU:0)\n",
      "mode = \n",
      "eval\n",
      "params = \n",
      "{'train_batch_size': 100, 'learning_rate': 0.01, 'train_steps': 1000, 'ksize1': 5, 'ksize2': 5, 'nfil1': 10, 'nfil2': 20, 'dprob': 0.1, 'batch_norm': False, 'model': 'linear'}\n",
      "ylogits = \n",
      "Tensor(\"dense/BiasAdd:0\", shape=(?, 10), dtype=float64)\n",
      "probabilities = \n",
      "Tensor(\"Softmax:0\", shape=(?, 10), dtype=float64)\n",
      "class_ids = \n",
      "Tensor(\"Cast:0\", shape=(?,), dtype=uint8)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-15-20:11:30\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from semi_supervised_trained/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-15-20:11:31\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.8867, global_step = 2000, loss = 0.5241929\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: semi_supervised_trained/model.ckpt-2000\n"
     ]
    }
   ],
   "source": [
    "shutil.rmtree(path = SEMI_SUPERVISED_MODEL_DIR, ignore_errors = True) # start fresh each time\n",
    "\n",
    "semi_supervised_labeled_x_train_arr = semi_supervised_labeled_x_train_original_arr\n",
    "semi_supervised_labeled_y_train_arr = semi_supervised_labeled_y_train_original_arr\n",
    "semi_supervised_unlabeled_x_train_arr = semi_supervised_unlabeled_x_train_original_arr\n",
    "\n",
    "new_labeled_x_train_arr = np.zeros([1])\n",
    "\n",
    "accuracy = 0.000001\n",
    "old_accuracy = 0.0\n",
    "\n",
    "loop_counter = 0\n",
    "print(\"\\nloop_counter = {}, number_of_labeled_examples = {}, number_of_unlabeled_examples = {}\\n\".format(loop_counter, semi_supervised_labeled_x_train_arr.shape[0], semi_supervised_unlabeled_x_train_arr.shape[0]))\n",
    "# Train on currently labeled data\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(x = {\"image\": semi_supervised_labeled_x_train_arr}, \n",
    "                                                    y = semi_supervised_labeled_y_train_arr, \n",
    "                                                    batch_size = 32, \n",
    "                                                    num_epochs = None, \n",
    "                                                    shuffle = True)\n",
    "\n",
    "semi_supervised_estimator.train(input_fn = train_input_fn, \n",
    "                                steps = 2000)\n",
    "\n",
    "\n",
    "# Check evaluation metrics on held out evaluation set now that training is over\n",
    "eval_metrics = semi_supervised_estimator.evaluate(input_fn = eval_input_fn, \n",
    "                                                  steps = None)\n",
    "\n",
    "old_accuracy = accuracy\n",
    "accuracy = eval_metrics[\"accuracy\"]\n",
    "\n",
    "# # Now predict from the unlabeled set\n",
    "# predict_input_fn = tf.estimator.inputs.numpy_input_fn(x = {\"image\": semi_supervised_unlabeled_x_train_arr}, \n",
    "#                                                       y = None, \n",
    "#                                                       batch_size = 512, \n",
    "#                                                       num_epochs = 1, \n",
    "#                                                       shuffle = False)\n",
    "\n",
    "# predictions = [prediction for prediction in semi_supervised_estimator.predict(input_fn = predict_input_fn)]\n",
    "\n",
    "# # Get the probabilities from the prediction list generated from the estimator\n",
    "# probabilities = np.array(object = [prediction[\"probabilities\"] for prediction in predictions]) # shape = (semi_supervised_unlabeled_x_train_arr.shape[0], NUM_CLASSES)\n",
    "\n",
    "# # Check if our predictions are above the confidence threshold\n",
    "# confidence_condition = np.amax(a = probabilities, axis = 1) > confidence_threshold # shape = (semi_supervised_unlabeled_x_train_arr.shape[0],)\n",
    "\n",
    "# # Create array of the confidently prediction examples combining their features with the predicted probabilities\n",
    "# new_labeled_x_train_arr = semi_supervised_unlabeled_x_train_arr[confidence_condition]\n",
    "# new_labeled_y_train_arr = probabilities[confidence_condition]\n",
    "\n",
    "# semi_supervised_labeled_x_train_arr = np.concatenate(seq = [semi_supervised_labeled_x_train_arr, new_labeled_x_train_arr], axis = 0)\n",
    "# semi_supervised_labeled_y_train_arr = np.concatenate(seq = [semi_supervised_labeled_y_train_arr, new_labeled_y_train_arr], axis = 0)\n",
    "\n",
    "# # Remove the confident predictions leaving only the unconfident predictions to go another round through the loop\n",
    "# semi_supervised_unlabeled_x_train_arr = semi_supervised_unlabeled_x_train_arr[~confidence_condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(x = {\"image\": semi_supervised_unlabeled_x_train_arr}, \n",
    "                                                      y = None, \n",
    "                                                      batch_size = 512, \n",
    "                                                      num_epochs = 1, \n",
    "                                                      shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = semi_supervised_estimator.predict(input_fn = predict_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "features = \n",
      "{'image': <tf.Tensor 'fifo_queue_DequeueUpTo:1' shape=(?, 28, 28) dtype=float64>}\n",
      "labels = \n",
      "None\n",
      "mode = \n",
      "infer\n",
      "params = \n",
      "{'train_batch_size': 100, 'learning_rate': 0.01, 'train_steps': 1000, 'ksize1': 5, 'ksize2': 5, 'nfil1': 10, 'nfil2': 20, 'dprob': 0.1, 'batch_norm': False, 'model': 'linear'}\n",
      "ylogits = \n",
      "Tensor(\"dense/BiasAdd:0\", shape=(?, 10), dtype=float64)\n",
      "probabilities = \n",
      "Tensor(\"Softmax:0\", shape=(?, 10), dtype=float64)\n",
      "class_ids = \n",
      "Tensor(\"Cast:0\", shape=(?,), dtype=uint8)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from semi_supervised_trained/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions = [prediction for prediction in semi_supervised_estimator.predict(input_fn = predict_input_fn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = np.array(object = [prediction[\"probabilities\"] for prediction in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57000, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.64081262e-03, 6.88067167e-10, 3.52739454e-03, 1.47519308e-08,\n",
       "       4.10573518e-03, 1.65267933e-03, 5.16866599e-05, 2.24661840e-02,\n",
       "       2.16985118e-04, 9.64338507e-01])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_condition = np.amax(a = probabilities, axis = 1) > confidence_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence_condition[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labeled_x_train_arr = semi_supervised_unlabeled_x_train_arr[confidence_condition]\n",
    "new_labeled_y_train_arr = probabilities[confidence_condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43477, 28, 28)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_labeled_x_train_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43477, 10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_labeled_y_train_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 28, 28)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semi_supervised_labeled_x_train_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 10)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semi_supervised_labeled_y_train_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(50000, 10)\n",
    "b = np.random.rand(1300, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.concatenate(seq = [a, b], axis = 0)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.concatenate(seq = [semi_supervised_labeled_y_train_arr, new_labeled_y_train_arr], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semi_supervised_labeled_x_train_arr = np.concatenate(seq = [semi_supervised_labeled_x_train_arr, new_labeled_x_train_arr], axis = 0)\n",
    "# semi_supervised_labeled_y_train_arr = np.concatenate(seq = [semi_supervised_labeled_y_train_arr, new_labeled_y_train_arr], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semi_supervised_labeled_x_train_arr = np.stack(arrays = [semi_supervised_labeled_x_train_arr, new_labeled_x_train_arr], axis = 0)\n",
    "# semi_supervised_labeled_y_train_arr = np.stack(arrays = [semi_supervised_labeled_y_train_arr, new_labeled_y_train_arr], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semi_supervised_labeled_y_train_arr = np.concatenate([semi_supervised_labeled_y_train_arr, new_labeled_y_train_arr], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semi_supervised_labeled_y_train_arr = np.array([semi_supervised_labeled_y_train_arr, new_labeled_y_train_arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil.rmtree(path = SEMI_SUPERVISED_MODEL_DIR, ignore_errors = True) # start fresh each time\n",
    "\n",
    "# semi_supervised_labeled_x_train_arr = semi_supervised_labeled_x_train_original_arr\n",
    "# semi_supervised_labeled_y_train_arr = semi_supervised_labeled_y_train_original_arr\n",
    "# semi_supervised_unlabeled_x_train_arr = semi_supervised_unlabeled_x_train_original_arr\n",
    "\n",
    "# new_labeled_x_train_arr = np.zeros([1])\n",
    "\n",
    "# accuracy = 0.000001\n",
    "# old_accuracy = 0.0\n",
    "\n",
    "# loop_counter = 0\n",
    "# while semi_supervised_unlabeled_x_train_arr.shape[0] > 0 and new_labeled_x_train_arr.shape[0] > 0 and accuracy > old_accuracy:\n",
    "#     print(\"\\nloop_counter = {}, number_of_labeled_examples = {}, number_of_unlabeled_examples = {}\\n\".format(loop_counter, semi_supervised_labeled_x_train_arr.shape[0], semi_supervised_unlabeled_x_train_arr.shape[0]))\n",
    "#     # Train on currently labeled data\n",
    "#     train_input_fn = tf.estimator.inputs.numpy_input_fn(x = {\"image\": semi_supervised_labeled_x_train_arr}, \n",
    "#                                                         y = semi_supervised_labeled_y_train_arr, \n",
    "#                                                         batch_size = 32, \n",
    "#                                                         num_epochs = None, \n",
    "#                                                         shuffle = True)\n",
    "\n",
    "#     semi_supervised_estimator.train(input_fn = train_input_fn, \n",
    "#                                     steps = 2000)\n",
    "\n",
    "\n",
    "#     # Check evaluation metrics on held out evaluation set now that training is over\n",
    "#     eval_metrics = semi_supervised_estimator.evaluate(input_fn = eval_input_fn, \n",
    "#                                                       steps = None)\n",
    "    \n",
    "#     old_accuracy = accuracy\n",
    "#     accuracy = eval_metrics[\"accuracy\"]\n",
    "\n",
    "#     # Now predict from the unlabeled set\n",
    "#     predict_input_fn = tf.estimator.inputs.numpy_input_fn(x = {\"image\": semi_supervised_unlabeled_x_train_arr}, \n",
    "#                                                           y = None, \n",
    "#                                                           batch_size = 512, \n",
    "#                                                           num_epochs = 1, \n",
    "#                                                           shuffle = False)\n",
    "\n",
    "#     predictions = [prediction for prediction in semi_supervised_estimator.predict(input_fn = predict_input_fn)]\n",
    "\n",
    "#     # Get the probabilities from the prediction list generated from the estimator\n",
    "#     probabilities = np.array(object = [prediction[\"probabilities\"] for prediction in predictions])\n",
    "\n",
    "#     # Check if our predictions are above the confidence threshold\n",
    "#     confidence_condition = np.amax(a = probabilities, axis = 1) > confidence_threshold\n",
    "\n",
    "#     # Create array of the confidently prediction examples combining their features with the predicted probabilities\n",
    "#     new_labeled_x_train_arr = semi_supervised_unlabeled_x_train_arr[confidence_condition]\n",
    "#     new_labeled_y_train_arr = probabilities[confidence_condition]\n",
    "\n",
    "#     semi_supervised_labeled_x_train_arr = np.concatenate(seq = [semi_supervised_labeled_x_train_arr, new_labeled_x_train_arr], axis = 0)\n",
    "#     semi_supervised_labeled_y_train_arr = np.concatenate(seq = [semi_supervised_labeled_y_train_arr, new_labeled_y_train_arr], axis = 0)\n",
    "\n",
    "#     # Remove the confident predictions leaving only the unconfident predictions to go another round through the loop\n",
    "#     semi_supervised_unlabeled_x_train_arr = semi_supervised_unlabeled_x_train_arr[~confidence_condition]\n",
    "    \n",
    "#     loop_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
